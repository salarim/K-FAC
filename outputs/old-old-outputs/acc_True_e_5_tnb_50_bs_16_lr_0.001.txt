Task 1 Model 1:
0 ['2.273']
100 ['1.013']
200 ['0.695']
300 ['0.204']
400 ['0.281']
500 ['0.573']
600 ['0.246']
700 ['0.287']
800 ['0.219']
900 ['0.051']
1000 ['0.171']
1100 ['0.045']
1200 ['0.210']
1300 ['0.120']
1400 ['0.008']
1500 ['0.303']
1600 ['0.196']
1700 ['0.231']
1800 ['0.097']
1900 ['0.208']
2000 ['0.060']
2100 ['0.022']
2200 ['0.158']
2300 ['0.123']
2400 ['0.212']
2500 ['0.215']
2600 ['0.037']
2700 ['0.080']
2800 ['0.086']
2900 ['0.133']
3000 ['0.016']
3100 ['0.020']
3200 ['0.226']
3300 ['0.039']
3400 ['0.216']
3500 ['0.056']
3600 ['0.007']
3700 ['0.162']
Train: [1][3750/3750]	loss 0.168 (0.294)	Acc@1 93.750 (90.953)
0 ['0.138']
100 ['0.015']
200 ['0.249']
300 ['0.053']
400 ['0.012']
500 ['0.071']
600 ['0.197']
700 ['0.015']
800 ['0.179']
900 ['0.013']
1000 ['0.036']
1100 ['0.066']
1200 ['0.264']
1300 ['0.072']
1400 ['0.080']
1500 ['0.015']
1600 ['0.158']
1700 ['0.031']
1800 ['0.077']
1900 ['0.607']
2000 ['0.021']
2100 ['0.145']
2200 ['0.049']
2300 ['0.004']
2400 ['0.165']
2500 ['0.132']
2600 ['0.173']
2700 ['0.053']
2800 ['0.010']
2900 ['0.553']
3000 ['0.007']
3100 ['0.398']
3200 ['0.017']
3300 ['0.003']
3400 ['0.012']
3500 ['0.012']
3600 ['0.047']
3700 ['0.532']
Train: [2][3750/3750]	loss 0.030 (0.112)	Acc@1 100.000 (96.570)
0 ['0.058']
100 ['0.109']
200 ['0.011']
300 ['0.082']
400 ['0.039']
500 ['0.032']
600 ['0.032']
700 ['0.046']
800 ['0.169']
900 ['0.386']
1000 ['0.003']
1100 ['0.006']
1200 ['0.609']
1300 ['0.010']
1400 ['0.047']
1500 ['0.017']
1600 ['0.093']
1700 ['0.079']
1800 ['0.013']
1900 ['0.335']
2000 ['0.121']
2100 ['0.032']
2200 ['0.506']
2300 ['0.037']
2400 ['0.213']
2500 ['0.035']
2600 ['0.020']
2700 ['0.001']
2800 ['0.065']
2900 ['0.004']
3000 ['0.155']
3100 ['0.231']
3200 ['0.058']
3300 ['0.153']
3400 ['0.251']
3500 ['0.007']
3600 ['0.016']
3700 ['0.031']
Train: [3][3750/3750]	loss 0.009 (0.079)	Acc@1 100.000 (97.538)
0 ['0.095']
100 ['0.001']
200 ['0.015']
300 ['0.074']
400 ['0.024']
500 ['0.024']
600 ['0.051']
700 ['0.017']
800 ['0.020']
900 ['0.059']
1000 ['0.115']
1100 ['0.177']
1200 ['0.165']
1300 ['0.400']
1400 ['0.007']
1500 ['0.011']
1600 ['0.026']
1700 ['0.005']
1800 ['0.009']
1900 ['0.009']
2000 ['0.004']
2100 ['0.151']
2200 ['0.188']
2300 ['0.080']
2400 ['0.014']
2500 ['0.023']
2600 ['0.006']
2700 ['0.006']
2800 ['0.005']
2900 ['0.006']
3000 ['0.192']
3100 ['0.004']
3200 ['0.001']
3300 ['0.358']
3400 ['0.033']
3500 ['0.041']
3600 ['0.081']
3700 ['0.007']
Train: [4][3750/3750]	loss 0.002 (0.062)	Acc@1 100.000 (98.022)
0 ['0.003']
100 ['0.059']
200 ['0.086']
300 ['0.001']
400 ['0.003']
500 ['0.018']
600 ['0.046']
700 ['0.000']
800 ['0.001']
900 ['0.010']
1000 ['0.053']
1100 ['0.046']
1200 ['0.009']
1300 ['0.003']
1400 ['0.003']
1500 ['0.026']
1600 ['0.001']
1700 ['0.007']
1800 ['0.087']
1900 ['0.017']
2000 ['0.001']
2100 ['0.065']
2200 ['0.198']
2300 ['0.000']
2400 ['0.003']
2500 ['0.083']
2600 ['0.242']
2700 ['0.090']
2800 ['0.002']
2900 ['0.001']
3000 ['0.036']
3100 ['0.002']
3200 ['0.027']
3300 ['0.052']
3400 ['0.191']
3500 ['0.015']
3600 ['0.306']
3700 ['0.006']
Train: [5][3750/3750]	loss 0.000 (0.052)	Acc@1 100.000 (98.335)
Test model 1 on task 1
Test: [3/3]	loss 0.059 (0.072)	Acc@1 97.898 (97.660)
############################################################ Avg acc: 97.66
Task 2 Model 1:
0 ['0.035', '3.149']
100 ['0.043', '0.204']
200 ['0.042', '0.191']
300 ['0.041', '0.371']
400 ['0.040', '0.246']
500 ['0.041', '0.091']
600 ['0.041', '0.192']
700 ['0.041', '0.453']
800 ['0.040', '0.063']
900 ['0.040', '0.249']
1000 ['0.040', '0.079']
1100 ['0.041', '0.171']
1200 ['0.041', '0.137']
1300 ['0.041', '0.633']
1400 ['0.040', '0.100']
1500 ['0.040', '0.072']
1600 ['0.041', '0.129']
1700 ['0.041', '0.091']
1800 ['0.040', '0.018']
1900 ['0.041', '0.363']
2000 ['0.041', '0.067']
2100 ['0.040', '0.212']
2200 ['0.041', '0.242']
2300 ['0.040', '0.296']
2400 ['0.041', '0.293']
2500 ['0.041', '0.108']
2600 ['0.041', '0.190']
2700 ['0.041', '0.345']
2800 ['0.041', '0.019']
2900 ['0.041', '0.720']
3000 ['0.041', '0.100']
3100 ['0.041', '0.030']
3200 ['0.041', '0.145']
3300 ['0.041', '0.047']
3400 ['0.041', '0.071']
3500 ['0.040', '0.054']
3600 ['0.040', '0.142']
3700 ['0.041', '0.256']
Train: [1][3750/3750]	loss 0.056 (0.137)	Acc@1 100.000 (92.878)
0 ['0.040', '0.063']
100 ['0.041', '0.169']
200 ['0.041', '0.032']
300 ['0.041', '0.077']
400 ['0.041', '0.047']
500 ['0.041', '0.299']
600 ['0.041', '0.147']
700 ['0.041', '0.264']
800 ['0.041', '0.008']
900 ['0.041', '0.056']
1000 ['0.041', '0.107']
1100 ['0.041', '0.096']
1200 ['0.041', '0.053']
1300 ['0.041', '0.009']
1400 ['0.041', '0.007']
1500 ['0.041', '0.250']
1600 ['0.041', '0.018']
1700 ['0.041', '0.286']
1800 ['0.041', '0.399']
1900 ['0.041', '0.294']
2000 ['0.041', '0.017']
2100 ['0.041', '0.317']
2200 ['0.041', '0.030']
2300 ['0.041', '0.015']
2400 ['0.041', '0.064']
2500 ['0.041', '0.133']
2600 ['0.041', '0.067']
2700 ['0.041', '0.011']
2800 ['0.041', '0.108']
2900 ['0.041', '0.013']
3000 ['0.041', '0.003']
3100 ['0.041', '0.078']
3200 ['0.041', '0.214']
3300 ['0.041', '0.323']
3400 ['0.041', '0.017']
3500 ['0.041', '0.088']
3600 ['0.041', '0.044']
3700 ['0.041', '0.012']
Train: [2][3750/3750]	loss 0.073 (0.077)	Acc@1 93.750 (96.525)
0 ['0.041', '0.160']
100 ['0.041', '0.003']
200 ['0.041', '0.012']
300 ['0.041', '0.032']
400 ['0.041', '0.073']
500 ['0.041', '0.030']
600 ['0.041', '0.039']
700 ['0.041', '0.179']
800 ['0.041', '0.008']
900 ['0.041', '0.168']
1000 ['0.041', '0.120']
1100 ['0.041', '0.095']
1200 ['0.041', '0.005']
1300 ['0.041', '0.046']
1400 ['0.041', '0.005']
1500 ['0.042', '0.017']
1600 ['0.041', '0.025']
1700 ['0.041', '0.083']
1800 ['0.041', '0.042']
1900 ['0.041', '0.056']
2000 ['0.041', '0.060']
2100 ['0.041', '0.049']
2200 ['0.041', '0.039']
2300 ['0.041', '0.020']
2400 ['0.041', '0.021']
2500 ['0.041', '0.026']
2600 ['0.041', '0.016']
2700 ['0.041', '0.075']
2800 ['0.042', '0.136']
2900 ['0.041', '0.044']
3000 ['0.041', '0.159']
3100 ['0.041', '0.027']
3200 ['0.041', '0.046']
3300 ['0.041', '0.181']
3400 ['0.041', '0.024']
3500 ['0.041', '0.381']
3600 ['0.041', '0.026']
3700 ['0.041', '0.004']
Train: [3][3750/3750]	loss 0.044 (0.064)	Acc@1 100.000 (97.270)
0 ['0.041', '0.057']
100 ['0.041', '0.120']
200 ['0.041', '0.024']
300 ['0.041', '0.016']
400 ['0.041', '0.002']
500 ['0.042', '0.032']
600 ['0.041', '0.040']
700 ['0.041', '0.158']
800 ['0.041', '0.060']
900 ['0.041', '0.426']
1000 ['0.041', '0.094']
1100 ['0.042', '0.038']
1200 ['0.042', '0.385']
1300 ['0.041', '0.037']
1400 ['0.042', '0.010']
1500 ['0.041', '0.114']
1600 ['0.041', '0.009']
1700 ['0.042', '0.042']
1800 ['0.041', '0.210']
1900 ['0.041', '0.104']
2000 ['0.041', '0.187']
2100 ['0.041', '0.065']
2200 ['0.042', '0.008']
2300 ['0.041', '0.008']
2400 ['0.042', '0.043']
2500 ['0.041', '0.022']
2600 ['0.041', '0.011']
2700 ['0.041', '0.009']
2800 ['0.041', '0.175']
2900 ['0.042', '0.137']
3000 ['0.042', '0.036']
3100 ['0.041', '0.025']
3200 ['0.042', '0.125']
3300 ['0.041', '0.009']
3400 ['0.042', '0.045']
3500 ['0.042', '0.068']
3600 ['0.041', '0.003']
3700 ['0.042', '0.010']
Train: [4][3750/3750]	loss 0.076 (0.056)	Acc@1 93.750 (97.853)
0 ['0.042', '0.105']
100 ['0.041', '0.007']
200 ['0.041', '0.005']
300 ['0.042', '0.116']
400 ['0.042', '0.018']
500 ['0.042', '0.001']
600 ['0.042', '0.027']
700 ['0.042', '0.085']
800 ['0.042', '0.011']
900 ['0.042', '0.021']
1000 ['0.042', '0.065']
1100 ['0.042', '0.005']
1200 ['0.042', '0.152']
1300 ['0.042', '0.128']
1400 ['0.042', '0.059']
1500 ['0.042', '0.177']
1600 ['0.041', '0.015']
1700 ['0.042', '0.010']
1800 ['0.042', '0.018']
1900 ['0.042', '0.002']
2000 ['0.042', '0.004']
2100 ['0.042', '0.027']
2200 ['0.042', '0.082']
2300 ['0.042', '0.044']
2400 ['0.042', '0.043']
2500 ['0.042', '0.107']
2600 ['0.041', '0.310']
2700 ['0.042', '0.083']
2800 ['0.042', '0.021']
2900 ['0.042', '0.146']
3000 ['0.042', '0.023']
3100 ['0.042', '0.024']
3200 ['0.042', '0.099']
3300 ['0.042', '0.221']
3400 ['0.042', '0.056']
3500 ['0.042', '0.017']
3600 ['0.042', '0.002']
3700 ['0.042', '0.048']
Train: [5][3750/3750]	loss 0.140 (0.051)	Acc@1 93.750 (98.137)
Test model 1 on task 1
Test: [3/3]	loss 0.110 (0.091)	Acc@1 97.179 (97.200)
Test model 1 on task 2
Test: [3/3]	loss 0.088 (0.088)	Acc@1 97.013 (97.090)
############################################################ Avg acc: 97.14
Task 3 Model 1:
0 ['0.053', '3.546']
100 ['0.069', '1.071']
200 ['0.067', '0.151']
300 ['0.066', '0.268']
400 ['0.066', '0.060']
500 ['0.065', '0.293']
600 ['0.065', '0.193']
700 ['0.065', '0.399']
800 ['0.064', '0.216']
900 ['0.065', '0.433']
1000 ['0.066', '0.038']
1100 ['0.065', '0.136']
1200 ['0.064', '0.065']
1300 ['0.065', '0.046']
1400 ['0.064', '0.033']
1500 ['0.064', '0.478']
1600 ['0.066', '0.431']
1700 ['0.066', '0.237']
1800 ['0.064', '0.047']
1900 ['0.064', '0.116']
2000 ['0.065', '0.296']
2100 ['0.065', '0.125']
2200 ['0.065', '0.109']
2300 ['0.065', '0.018']
2400 ['0.065', '0.030']
2500 ['0.065', '0.008']
2600 ['0.065', '0.075']
2700 ['0.065', '0.094']
2800 ['0.065', '0.044']
2900 ['0.065', '0.021']
3000 ['0.065', '0.042']
3100 ['0.065', '0.122']
3200 ['0.065', '0.648']
3300 ['0.065', '0.878']
3400 ['0.066', '0.024']
3500 ['0.066', '0.206']
3600 ['0.065', '0.039']
3700 ['0.066', '0.116']
Train: [1][3750/3750]	loss 0.047 (0.100)	Acc@1 100.000 (92.818)
0 ['0.065', '0.052']
100 ['0.065', '0.042']
200 ['0.065', '0.166']
300 ['0.065', '0.046']
400 ['0.065', '0.049']
500 ['0.065', '0.006']
600 ['0.065', '0.064']
700 ['0.065', '0.030']
800 ['0.065', '0.008']
900 ['0.065', '0.005']
1000 ['0.065', '0.044']
1100 ['0.065', '0.015']
1200 ['0.066', '0.534']
1300 ['0.065', '0.057']
1400 ['0.065', '0.382']
1500 ['0.065', '0.017']
1600 ['0.065', '0.097']
1700 ['0.066', '0.157']
1800 ['0.065', '0.049']
1900 ['0.065', '0.103']
2000 ['0.066', '0.236']
2100 ['0.066', '0.204']
2200 ['0.066', '0.064']
2300 ['0.065', '0.422']
2400 ['0.065', '0.384']
2500 ['0.066', '0.066']
2600 ['0.065', '0.061']
2700 ['0.065', '0.300']
2800 ['0.065', '0.028']
2900 ['0.066', '0.344']
3000 ['0.066', '0.254']
3100 ['0.066', '0.492']
3200 ['0.066', '0.100']
3300 ['0.066', '0.014']
3400 ['0.065', '0.063']
3500 ['0.065', '0.221']
3600 ['0.066', '0.030']
3700 ['0.066', '0.006']
Train: [2][3750/3750]	loss 0.063 (0.060)	Acc@1 93.750 (96.575)
0 ['0.065', '0.089']
100 ['0.065', '0.023']
200 ['0.066', '0.323']
300 ['0.066', '0.021']
400 ['0.066', '0.005']
500 ['0.065', '0.095']
600 ['0.065', '0.057']
700 ['0.066', '0.141']
800 ['0.066', '0.016']
900 ['0.066', '0.078']
1000 ['0.066', '0.040']
1100 ['0.067', '0.457']
1200 ['0.066', '0.032']
1300 ['0.066', '0.026']
1400 ['0.066', '0.029']
1500 ['0.067', '0.030']
1600 ['0.065', '0.038']
1700 ['0.065', '0.020']
1800 ['0.066', '0.059']
1900 ['0.066', '0.081']
2000 ['0.066', '0.064']
2100 ['0.065', '0.048']
2200 ['0.066', '0.085']
2300 ['0.066', '0.024']
2400 ['0.066', '0.003']
2500 ['0.065', '0.013']
2600 ['0.066', '0.014']
2700 ['0.066', '0.042']
2800 ['0.066', '0.006']
2900 ['0.066', '0.004']
3000 ['0.066', '0.007']
3100 ['0.066', '0.075']
3200 ['0.066', '0.244']
3300 ['0.066', '0.212']
3400 ['0.066', '0.117']
3500 ['0.066', '0.012']
3600 ['0.066', '0.051']
3700 ['0.066', '0.163']
Train: [3][3750/3750]	loss 0.028 (0.052)	Acc@1 100.000 (97.315)
0 ['0.066', '0.156']
100 ['0.066', '0.097']
200 ['0.065', '0.121']
300 ['0.066', '0.177']
400 ['0.066', '0.005']
500 ['0.066', '0.076']
600 ['0.066', '0.041']
700 ['0.067', '0.059']
800 ['0.066', '0.045']
900 ['0.067', '0.030']
1000 ['0.066', '0.012']
1100 ['0.066', '0.009']
1200 ['0.066', '0.024']
1300 ['0.066', '0.026']
1400 ['0.066', '0.014']
1500 ['0.066', '0.050']
1600 ['0.067', '0.067']
1700 ['0.066', '0.007']
1800 ['0.066', '0.008']
1900 ['0.066', '0.022']
2000 ['0.065', '0.132']
2100 ['0.066', '0.188']
2200 ['0.066', '0.122']
2300 ['0.066', '0.005']
2400 ['0.066', '0.008']
2500 ['0.066', '0.006']
2600 ['0.065', '0.004']
2700 ['0.066', '0.539']
2800 ['0.066', '0.390']
2900 ['0.066', '0.015']
3000 ['0.066', '0.104']
3100 ['0.066', '0.011']
3200 ['0.066', '0.087']
3300 ['0.066', '0.064']
3400 ['0.066', '0.191']
3500 ['0.066', '0.013']
3600 ['0.067', '0.036']
3700 ['0.066', '0.018']
Train: [4][3750/3750]	loss 0.043 (0.047)	Acc@1 100.000 (97.763)
0 ['0.067', '0.005']
100 ['0.066', '0.129']
200 ['0.067', '0.141']
300 ['0.066', '0.059']
400 ['0.066', '0.116']
500 ['0.066', '0.008']
600 ['0.066', '0.085']
700 ['0.066', '0.340']
800 ['0.066', '0.121']
900 ['0.066', '0.014']
1000 ['0.066', '0.007']
1100 ['0.066', '0.024']
1200 ['0.066', '0.026']
1300 ['0.066', '0.338']
1400 ['0.066', '0.065']
1500 ['0.066', '0.068']
1600 ['0.066', '0.005']
1700 ['0.066', '0.045']
1800 ['0.066', '0.002']
1900 ['0.066', '0.008']
2000 ['0.066', '0.004']
2100 ['0.066', '0.304']
2200 ['0.066', '0.005']
2300 ['0.066', '0.092']
2400 ['0.066', '0.011']
2500 ['0.066', '0.017']
2600 ['0.066', '0.437']
2700 ['0.066', '0.003']
2800 ['0.066', '0.053']
2900 ['0.066', '0.019']
3000 ['0.066', '0.017']
3100 ['0.066', '0.013']
3200 ['0.066', '0.033']
3300 ['0.066', '0.124']
3400 ['0.066', '0.067']
3500 ['0.066', '0.002']
3600 ['0.067', '0.231']
3700 ['0.066', '0.026']
Train: [5][3750/3750]	loss 0.038 (0.044)	Acc@1 100.000 (97.992)
Test model 1 on task 1
Test: [3/3]	loss 0.102 (0.110)	Acc@1 96.847 (96.560)
Test model 1 on task 2
Test: [3/3]	loss 0.116 (0.099)	Acc@1 96.018 (96.770)
Test model 1 on task 3
Test: [3/3]	loss 0.079 (0.082)	Acc@1 97.566 (97.400)
############################################################ Avg acc: 96.91
Task 4 Model 1:
0 ['0.051', '3.501']
100 ['0.076', '0.632']
200 ['0.074', '0.450']
300 ['0.071', '0.555']
400 ['0.070', '0.384']
500 ['0.071', '0.154']
600 ['0.070', '0.905']
700 ['0.070', '0.506']
800 ['0.072', '0.512']
900 ['0.070', '0.198']
1000 ['0.072', '0.265']
1100 ['0.071', '0.680']
1200 ['0.071', '0.294']
1300 ['0.071', '0.124']
1400 ['0.070', '0.135']
1500 ['0.070', '0.034']
1600 ['0.071', '0.089']
1700 ['0.071', '0.488']
1800 ['0.070', '0.603']
1900 ['0.070', '0.353']
2000 ['0.070', '0.006']
2100 ['0.070', '0.145']
2200 ['0.070', '0.068']
2300 ['0.070', '0.345']
2400 ['0.070', '0.115']
2500 ['0.072', '0.186']
2600 ['0.070', '0.110']
2700 ['0.069', '0.208']
2800 ['0.071', '0.122']
2900 ['0.070', '0.029']
3000 ['0.069', '0.058']
3100 ['0.070', '0.055']
3200 ['0.070', '0.024']
3300 ['0.072', '0.287']
3400 ['0.070', '0.045']
3500 ['0.070', '0.042']
3600 ['0.072', '0.364']
3700 ['0.071', '0.039']
Train: [1][3750/3750]	loss 0.023 (0.079)	Acc@1 100.000 (92.422)
0 ['0.070', '0.201']
100 ['0.070', '0.109']
200 ['0.069', '0.021']
300 ['0.069', '0.026']
400 ['0.070', '0.031']
500 ['0.072', '0.155']
600 ['0.071', '0.149']
700 ['0.071', '0.035']
800 ['0.071', '0.548']
900 ['0.071', '0.096']
1000 ['0.070', '0.259']
1100 ['0.070', '0.023']
1200 ['0.070', '0.100']
1300 ['0.070', '0.315']
1400 ['0.071', '0.195']
1500 ['0.071', '0.050']
1600 ['0.070', '0.153']
1700 ['0.070', '0.005']
1800 ['0.071', '0.052']
1900 ['0.070', '0.072']
2000 ['0.071', '0.110']
2100 ['0.071', '0.145']
2200 ['0.071', '0.007']
2300 ['0.071', '0.414']
2400 ['0.070', '0.067']
2500 ['0.071', '0.018']
2600 ['0.071', '0.044']
2700 ['0.071', '0.051']
2800 ['0.071', '0.291']
2900 ['0.070', '0.077']
3000 ['0.072', '0.208']
3100 ['0.072', '0.129']
3200 ['0.070', '0.339']
3300 ['0.071', '0.088']
3400 ['0.072', '0.033']
3500 ['0.071', '0.016']
3600 ['0.070', '0.227']
3700 ['0.070', '0.041']
Train: [2][3750/3750]	loss 0.027 (0.048)	Acc@1 100.000 (96.323)
0 ['0.071', '0.020']
100 ['0.071', '0.065']
200 ['0.071', '0.063']
300 ['0.072', '0.176']
400 ['0.070', '0.253']
500 ['0.070', '0.034']
600 ['0.070', '0.165']
700 ['0.071', '0.112']
800 ['0.071', '0.092']
900 ['0.072', '0.378']
1000 ['0.071', '0.263']
1100 ['0.071', '0.051']
1200 ['0.070', '0.012']
1300 ['0.072', '0.020']
1400 ['0.072', '0.043']
1500 ['0.070', '0.196']
1600 ['0.071', '0.015']
1700 ['0.071', '0.031']
1800 ['0.071', '0.224']
1900 ['0.071', '0.046']
2000 ['0.073', '0.053']
2100 ['0.071', '0.748']
2200 ['0.071', '0.025']
2300 ['0.071', '0.011']
2400 ['0.072', '0.006']
2500 ['0.071', '0.055']
2600 ['0.071', '0.103']
2700 ['0.072', '0.074']
2800 ['0.073', '0.258']
2900 ['0.071', '0.013']
3000 ['0.071', '0.027']
3100 ['0.070', '0.009']
3200 ['0.071', '0.030']
3300 ['0.071', '0.100']
3400 ['0.071', '0.220']
3500 ['0.071', '0.035']
3600 ['0.071', '0.087']
3700 ['0.071', '0.013']
Train: [3][3750/3750]	loss 0.025 (0.041)	Acc@1 100.000 (97.183)
0 ['0.072', '0.116']
100 ['0.071', '0.024']
200 ['0.071', '0.021']
300 ['0.072', '0.037']
400 ['0.071', '0.029']
500 ['0.071', '0.008']
600 ['0.071', '0.053']
700 ['0.071', '0.003']
800 ['0.071', '0.072']
900 ['0.072', '0.044']
1000 ['0.072', '0.172']
1100 ['0.072', '0.038']
1200 ['0.072', '0.010']
1300 ['0.071', '0.047']
1400 ['0.071', '0.063']
1500 ['0.071', '0.049']
1600 ['0.072', '0.030']
1700 ['0.072', '0.021']
1800 ['0.071', '0.059']
1900 ['0.071', '0.064']
2000 ['0.071', '0.030']
2100 ['0.072', '0.293']
2200 ['0.071', '0.019']
2300 ['0.071', '0.067']
2400 ['0.072', '0.027']
2500 ['0.071', '0.037']
2600 ['0.072', '0.090']
2700 ['0.071', '0.031']
2800 ['0.071', '0.015']
2900 ['0.071', '0.019']
3000 ['0.072', '0.067']
3100 ['0.071', '0.035']
3200 ['0.072', '0.057']
3300 ['0.070', '0.016']
3400 ['0.073', '0.011']
3500 ['0.071', '0.071']
3600 ['0.071', '0.149']
3700 ['0.072', '0.031']
Train: [4][3750/3750]	loss 0.074 (0.038)	Acc@1 93.750 (97.663)
0 ['0.071', '0.029']
100 ['0.071', '0.041']
200 ['0.072', '0.051']
300 ['0.071', '0.103']
400 ['0.071', '0.044']
500 ['0.071', '0.050']
600 ['0.072', '0.081']
700 ['0.071', '0.009']
800 ['0.071', '0.038']
900 ['0.070', '0.147']
1000 ['0.072', '0.038']
1100 ['0.071', '0.105']
1200 ['0.071', '0.097']
1300 ['0.072', '0.040']
1400 ['0.071', '0.020']
1500 ['0.072', '0.587']
1600 ['0.071', '0.052']
1700 ['0.071', '0.038']
1800 ['0.072', '0.035']
1900 ['0.072', '0.003']
2000 ['0.072', '0.162']
2100 ['0.071', '0.005']
2200 ['0.072', '0.019']
2300 ['0.072', '0.231']
2400 ['0.072', '0.017']
2500 ['0.072', '0.093']
2600 ['0.071', '0.013']
2700 ['0.072', '0.292']
2800 ['0.072', '0.023']
2900 ['0.071', '0.052']
3000 ['0.071', '0.006']
3100 ['0.071', '0.060']
3200 ['0.071', '0.052']
3300 ['0.072', '0.057']
3400 ['0.071', '0.003']
3500 ['0.071', '0.030']
3600 ['0.072', '0.079']
3700 ['0.072', '0.191']
Train: [5][3750/3750]	loss 0.059 (0.036)	Acc@1 93.750 (97.932)
Test model 1 on task 1
Test: [3/3]	loss 0.125 (0.125)	Acc@1 96.460 (95.960)
Test model 1 on task 2
Test: [3/3]	loss 0.102 (0.110)	Acc@1 96.903 (96.630)
Test model 1 on task 3
Test: [3/3]	loss 0.103 (0.092)	Acc@1 96.571 (97.110)
Test model 1 on task 4
Test: [3/3]	loss 0.094 (0.087)	Acc@1 97.400 (97.320)
############################################################ Avg acc: 96.75
Task 5 Model 1:
0 ['0.058', '4.244']
100 ['0.099', '0.712']
200 ['0.093', '0.116']
300 ['0.090', '0.688']
400 ['0.091', '0.403']
500 ['0.088', '0.284']
600 ['0.087', '0.510']
700 ['0.087', '0.477']
800 ['0.088', '0.588']
900 ['0.087', '0.170']
1000 ['0.088', '0.262']
1100 ['0.086', '0.298']
1200 ['0.087', '0.235']
1300 ['0.087', '0.143']
1400 ['0.089', '0.076']
1500 ['0.086', '0.068']
1600 ['0.087', '0.441']
1700 ['0.085', '0.475']
1800 ['0.087', '0.093']
1900 ['0.087', '0.114']
2000 ['0.087', '0.068']
2100 ['0.087', '0.118']
2200 ['0.087', '0.145']
2300 ['0.087', '0.628']
2400 ['0.087', '0.222']
2500 ['0.086', '0.218']
2600 ['0.086', '0.530']
2700 ['0.086', '0.140']
2800 ['0.089', '0.235']
2900 ['0.086', '0.064']
3000 ['0.086', '0.361']
3100 ['0.087', '0.457']
3200 ['0.086', '0.043']
3300 ['0.085', '0.394']
3400 ['0.085', '0.385']
3500 ['0.086', '0.134']
3600 ['0.086', '0.023']
3700 ['0.086', '0.276']
Train: [1][3750/3750]	loss 0.078 (0.071)	Acc@1 93.750 (91.700)
0 ['0.086', '0.261']
100 ['0.086', '0.471']
200 ['0.085', '0.312']
300 ['0.086', '0.064']
400 ['0.087', '0.021']
500 ['0.085', '0.062']
600 ['0.087', '0.011']
700 ['0.085', '0.109']
800 ['0.085', '0.246']
900 ['0.087', '0.429']
1000 ['0.085', '0.195']
1100 ['0.087', '0.131']
1200 ['0.086', '0.014']
1300 ['0.086', '0.083']
1400 ['0.089', '0.113']
1500 ['0.086', '0.055']
1600 ['0.086', '0.052']
1700 ['0.087', '0.384']
1800 ['0.086', '0.038']
1900 ['0.087', '0.136']
2000 ['0.088', '0.032']
2100 ['0.087', '0.094']
2200 ['0.087', '0.329']
2300 ['0.087', '0.033']
2400 ['0.086', '0.282']
2500 ['0.087', '0.205']
2600 ['0.085', '0.006']
2700 ['0.087', '0.060']
2800 ['0.087', '0.209']
2900 ['0.085', '0.038']
3000 ['0.085', '0.152']
3100 ['0.086', '0.077']
3200 ['0.086', '0.156']
3300 ['0.087', '0.037']
3400 ['0.086', '0.028']
3500 ['0.087', '0.015']
3600 ['0.086', '0.033']
3700 ['0.086', '0.066']
Train: [2][3750/3750]	loss 0.027 (0.044)	Acc@1 100.000 (96.002)
0 ['0.087', '0.185']
100 ['0.085', '0.025']
200 ['0.086', '0.016']
300 ['0.086', '0.221']
400 ['0.086', '0.015']
500 ['0.086', '0.045']
600 ['0.086', '0.045']
700 ['0.086', '0.074']
800 ['0.086', '0.051']
900 ['0.088', '0.016']
1000 ['0.086', '0.087']
1100 ['0.086', '0.016']
1200 ['0.087', '0.042']
1300 ['0.086', '0.005']
1400 ['0.087', '0.194']
1500 ['0.087', '0.099']
1600 ['0.087', '0.068']
1700 ['0.088', '0.173']
1800 ['0.089', '0.037']
1900 ['0.086', '0.045']
2000 ['0.086', '0.024']
2100 ['0.086', '0.136']
2200 ['0.088', '0.087']
2300 ['0.086', '0.528']
2400 ['0.086', '0.139']
2500 ['0.087', '0.291']
2600 ['0.087', '0.201']
2700 ['0.086', '0.103']
2800 ['0.087', '0.231']
2900 ['0.087', '0.131']
3000 ['0.087', '0.038']
3100 ['0.087', '0.318']
3200 ['0.087', '0.062']
3300 ['0.086', '0.051']
3400 ['0.087', '0.016']
3500 ['0.087', '0.076']
3600 ['0.087', '0.007']
3700 ['0.087', '0.075']
Train: [3][3750/3750]	loss 0.026 (0.039)	Acc@1 100.000 (96.860)
0 ['0.086', '0.109']
100 ['0.085', '0.054']
200 ['0.087', '0.103']
300 ['0.086', '0.021']
400 ['0.086', '0.009']
500 ['0.086', '0.018']
600 ['0.086', '0.016']
700 ['0.087', '0.186']
800 ['0.087', '0.075']
900 ['0.086', '0.029']
1000 ['0.086', '0.629']
1100 ['0.086', '0.015']
1200 ['0.086', '0.025']
1300 ['0.087', '0.013']
1400 ['0.087', '0.063']
1500 ['0.087', '0.013']
1600 ['0.086', '0.044']
1700 ['0.086', '0.080']
1800 ['0.087', '0.016']
1900 ['0.086', '0.006']
2000 ['0.091', '0.039']
2100 ['0.087', '0.059']
2200 ['0.086', '0.027']
2300 ['0.086', '0.139']
2400 ['0.087', '0.062']
2500 ['0.087', '0.003']
2600 ['0.089', '0.043']
2700 ['0.086', '0.090']
2800 ['0.086', '0.013']
2900 ['0.087', '0.056']
3000 ['0.087', '0.119']
3100 ['0.087', '0.179']
3200 ['0.087', '0.015']
3300 ['0.088', '0.479']
3400 ['0.087', '0.122']
3500 ['0.087', '0.154']
3600 ['0.087', '0.006']
3700 ['0.086', '0.227']
Train: [4][3750/3750]	loss 0.027 (0.036)	Acc@1 100.000 (97.288)
0 ['0.087', '0.201']
100 ['0.087', '0.126']
200 ['0.087', '0.030']
300 ['0.086', '0.032']
400 ['0.086', '0.026']
500 ['0.087', '0.076']
600 ['0.086', '0.007']
700 ['0.087', '0.003']
800 ['0.087', '0.144']
900 ['0.087', '0.085']
1000 ['0.088', '0.100']
1100 ['0.087', '0.081']
1200 ['0.086', '0.293']
1300 ['0.086', '0.055']
1400 ['0.088', '0.104']
1500 ['0.087', '0.047']
1600 ['0.087', '0.041']
1700 ['0.087', '0.083']
1800 ['0.086', '0.072']
1900 ['0.087', '0.201']
2000 ['0.087', '0.146']
2100 ['0.088', '0.064']
2200 ['0.088', '0.216']
2300 ['0.088', '0.034']
2400 ['0.088', '0.026']
2500 ['0.087', '0.026']
2600 ['0.086', '0.103']
2700 ['0.087', '0.118']
2800 ['0.087', '0.018']
2900 ['0.087', '0.256']
3000 ['0.087', '0.288']
3100 ['0.087', '0.011']
3200 ['0.086', '0.010']
3300 ['0.087', '0.014']
3400 ['0.087', '0.096']
3500 ['0.086', '0.178']
3600 ['0.087', '0.022']
3700 ['0.087', '0.032']
Train: [5][3750/3750]	loss 0.067 (0.034)	Acc@1 93.750 (97.560)
Test model 1 on task 1
Test: [3/3]	loss 0.141 (0.145)	Acc@1 94.856 (95.130)
Test model 1 on task 2
Test: [3/3]	loss 0.111 (0.121)	Acc@1 96.294 (96.120)
Test model 1 on task 3
Test: [3/3]	loss 0.106 (0.104)	Acc@1 96.239 (96.700)
Test model 1 on task 4
Test: [3/3]	loss 0.079 (0.097)	Acc@1 97.400 (96.970)
Test model 1 on task 5
Test: [3/3]	loss 0.089 (0.091)	Acc@1 97.235 (97.280)
############################################################ Avg acc: 96.44
Task 6 Model 1:
0 ['0.071', '4.843']
100 ['0.119', '0.954']
200 ['0.120', '0.493']
300 ['0.115', '0.260']
400 ['0.115', '0.567']
500 ['0.109', '0.095']
600 ['0.112', '0.454']
700 ['0.116', '0.239']
800 ['0.112', '0.244']
900 ['0.111', '0.452']
1000 ['0.112', '0.888']
1100 ['0.110', '0.618']
1200 ['0.108', '0.172']
1300 ['0.109', '0.155']
1400 ['0.110', '0.015']
1500 ['0.110', '0.384']
1600 ['0.109', '0.041']
1700 ['0.110', '0.154']
1800 ['0.109', '0.453']
1900 ['0.109', '0.158']
2000 ['0.108', '0.142']
2100 ['0.112', '0.241']
2200 ['0.108', '0.179']
2300 ['0.108', '0.028']
2400 ['0.108', '0.189']
2500 ['0.107', '0.066']
2600 ['0.108', '0.114']
2700 ['0.108', '0.090']
2800 ['0.109', '0.023']
2900 ['0.108', '0.211']
3000 ['0.107', '0.038']
3100 ['0.108', '0.235']
3200 ['0.108', '0.035']
3300 ['0.109', '0.065']
3400 ['0.108', '0.203']
3500 ['0.109', '0.086']
3600 ['0.108', '0.082']
3700 ['0.109', '0.023']
Train: [1][3750/3750]	loss 0.042 (0.065)	Acc@1 93.750 (91.310)
0 ['0.107', '0.191']
100 ['0.107', '0.176']
200 ['0.106', '0.219']
300 ['0.108', '0.063']
400 ['0.108', '0.110']
500 ['0.106', '0.030']
600 ['0.106', '0.194']
700 ['0.107', '0.064']
800 ['0.106', '0.044']
900 ['0.107', '0.345']
1000 ['0.107', '0.058']
1100 ['0.107', '0.059']
1200 ['0.107', '0.236']
1300 ['0.107', '0.327']
1400 ['0.107', '0.361']
1500 ['0.109', '0.038']
1600 ['0.106', '0.018']
1700 ['0.106', '0.256']
1800 ['0.107', '0.059']
1900 ['0.108', '0.451']
2000 ['0.108', '0.185']
2100 ['0.107', '0.451']
2200 ['0.107', '0.048']
2300 ['0.108', '0.025']
2400 ['0.107', '0.362']
2500 ['0.110', '0.037']
2600 ['0.108', '0.081']
2700 ['0.108', '0.035']
2800 ['0.105', '0.046']
2900 ['0.107', '0.009']
3000 ['0.106', '0.076']
3100 ['0.108', '0.162']
3200 ['0.107', '0.037']
3300 ['0.107', '0.129']
3400 ['0.106', '0.139']
3500 ['0.108', '0.183']
3600 ['0.107', '0.016']
3700 ['0.107', '0.040']
Train: [2][3750/3750]	loss 0.026 (0.042)	Acc@1 100.000 (95.707)
0 ['0.107', '0.303']
100 ['0.106', '0.013']
200 ['0.107', '0.226']
300 ['0.108', '0.047']
400 ['0.106', '0.135']
500 ['0.106', '0.242']
600 ['0.107', '0.061']
700 ['0.108', '0.033']
800 ['0.106', '0.038']
900 ['0.106', '0.023']
1000 ['0.106', '0.073']
1100 ['0.106', '0.136']
1200 ['0.107', '0.187']
1300 ['0.106', '0.035']
1400 ['0.106', '0.132']
1500 ['0.106', '0.132']
1600 ['0.107', '0.234']
1700 ['0.107', '0.110']
1800 ['0.107', '0.054']
1900 ['0.108', '0.074']
2000 ['0.107', '0.048']
2100 ['0.110', '0.045']
2200 ['0.109', '0.042']
2300 ['0.106', '0.255']
2400 ['0.106', '0.008']
2500 ['0.106', '0.064']
2600 ['0.107', '0.035']
2700 ['0.107', '0.062']
2800 ['0.107', '0.013']
2900 ['0.106', '0.028']
3000 ['0.107', '0.050']
3100 ['0.107', '0.223']
3200 ['0.107', '0.084']
3300 ['0.106', '0.034']
3400 ['0.108', '0.229']
3500 ['0.107', '0.016']
3600 ['0.107', '0.270']
3700 ['0.107', '0.053']
Train: [3][3750/3750]	loss 0.024 (0.037)	Acc@1 100.000 (96.548)
0 ['0.106', '0.179']
100 ['0.107', '0.148']
200 ['0.106', '0.059']
300 ['0.106', '0.340']
400 ['0.106', '0.179']
500 ['0.107', '0.015']
600 ['0.106', '0.015']
700 ['0.108', '0.028']
800 ['0.106', '0.261']
900 ['0.107', '0.038']
1000 ['0.106', '0.021']
1100 ['0.108', '0.011']
1200 ['0.106', '0.044']
1300 ['0.106', '0.008']
1400 ['0.106', '0.058']
1500 ['0.107', '0.123']
1600 ['0.106', '0.073']
1700 ['0.108', '0.017']
1800 ['0.106', '0.017']
1900 ['0.106', '0.131']
2000 ['0.107', '0.174']
2100 ['0.107', '0.041']
2200 ['0.108', '0.044']
2300 ['0.106', '0.012']
2400 ['0.108', '0.237']
2500 ['0.108', '0.041']
2600 ['0.107', '0.033']
2700 ['0.107', '0.355']
2800 ['0.106', '0.068']
2900 ['0.107', '0.097']
3000 ['0.107', '0.036']
3100 ['0.108', '0.159']
3200 ['0.107', '0.056']
3300 ['0.108', '0.111']
3400 ['0.107', '0.037']
3500 ['0.108', '0.017']
3600 ['0.107', '0.151']
3700 ['0.108', '0.065']
Train: [4][3750/3750]	loss 0.022 (0.035)	Acc@1 100.000 (96.923)
0 ['0.107', '0.028']
100 ['0.107', '0.024']
200 ['0.106', '0.309']
300 ['0.107', '0.046']
400 ['0.106', '0.150']
500 ['0.106', '0.091']
600 ['0.109', '0.465']
700 ['0.109', '0.043']
800 ['0.106', '0.061']
900 ['0.106', '0.016']
1000 ['0.107', '0.006']
1100 ['0.107', '0.098']
1200 ['0.107', '0.020']
1300 ['0.107', '0.202']
1400 ['0.106', '0.026']
1500 ['0.106', '0.121']
1600 ['0.107', '0.079']
1700 ['0.107', '0.079']
1800 ['0.107', '0.098']
1900 ['0.106', '0.014']
2000 ['0.107', '0.052']
2100 ['0.107', '0.214']
2200 ['0.106', '0.261']
2300 ['0.107', '0.010']
2400 ['0.107', '0.139']
2500 ['0.107', '0.218']
2600 ['0.107', '0.012']
2700 ['0.108', '0.372']
2800 ['0.106', '0.145']
2900 ['0.107', '0.033']
3000 ['0.107', '0.058']
3100 ['0.108', '0.015']
3200 ['0.106', '0.099']
3300 ['0.107', '0.042']
3400 ['0.107', '0.071']
3500 ['0.106', '0.035']
3600 ['0.107', '0.354']
3700 ['0.106', '0.002']
Train: [5][3750/3750]	loss 0.020 (0.033)	Acc@1 100.000 (97.257)
Test model 1 on task 1
Test: [3/3]	loss 0.174 (0.162)	Acc@1 94.469 (94.550)
Test model 1 on task 2
Test: [3/3]	loss 0.108 (0.127)	Acc@1 96.294 (96.040)
Test model 1 on task 3
Test: [3/3]	loss 0.100 (0.112)	Acc@1 97.124 (96.480)
Test model 1 on task 4
Test: [3/3]	loss 0.116 (0.109)	Acc@1 96.128 (96.550)
Test model 1 on task 5
Test: [3/3]	loss 0.114 (0.099)	Acc@1 96.571 (97.040)
Test model 1 on task 6
Test: [3/3]	loss 0.096 (0.105)	Acc@1 97.069 (96.770)
############################################################ Avg acc: 96.24
Task 7 Model 1:
0 ['0.085', '2.977']
100 ['0.136', '1.366']
200 ['0.135', '0.543']
300 ['0.132', '0.680']
400 ['0.134', '0.386']
500 ['0.134', '0.201']
600 ['0.133', '0.648']
700 ['0.131', '0.176']
800 ['0.130', '0.206']
900 ['0.133', '0.098']
1000 ['0.137', '0.139']
1100 ['0.135', '0.302']
1200 ['0.131', '0.081']
1300 ['0.132', '0.022']
1400 ['0.132', '0.743']
1500 ['0.130', '0.233']
1600 ['0.134', '0.203']
1700 ['0.130', '0.209']
1800 ['0.133', '0.306']
1900 ['0.129', '0.130']
2000 ['0.131', '0.131']
2100 ['0.132', '0.067']
2200 ['0.131', '0.590']
2300 ['0.130', '0.467']
2400 ['0.133', '0.060']
2500 ['0.130', '0.060']
2600 ['0.131', '0.151']
2700 ['0.130', '0.489']
2800 ['0.130', '0.074']
2900 ['0.131', '0.025']
3000 ['0.131', '0.301']
3100 ['0.131', '0.151']
3200 ['0.132', '0.074']
3300 ['0.130', '0.364']
3400 ['0.129', '0.124']
3500 ['0.129', '0.451']
3600 ['0.131', '0.672']
3700 ['0.130', '0.151']
Train: [1][3750/3750]	loss 0.041 (0.060)	Acc@1 93.750 (91.090)
0 ['0.129', '0.250']
100 ['0.130', '0.101']
200 ['0.129', '0.045']
300 ['0.129', '0.030']
400 ['0.130', '0.035']
500 ['0.130', '0.059']
600 ['0.131', '0.074']
700 ['0.130', '0.038']
800 ['0.128', '0.113']
900 ['0.131', '0.239']
1000 ['0.131', '0.149']
1100 ['0.131', '0.050']
1200 ['0.129', '0.097']
1300 ['0.129', '0.364']
1400 ['0.130', '0.109']
1500 ['0.128', '0.291']
1600 ['0.130', '0.150']
1700 ['0.131', '0.077']
1800 ['0.129', '0.410']
1900 ['0.128', '0.020']
2000 ['0.133', '0.070']
2100 ['0.129', '0.095']
2200 ['0.130', '0.506']
2300 ['0.129', '0.086']
2400 ['0.129', '0.062']
2500 ['0.130', '0.218']
2600 ['0.130', '0.025']
2700 ['0.129', '0.228']
2800 ['0.128', '0.657']
2900 ['0.130', '0.836']
3000 ['0.129', '0.014']
3100 ['0.129', '0.024']
3200 ['0.129', '0.079']
3300 ['0.129', '0.050']
3400 ['0.130', '0.131']
3500 ['0.129', '0.362']
3600 ['0.130', '0.602']
3700 ['0.129', '0.126']
Train: [2][3750/3750]	loss 0.027 (0.040)	Acc@1 100.000 (95.592)
0 ['0.129', '0.084']
100 ['0.131', '0.020']
200 ['0.129', '0.079']
300 ['0.128', '0.078']
400 ['0.128', '0.086']
500 ['0.129', '0.052']
600 ['0.129', '0.103']
700 ['0.129', '0.042']
800 ['0.130', '0.059']
900 ['0.129', '0.270']
1000 ['0.129', '0.085']
1100 ['0.129', '0.127']
1200 ['0.129', '0.066']
1300 ['0.129', '0.090']
1400 ['0.130', '0.110']
1500 ['0.131', '0.122']
1600 ['0.129', '0.141']
1700 ['0.129', '0.055']
1800 ['0.129', '0.007']
1900 ['0.129', '0.044']
2000 ['0.130', '0.312']
2100 ['0.129', '0.322']
2200 ['0.128', '0.063']
2300 ['0.129', '0.057']
2400 ['0.130', '0.085']
2500 ['0.129', '0.084']
2600 ['0.129', '0.015']
2700 ['0.131', '0.203']
2800 ['0.130', '0.185']
2900 ['0.129', '0.214']
3000 ['0.129', '0.017']
3100 ['0.130', '0.179']
3200 ['0.129', '0.042']
3300 ['0.128', '0.357']
3400 ['0.128', '0.118']
3500 ['0.129', '0.066']
3600 ['0.129', '0.023']
3700 ['0.131', '0.498']
Train: [3][3750/3750]	loss 0.023 (0.036)	Acc@1 100.000 (96.367)
0 ['0.129', '0.162']
100 ['0.128', '0.065']
200 ['0.129', '0.139']
300 ['0.129', '0.066']
400 ['0.129', '0.072']
500 ['0.129', '0.305']
600 ['0.128', '0.023']
700 ['0.128', '0.094']
800 ['0.129', '0.111']
900 ['0.129', '0.085']
1000 ['0.129', '0.035']
1100 ['0.129', '0.033']
1200 ['0.128', '0.243']
1300 ['0.131', '0.027']
1400 ['0.129', '0.208']
1500 ['0.130', '0.559']
1600 ['0.130', '0.122']
1700 ['0.131', '0.260']
1800 ['0.129', '0.045']
1900 ['0.130', '0.186']
2000 ['0.128', '0.055']
2100 ['0.128', '0.321']
2200 ['0.129', '0.103']
2300 ['0.132', '0.129']
2400 ['0.128', '0.286']
2500 ['0.129', '0.148']
2600 ['0.129', '0.174']
2700 ['0.129', '0.234']
2800 ['0.129', '0.090']
2900 ['0.129', '0.040']
3000 ['0.129', '0.033']
3100 ['0.129', '0.137']
3200 ['0.129', '0.346']
3300 ['0.130', '0.617']
3400 ['0.129', '0.209']
3500 ['0.129', '0.018']
3600 ['0.129', '0.482']
3700 ['0.130', '0.039']
Train: [4][3750/3750]	loss 0.056 (0.034)	Acc@1 87.500 (96.778)
0 ['0.129', '0.008']
100 ['0.129', '0.078']
200 ['0.129', '0.115']
300 ['0.129', '0.108']
400 ['0.129', '0.059']
500 ['0.131', '0.069']
600 ['0.129', '0.098']
700 ['0.130', '0.133']
800 ['0.128', '0.050']
900 ['0.129', '0.031']
1000 ['0.129', '0.071']
1100 ['0.128', '0.044']
1200 ['0.129', '0.224']
1300 ['0.128', '0.059']
1400 ['0.129', '0.544']
1500 ['0.130', '0.403']
1600 ['0.128', '0.533']
1700 ['0.128', '0.015']
1800 ['0.130', '0.092']
1900 ['0.130', '0.137']
2000 ['0.129', '0.159']
2100 ['0.129', '0.026']
2200 ['0.129', '0.106']
2300 ['0.129', '0.167']
2400 ['0.129', '0.088']
2500 ['0.129', '0.248']
2600 ['0.130', '0.032']
2700 ['0.129', '0.402']
2800 ['0.129', '0.087']
2900 ['0.130', '0.007']
3000 ['0.129', '0.017']
3100 ['0.129', '0.082']
3200 ['0.128', '0.076']
3300 ['0.129', '0.101']
3400 ['0.129', '0.165']
3500 ['0.129', '0.052']
3600 ['0.128', '0.075']
3700 ['0.131', '0.059']
Train: [5][3750/3750]	loss 0.026 (0.033)	Acc@1 100.000 (97.045)
Test model 1 on task 1
Test: [3/3]	loss 0.202 (0.175)	Acc@1 93.639 (94.230)
Test model 1 on task 2
Test: [3/3]	loss 0.127 (0.138)	Acc@1 95.907 (95.740)
Test model 1 on task 3
Test: [3/3]	loss 0.120 (0.121)	Acc@1 96.350 (96.140)
Test model 1 on task 4
Test: [3/3]	loss 0.117 (0.118)	Acc@1 96.515 (96.270)
Test model 1 on task 5
Test: [3/3]	loss 0.103 (0.108)	Acc@1 96.958 (96.830)
Test model 1 on task 6
Test: [3/3]	loss 0.111 (0.112)	Acc@1 96.792 (96.560)
Test model 1 on task 7
Test: [3/3]	loss 0.112 (0.114)	Acc@1 96.239 (96.390)
############################################################ Avg acc: 96.02
Task 8 Model 1:
0 ['0.097', '3.563']
100 ['0.159', '1.126']
200 ['0.161', '0.425']
300 ['0.162', '0.528']
400 ['0.157', '0.358']
500 ['0.158', '0.198']
600 ['0.155', '0.645']
700 ['0.158', '0.468']
800 ['0.162', '0.088']
900 ['0.158', '0.125']
1000 ['0.156', '0.314']
1100 ['0.156', '0.127']
1200 ['0.157', '0.074']
1300 ['0.155', '0.111']
1400 ['0.156', '0.104']
1500 ['0.157', '0.261']
1600 ['0.158', '0.527']
1700 ['0.155', '0.079']
1800 ['0.156', '0.305']
1900 ['0.153', '0.065']
2000 ['0.155', '0.462']
2100 ['0.154', '0.615']
2200 ['0.154', '0.270']
2300 ['0.154', '0.317']
2400 ['0.156', '0.182']
2500 ['0.157', '0.260']
2600 ['0.154', '0.081']
2700 ['0.153', '0.129']
2800 ['0.156', '0.117']
2900 ['0.153', '0.192']
3000 ['0.154', '0.033']
3100 ['0.156', '0.119']
3200 ['0.154', '0.283']
3300 ['0.155', '0.119']
3400 ['0.154', '0.395']
3500 ['0.154', '0.168']
3600 ['0.158', '0.202']
3700 ['0.155', '0.104']
Train: [1][3750/3750]	loss 0.094 (0.059)	Acc@1 87.500 (90.320)
0 ['0.154', '0.085']
100 ['0.154', '0.077']
200 ['0.154', '0.139']
300 ['0.155', '0.020']
400 ['0.153', '0.407']
500 ['0.153', '0.042']
600 ['0.154', '0.205']
700 ['0.153', '0.242']
800 ['0.157', '0.235']
900 ['0.153', '0.066']
1000 ['0.153', '0.086']
1100 ['0.153', '0.081']
1200 ['0.153', '0.340']
1300 ['0.154', '0.167']
1400 ['0.154', '0.048']
1500 ['0.154', '0.064']
1600 ['0.153', '0.072']
1700 ['0.152', '0.239']
1800 ['0.154', '0.035']
1900 ['0.153', '0.010']
2000 ['0.155', '0.108']
2100 ['0.153', '0.078']
2200 ['0.155', '0.076']
2300 ['0.154', '0.029']
2400 ['0.153', '0.190']
2500 ['0.155', '0.150']
2600 ['0.154', '0.333']
2700 ['0.154', '0.058']
2800 ['0.152', '0.111']
2900 ['0.153', '0.243']
3000 ['0.153', '0.024']
3100 ['0.154', '0.122']
3200 ['0.153', '0.489']
3300 ['0.153', '0.284']
3400 ['0.154', '0.080']
3500 ['0.156', '0.210']
3600 ['0.153', '0.093']
3700 ['0.156', '0.065']
Train: [2][3750/3750]	loss 0.025 (0.040)	Acc@1 100.000 (95.193)
0 ['0.153', '0.015']
100 ['0.154', '0.032']
200 ['0.154', '0.318']
300 ['0.154', '0.104']
400 ['0.154', '0.080']
500 ['0.153', '0.120']
600 ['0.153', '0.099']
700 ['0.153', '0.029']
800 ['0.152', '0.081']
900 ['0.153', '0.165']
1000 ['0.152', '0.009']
1100 ['0.154', '0.299']
1200 ['0.151', '0.117']
1300 ['0.152', '0.083']
1400 ['0.154', '0.132']
1500 ['0.154', '0.060']
1600 ['0.153', '0.027']
1700 ['0.154', '0.611']
1800 ['0.153', '0.087']
1900 ['0.156', '0.098']
2000 ['0.155', '0.479']
2100 ['0.153', '0.196']
2200 ['0.153', '0.037']
2300 ['0.154', '0.075']
2400 ['0.154', '0.055']
2500 ['0.153', '0.092']
2600 ['0.154', '0.036']
2700 ['0.152', '0.118']
2800 ['0.152', '0.251']
2900 ['0.153', '0.074']
3000 ['0.153', '0.281']
3100 ['0.154', '0.045']
3200 ['0.152', '0.182']
3300 ['0.155', '0.051']
3400 ['0.152', '0.034']
3500 ['0.153', '0.101']
3600 ['0.152', '0.057']
3700 ['0.154', '0.122']
Train: [3][3750/3750]	loss 0.041 (0.036)	Acc@1 93.750 (96.113)
0 ['0.153', '0.196']
100 ['0.152', '0.058']
200 ['0.153', '0.021']
300 ['0.154', '0.493']
400 ['0.153', '0.568']
500 ['0.152', '0.047']
600 ['0.153', '0.033']
700 ['0.153', '0.049']
800 ['0.152', '0.009']
900 ['0.152', '0.102']
1000 ['0.152', '0.309']
1100 ['0.153', '0.046']
1200 ['0.152', '0.018']
1300 ['0.153', '0.111']
1400 ['0.153', '0.238']
1500 ['0.154', '0.218']
1600 ['0.154', '0.652']
1700 ['0.152', '0.085']
1800 ['0.153', '0.563']
1900 ['0.153', '0.232']
2000 ['0.152', '0.185']
2100 ['0.151', '0.515']
2200 ['0.153', '0.103']
2300 ['0.154', '0.016']
2400 ['0.153', '0.056']
2500 ['0.153', '0.095']
2600 ['0.152', '0.048']
2700 ['0.153', '0.172']
2800 ['0.153', '0.024']
2900 ['0.154', '0.008']
3000 ['0.155', '0.319']
3100 ['0.154', '0.073']
3200 ['0.153', '0.073']
3300 ['0.154', '0.122']
3400 ['0.154', '0.025']
3500 ['0.153', '0.125']
3600 ['0.152', '0.115']
3700 ['0.152', '0.029']
Train: [4][3750/3750]	loss 0.029 (0.034)	Acc@1 100.000 (96.517)
0 ['0.153', '0.291']
100 ['0.153', '0.038']
200 ['0.152', '0.019']
300 ['0.152', '0.027']
400 ['0.153', '0.059']
500 ['0.153', '0.148']
600 ['0.154', '0.042']
700 ['0.152', '0.007']
800 ['0.152', '0.255']
900 ['0.153', '0.054']
1000 ['0.155', '0.150']
1100 ['0.152', '0.013']
1200 ['0.152', '0.117']
1300 ['0.153', '0.056']
1400 ['0.153', '0.235']
1500 ['0.152', '0.104']
1600 ['0.153', '0.399']
1700 ['0.152', '0.408']
1800 ['0.153', '0.228']
1900 ['0.153', '0.088']
2000 ['0.153', '0.698']
2100 ['0.153', '0.096']
2200 ['0.152', '0.119']
2300 ['0.154', '0.098']
2400 ['0.154', '0.192']
2500 ['0.154', '0.113']
2600 ['0.152', '0.026']
2700 ['0.152', '0.119']
2800 ['0.153', '0.088']
2900 ['0.152', '0.294']
3000 ['0.153', '0.132']
3100 ['0.153', '0.029']
3200 ['0.154', '0.035']
3300 ['0.152', '0.031']
3400 ['0.152', '0.094']
3500 ['0.153', '0.182']
3600 ['0.152', '0.159']
3700 ['0.152', '0.274']
Train: [5][3750/3750]	loss 0.054 (0.033)	Acc@1 93.750 (96.828)
Test model 1 on task 1
Test: [3/3]	loss 0.175 (0.194)	Acc@1 94.137 (93.700)
Test model 1 on task 2
Test: [3/3]	loss 0.160 (0.144)	Acc@1 95.022 (95.520)
Test model 1 on task 3
Test: [3/3]	loss 0.128 (0.131)	Acc@1 95.962 (95.880)
Test model 1 on task 4
Test: [3/3]	loss 0.124 (0.126)	Acc@1 95.796 (96.010)
Test model 1 on task 5
Test: [3/3]	loss 0.114 (0.118)	Acc@1 96.460 (96.370)
Test model 1 on task 6
Test: [3/3]	loss 0.114 (0.118)	Acc@1 96.515 (96.360)
Test model 1 on task 7
Test: [3/3]	loss 0.125 (0.123)	Acc@1 96.515 (96.150)
Test model 1 on task 8
Test: [3/3]	loss 0.123 (0.119)	Acc@1 96.626 (96.570)
############################################################ Avg acc: 95.82
Task 9 Model 1:
0 ['0.105', '3.828']
100 ['0.182', '1.228']
200 ['0.183', '0.280']
300 ['0.183', '0.166']
400 ['0.183', '0.595']
500 ['0.182', '0.567']
600 ['0.184', '0.611']
700 ['0.185', '0.563']
800 ['0.181', '0.249']
900 ['0.183', '0.257']
1000 ['0.181', '0.216']
1100 ['0.182', '0.413']
1200 ['0.181', '0.216']
1300 ['0.183', '0.059']
1400 ['0.182', '0.103']
1500 ['0.181', '0.348']
1600 ['0.184', '0.122']
1700 ['0.181', '0.398']
1800 ['0.182', '0.149']
1900 ['0.180', '0.662']
2000 ['0.178', '0.405']
2100 ['0.181', '0.597']
2200 ['0.183', '0.028']
2300 ['0.180', '0.058']
2400 ['0.180', '0.108']
2500 ['0.180', '0.088']
2600 ['0.178', '0.116']
2700 ['0.178', '0.117']
2800 ['0.179', '0.280']
2900 ['0.179', '0.074']
3000 ['0.182', '0.019']
3100 ['0.180', '0.605']
3200 ['0.180', '0.573']
3300 ['0.178', '0.151']
3400 ['0.179', '0.173']
3500 ['0.182', '0.134']
3600 ['0.183', '0.793']
3700 ['0.180', '0.298']
Train: [1][3750/3750]	loss 0.034 (0.057)	Acc@1 100.000 (89.793)
0 ['0.180', '0.346']
100 ['0.180', '0.080']
200 ['0.178', '0.242']
300 ['0.179', '0.201']
400 ['0.178', '0.091']
500 ['0.179', '0.490']
600 ['0.178', '0.214']
700 ['0.179', '0.195']
800 ['0.180', '0.084']
900 ['0.179', '0.335']
1000 ['0.182', '0.124']
1100 ['0.179', '0.230']
1200 ['0.181', '0.324']
1300 ['0.179', '0.178']
1400 ['0.180', '0.238']
1500 ['0.178', '0.134']
1600 ['0.178', '0.302']
1700 ['0.178', '0.141']
1800 ['0.178', '0.324']
1900 ['0.177', '0.183']
2000 ['0.177', '0.249']
2100 ['0.176', '0.122']
2200 ['0.179', '0.071']
2300 ['0.179', '0.086']
2400 ['0.178', '0.290']
2500 ['0.176', '0.070']
2600 ['0.178', '0.125']
2700 ['0.177', '0.654']
2800 ['0.176', '0.087']
2900 ['0.177', '0.149']
3000 ['0.178', '0.263']
3100 ['0.177', '0.076']
3200 ['0.177', '0.224']
3300 ['0.177', '0.173']
3400 ['0.178', '0.014']
3500 ['0.177', '0.102']
3600 ['0.177', '0.223']
3700 ['0.176', '0.177']
Train: [2][3750/3750]	loss 0.058 (0.040)	Acc@1 87.500 (94.655)
0 ['0.177', '0.149']
100 ['0.179', '0.099']
200 ['0.176', '0.121']
300 ['0.177', '0.026']
400 ['0.177', '0.078']
500 ['0.176', '0.059']
600 ['0.176', '0.097']
700 ['0.177', '0.062']
800 ['0.176', '0.088']
900 ['0.177', '0.065']
1000 ['0.178', '0.282']
1100 ['0.175', '0.036']
1200 ['0.177', '0.243']
1300 ['0.176', '0.205']
1400 ['0.178', '0.224']
1500 ['0.178', '0.158']
1600 ['0.176', '0.115']
1700 ['0.176', '0.341']
1800 ['0.176', '0.299']
1900 ['0.177', '0.064']
2000 ['0.177', '0.060']
2100 ['0.177', '0.355']
2200 ['0.177', '0.416']
2300 ['0.180', '0.033']
2400 ['0.180', '0.218']
2500 ['0.176', '0.468']
2600 ['0.178', '0.139']
2700 ['0.177', '0.071']
2800 ['0.177', '0.026']
2900 ['0.177', '0.026']
3000 ['0.177', '0.041']
3100 ['0.177', '0.202']
3200 ['0.176', '0.019']
3300 ['0.176', '0.094']
3400 ['0.179', '0.039']
3500 ['0.176', '0.256']
3600 ['0.177', '0.086']
3700 ['0.177', '0.169']
Train: [3][3750/3750]	loss 0.027 (0.037)	Acc@1 100.000 (95.505)
0 ['0.176', '0.135']
100 ['0.175', '0.329']
200 ['0.178', '0.055']
300 ['0.177', '0.062']
400 ['0.175', '0.020']
500 ['0.177', '0.251']
600 ['0.177', '0.060']
700 ['0.178', '0.074']
800 ['0.177', '0.091']
900 ['0.180', '0.211']
1000 ['0.176', '0.049']
1100 ['0.176', '0.154']
1200 ['0.177', '0.042']
1300 ['0.177', '0.066']
1400 ['0.177', '0.178']
1500 ['0.176', '0.204']
1600 ['0.177', '0.170']
1700 ['0.177', '0.257']
1800 ['0.176', '0.067']
1900 ['0.179', '0.172']
2000 ['0.178', '0.194']
2100 ['0.177', '0.110']
2200 ['0.178', '0.222']
2300 ['0.177', '0.039']
2400 ['0.177', '0.127']
2500 ['0.177', '0.044']
2600 ['0.175', '0.370']
2700 ['0.175', '0.125']
2800 ['0.176', '0.061']
2900 ['0.179', '0.073']
3000 ['0.178', '0.054']
3100 ['0.177', '0.264']
3200 ['0.178', '0.282']
3300 ['0.180', '0.030']
3400 ['0.176', '0.284']
3500 ['0.179', '0.572']
3600 ['0.176', '0.269']
3700 ['0.176', '0.056']
Train: [4][3750/3750]	loss 0.026 (0.035)	Acc@1 100.000 (95.872)
0 ['0.176', '0.422']
100 ['0.176', '0.173']
200 ['0.175', '0.042']
300 ['0.177', '0.031']
400 ['0.177', '0.056']
500 ['0.176', '0.099']
600 ['0.178', '0.103']
700 ['0.180', '0.394']
800 ['0.175', '0.017']
900 ['0.177', '0.075']
1000 ['0.178', '0.052']
1100 ['0.176', '0.026']
1200 ['0.175', '0.105']
1300 ['0.175', '0.268']
1400 ['0.177', '0.314']
1500 ['0.176', '0.067']
1600 ['0.177', '0.157']
1700 ['0.177', '0.215']
1800 ['0.176', '0.461']
1900 ['0.175', '0.153']
2000 ['0.178', '0.348']
2100 ['0.176', '0.159']
2200 ['0.176', '0.353']
2300 ['0.176', '0.175']
2400 ['0.177', '0.042']
2500 ['0.176', '0.162']
2600 ['0.175', '0.141']
2700 ['0.177', '0.038']
2800 ['0.175', '0.353']
2900 ['0.177', '0.028']
3000 ['0.176', '0.160']
3100 ['0.178', '0.041']
3200 ['0.177', '0.045']
3300 ['0.176', '0.021']
3400 ['0.179', '0.022']
3500 ['0.176', '0.239']
3600 ['0.177', '0.093']
3700 ['0.177', '0.053']
Train: [5][3750/3750]	loss 0.031 (0.034)	Acc@1 100.000 (96.163)
Test model 1 on task 1
Test: [3/3]	loss 0.220 (0.209)	Acc@1 92.588 (93.280)
Test model 1 on task 2
Test: [3/3]	loss 0.152 (0.152)	Acc@1 95.354 (95.210)
Test model 1 on task 3
Test: [3/3]	loss 0.157 (0.139)	Acc@1 95.741 (95.700)
Test model 1 on task 4
Test: [3/3]	loss 0.141 (0.138)	Acc@1 95.686 (95.610)
Test model 1 on task 5
Test: [3/3]	loss 0.120 (0.128)	Acc@1 96.792 (96.140)
Test model 1 on task 6
Test: [3/3]	loss 0.139 (0.128)	Acc@1 95.962 (96.160)
Test model 1 on task 7
Test: [3/3]	loss 0.137 (0.132)	Acc@1 95.796 (95.860)
Test model 1 on task 8
Test: [3/3]	loss 0.123 (0.127)	Acc@1 96.239 (96.320)
Test model 1 on task 9
Test: [3/3]	loss 0.126 (0.133)	Acc@1 96.460 (96.090)
############################################################ Avg acc: 95.60
Task 10 Model 1:
0 ['0.121', '3.527']
100 ['0.212', '1.343']
200 ['0.223', '0.466']
300 ['0.224', '0.641']
400 ['0.231', '0.848']
500 ['0.225', '0.707']
600 ['0.224', '0.169']
700 ['0.221', '0.523']
800 ['0.222', '0.266']
900 ['0.224', '0.354']
1000 ['0.220', '0.380']
1100 ['0.219', '0.064']
1200 ['0.219', '0.363']
1300 ['0.218', '0.307']
1400 ['0.219', '0.140']
1500 ['0.216', '0.359']
1600 ['0.216', '0.280']
1700 ['0.217', '0.312']
1800 ['0.215', '0.111']
1900 ['0.214', '0.471']
2000 ['0.213', '0.271']
2100 ['0.211', '0.214']
2200 ['0.212', '0.356']
2300 ['0.211', '0.475']
2400 ['0.210', '0.106']
2500 ['0.209', '0.227']
2600 ['0.212', '0.249']
2700 ['0.209', '0.236']
2800 ['0.211', '0.385']
2900 ['0.215', '0.381']
3000 ['0.210', '0.580']
3100 ['0.210', '0.185']
3200 ['0.213', '0.294']
3300 ['0.210', '0.258']
3400 ['0.209', '0.082']
3500 ['0.210', '0.165']
3600 ['0.210', '0.080']
3700 ['0.212', '0.064']
Train: [1][3750/3750]	loss 0.037 (0.057)	Acc@1 93.750 (89.368)
0 ['0.209', '0.076']
100 ['0.208', '0.158']
200 ['0.208', '0.114']
300 ['0.208', '0.071']
400 ['0.208', '0.151']
500 ['0.208', '0.062']
600 ['0.208', '0.360']
700 ['0.208', '0.130']
800 ['0.206', '0.069']
900 ['0.207', '0.234']
1000 ['0.212', '0.532']
1100 ['0.207', '0.199']
1200 ['0.209', '0.028']
1300 ['0.207', '0.603']
1400 ['0.208', '0.092']
1500 ['0.206', '0.071']
1600 ['0.206', '0.099']
1700 ['0.205', '0.165']
1800 ['0.206', '0.189']
1900 ['0.207', '0.124']
2000 ['0.207', '0.432']
2100 ['0.207', '0.149']
2200 ['0.207', '0.151']
2300 ['0.208', '0.308']
2400 ['0.207', '0.036']
2500 ['0.208', '0.268']
2600 ['0.206', '0.128']
2700 ['0.206', '0.223']
2800 ['0.206', '0.074']
2900 ['0.206', '0.055']
3000 ['0.206', '0.076']
3100 ['0.206', '0.047']
3200 ['0.205', '0.032']
3300 ['0.205', '0.073']
3400 ['0.205', '0.137']
3500 ['0.207', '0.452']
3600 ['0.205', '0.186']
3700 ['0.204', '0.137']
Train: [2][3750/3750]	loss 0.031 (0.040)	Acc@1 93.750 (94.443)
0 ['0.205', '0.103']
100 ['0.203', '0.069']
200 ['0.208', '0.027']
300 ['0.206', '0.359']
400 ['0.204', '0.051']
500 ['0.212', '0.232']
600 ['0.207', '0.028']
700 ['0.205', '0.279']
800 ['0.205', '0.061']
900 ['0.205', '0.225']
1000 ['0.204', '0.169']
1100 ['0.206', '0.068']
1200 ['0.207', '0.108']
1300 ['0.205', '0.041']
1400 ['0.206', '0.045']
1500 ['0.206', '0.076']
1600 ['0.205', '0.125']
1700 ['0.204', '0.371']
1800 ['0.204', '0.506']
1900 ['0.203', '0.091']
2000 ['0.204', '0.198']
2100 ['0.204', '0.048']
2200 ['0.205', '0.044']
2300 ['0.205', '0.292']
2400 ['0.204', '0.056']
2500 ['0.205', '0.103']
2600 ['0.204', '0.214']
2700 ['0.203', '0.107']
2800 ['0.203', '0.171']
2900 ['0.205', '0.127']
3000 ['0.204', '0.197']
3100 ['0.203', '0.111']
3200 ['0.204', '0.378']
3300 ['0.206', '0.159']
3400 ['0.204', '0.300']
3500 ['0.204', '0.282']
3600 ['0.205', '0.076']
3700 ['0.204', '0.075']
Train: [3][3750/3750]	loss 0.023 (0.037)	Acc@1 100.000 (95.250)
0 ['0.204', '0.019']
100 ['0.205', '0.069']
200 ['0.205', '0.104']
300 ['0.207', '0.067']
400 ['0.205', '0.150']
500 ['0.204', '0.365']
600 ['0.205', '0.411']
700 ['0.205', '0.072']
800 ['0.205', '0.038']
900 ['0.207', '0.145']
1000 ['0.205', '0.097']
1100 ['0.206', '0.109']
1200 ['0.206', '0.035']
1300 ['0.204', '0.181']
1400 ['0.203', '0.105']
1500 ['0.206', '0.251']
1600 ['0.205', '0.344']
1700 ['0.204', '0.260']
1800 ['0.203', '0.071']
1900 ['0.203', '0.131']
2000 ['0.204', '0.174']
2100 ['0.204', '0.767']
2200 ['0.204', '0.067']
2300 ['0.203', '0.118']
2400 ['0.204', '0.080']
2500 ['0.204', '0.066']
2600 ['0.204', '0.196']
2700 ['0.206', '0.174']
2800 ['0.203', '0.020']
2900 ['0.205', '0.079']
3000 ['0.206', '0.094']
3100 ['0.207', '0.126']
3200 ['0.204', '0.119']
3300 ['0.204', '0.186']
3400 ['0.203', '0.041']
3500 ['0.203', '0.043']
3600 ['0.203', '0.216']
3700 ['0.205', '0.017']
Train: [4][3750/3750]	loss 0.026 (0.036)	Acc@1 100.000 (95.657)
0 ['0.204', '0.251']
100 ['0.203', '0.070']
200 ['0.203', '0.065']
300 ['0.205', '0.089']
400 ['0.204', '0.030']
500 ['0.204', '0.524']
600 ['0.205', '0.110']
700 ['0.204', '0.053']
800 ['0.204', '0.053']
900 ['0.205', '0.166']
1000 ['0.205', '0.194']
1100 ['0.201', '0.050']
1200 ['0.205', '0.440']
1300 ['0.204', '0.184']
1400 ['0.204', '0.063']
1500 ['0.204', '0.065']
1600 ['0.204', '0.083']
1700 ['0.207', '0.194']
1800 ['0.205', '0.219']
1900 ['0.203', '0.109']
2000 ['0.204', '0.159']
2100 ['0.206', '0.019']
2200 ['0.204', '0.097']
2300 ['0.205', '0.231']
2400 ['0.204', '0.104']
2500 ['0.203', '0.107']
2600 ['0.205', '0.149']
2700 ['0.205', '0.245']
2800 ['0.205', '0.020']
2900 ['0.204', '0.085']
3000 ['0.204', '0.094']
3100 ['0.202', '0.196']
3200 ['0.202', '0.107']
3300 ['0.205', '0.092']
3400 ['0.206', '0.091']
3500 ['0.204', '0.042']
3600 ['0.205', '0.045']
3700 ['0.204', '0.455']
Train: [5][3750/3750]	loss 0.026 (0.035)	Acc@1 100.000 (95.933)
Test model 1 on task 1
Test: [3/3]	loss 0.226 (0.219)	Acc@1 92.810 (93.080)
Test model 1 on task 2
Test: [3/3]	loss 0.138 (0.161)	Acc@1 95.686 (94.880)
Test model 1 on task 3
Test: [3/3]	loss 0.149 (0.145)	Acc@1 95.077 (95.440)
Test model 1 on task 4
Test: [3/3]	loss 0.125 (0.143)	Acc@1 96.184 (95.460)
Test model 1 on task 5
Test: [3/3]	loss 0.148 (0.138)	Acc@1 95.631 (95.830)
Test model 1 on task 6
Test: [3/3]	loss 0.133 (0.135)	Acc@1 96.184 (95.880)
Test model 1 on task 7
Test: [3/3]	loss 0.134 (0.136)	Acc@1 95.852 (95.750)
Test model 1 on task 8
Test: [3/3]	loss 0.134 (0.136)	Acc@1 96.128 (95.980)
Test model 1 on task 9
Test: [3/3]	loss 0.138 (0.143)	Acc@1 95.520 (95.780)
Test model 1 on task 10
Test: [3/3]	loss 0.156 (0.154)	Acc@1 95.299 (95.310)
############################################################ Avg acc: 95.34
Task 11 Model 1:
0 ['0.145', '3.708']
100 ['0.250', '1.788']
200 ['0.259', '0.618']
300 ['0.256', '0.346']
400 ['0.253', '0.169']
500 ['0.259', '0.355']
600 ['0.255', '0.514']
700 ['0.254', '0.466']
800 ['0.256', '0.121']
900 ['0.256', '0.673']
1000 ['0.251', '0.615']
1100 ['0.250', '0.222']
1200 ['0.250', '0.363']
1300 ['0.251', '0.300']
1400 ['0.252', '0.169']
1500 ['0.249', '0.458']
1600 ['0.252', '0.730']
1700 ['0.250', '0.295']
1800 ['0.252', '0.541']
1900 ['0.249', '0.157']
2000 ['0.247', '0.371']
2100 ['0.246', '0.218']
2200 ['0.248', '0.212']
2300 ['0.250', '0.343']
2400 ['0.248', '0.147']
2500 ['0.248', '0.359']
2600 ['0.247', '0.268']
2700 ['0.250', '0.153']
2800 ['0.248', '0.620']
2900 ['0.246', '0.131']
3000 ['0.247', '0.225']
3100 ['0.246', '0.290']
3200 ['0.246', '0.231']
3300 ['0.245', '0.144']
3400 ['0.243', '0.395']
3500 ['0.246', '0.250']
3600 ['0.246', '0.454']
3700 ['0.246', '0.520']
Train: [1][3750/3750]	loss 0.058 (0.055)	Acc@1 93.750 (89.113)
0 ['0.246', '0.092']
100 ['0.247', '0.333']
200 ['0.245', '0.368']
300 ['0.244', '0.182']
400 ['0.245', '0.614']
500 ['0.246', '0.327']
600 ['0.246', '0.154']
700 ['0.243', '0.039']
800 ['0.244', '0.069']
900 ['0.243', '0.113']
1000 ['0.243', '0.494']
1100 ['0.241', '0.073']
1200 ['0.243', '0.133']
1300 ['0.242', '0.138']
1400 ['0.242', '0.094']
1500 ['0.243', '0.256']
1600 ['0.242', '0.201']
1700 ['0.243', '0.106']
1800 ['0.245', '0.106']
1900 ['0.245', '0.167']
2000 ['0.249', '0.120']
2100 ['0.242', '0.820']
2200 ['0.243', '0.194']
2300 ['0.243', '0.172']
2400 ['0.243', '0.158']
2500 ['0.241', '0.155']
2600 ['0.241', '0.091']
2700 ['0.243', '0.327']
2800 ['0.242', '0.176']
2900 ['0.245', '0.071']
3000 ['0.242', '0.278']
3100 ['0.243', '0.056']
3200 ['0.242', '0.024']
3300 ['0.245', '0.477']
3400 ['0.247', '0.095']
3500 ['0.246', '0.220']
3600 ['0.243', '0.075']
3700 ['0.242', '0.068']
Train: [2][3750/3750]	loss 0.031 (0.041)	Acc@1 100.000 (93.887)
0 ['0.245', '0.153']
100 ['0.241', '0.097']
200 ['0.241', '0.132']
300 ['0.241', '0.282']
400 ['0.240', '0.429']
500 ['0.243', '0.376']
600 ['0.241', '0.030']
700 ['0.245', '0.186']
800 ['0.242', '0.092']
900 ['0.241', '0.197']
1000 ['0.245', '0.033']
1100 ['0.241', '0.071']
1200 ['0.243', '0.097']
1300 ['0.243', '0.402']
1400 ['0.242', '0.073']
1500 ['0.241', '0.147']
1600 ['0.241', '0.096']
1700 ['0.241', '0.440']
1800 ['0.242', '0.307']
1900 ['0.241', '0.075']
2000 ['0.242', '0.065']
2100 ['0.240', '0.084']
2200 ['0.241', '0.048']
2300 ['0.244', '0.418']
2400 ['0.242', '0.165']
2500 ['0.241', '0.156']
2600 ['0.242', '0.162']
2700 ['0.241', '0.023']
2800 ['0.242', '0.121']
2900 ['0.244', '0.333']
3000 ['0.245', '0.117']
3100 ['0.243', '0.034']
3200 ['0.241', '0.264']
3300 ['0.242', '0.084']
3400 ['0.242', '0.055']
3500 ['0.241', '0.207']
3600 ['0.241', '0.233']
3700 ['0.244', '0.041']
Train: [3][3750/3750]	loss 0.027 (0.039)	Acc@1 100.000 (94.765)
0 ['0.244', '0.688']
100 ['0.241', '0.035']
200 ['0.240', '0.112']
300 ['0.240', '0.277']
400 ['0.240', '0.338']
500 ['0.241', '0.378']
600 ['0.242', '0.194']
700 ['0.242', '0.105']
800 ['0.241', '0.348']
900 ['0.239', '0.060']
1000 ['0.241', '0.053']
1100 ['0.242', '0.075']
1200 ['0.241', '0.160']
1300 ['0.241', '0.137']
1400 ['0.243', '0.037']
1500 ['0.243', '0.185']
1600 ['0.242', '0.095']
1700 ['0.242', '0.510']
1800 ['0.242', '0.176']
1900 ['0.241', '0.120']
2000 ['0.244', '0.205']
2100 ['0.243', '0.036']
2200 ['0.245', '0.021']
2300 ['0.241', '0.026']
2400 ['0.243', '0.009']
2500 ['0.240', '0.640']
2600 ['0.240', '0.190']
2700 ['0.245', '0.100']
2800 ['0.240', '0.329']
2900 ['0.244', '0.108']
3000 ['0.243', '0.048']
3100 ['0.242', '0.098']
3200 ['0.241', '0.075']
3300 ['0.241', '0.074']
3400 ['0.241', '0.138']
3500 ['0.241', '0.157']
3600 ['0.241', '0.108']
3700 ['0.243', '0.057']
Train: [4][3750/3750]	loss 0.038 (0.037)	Acc@1 93.750 (95.115)
0 ['0.241', '0.069']
100 ['0.242', '0.074']
200 ['0.240', '0.086']
300 ['0.243', '0.071']
400 ['0.242', '0.075']
500 ['0.242', '0.113']
600 ['0.240', '0.085']
700 ['0.241', '0.103']
800 ['0.242', '0.120']
900 ['0.240', '0.138']
1000 ['0.242', '0.203']
1100 ['0.241', '0.103']
1200 ['0.242', '0.137']
1300 ['0.241', '0.025']
1400 ['0.242', '0.500']
1500 ['0.243', '0.109']
1600 ['0.242', '0.103']
1700 ['0.241', '0.017']
1800 ['0.240', '0.043']
1900 ['0.242', '0.251']
2000 ['0.245', '0.116']
2100 ['0.245', '0.197']
2200 ['0.241', '0.046']
2300 ['0.243', '0.048']
2400 ['0.242', '0.065']
2500 ['0.243', '0.277']
2600 ['0.242', '0.164']
2700 ['0.245', '0.146']
2800 ['0.242', '0.027']
2900 ['0.242', '0.038']
3000 ['0.240', '0.070']
3100 ['0.240', '0.077']
3200 ['0.241', '0.274']
3300 ['0.242', '0.038']
3400 ['0.241', '0.025']
3500 ['0.241', '0.121']
3600 ['0.243', '0.081']
3700 ['0.242', '0.478']
Train: [5][3750/3750]	loss 0.028 (0.037)	Acc@1 100.000 (95.335)
Test model 1 on task 1
Test: [3/3]	loss 0.245 (0.233)	Acc@1 91.759 (92.470)
Test model 1 on task 2
Test: [3/3]	loss 0.182 (0.169)	Acc@1 94.192 (94.680)
Test model 1 on task 3
Test: [3/3]	loss 0.175 (0.153)	Acc@1 94.358 (95.150)
Test model 1 on task 4
Test: [3/3]	loss 0.145 (0.151)	Acc@1 95.907 (95.310)
Test model 1 on task 5
Test: [3/3]	loss 0.148 (0.146)	Acc@1 95.520 (95.630)
Test model 1 on task 6
Test: [3/3]	loss 0.125 (0.140)	Acc@1 96.350 (95.800)
Test model 1 on task 7
Test: [3/3]	loss 0.150 (0.141)	Acc@1 95.631 (95.650)
Test model 1 on task 8
Test: [3/3]	loss 0.135 (0.144)	Acc@1 96.184 (95.810)
Test model 1 on task 9
Test: [3/3]	loss 0.146 (0.152)	Acc@1 95.796 (95.550)
Test model 1 on task 10
Test: [3/3]	loss 0.156 (0.164)	Acc@1 95.354 (95.130)
Test model 1 on task 11
Test: [3/3]	loss 0.171 (0.160)	Acc@1 94.746 (95.380)
############################################################ Avg acc: 95.14
Task 12 Model 1:
0 ['0.153', '3.733']
100 ['0.251', '1.084']
200 ['0.269', '0.267']
300 ['0.275', '0.571']
400 ['0.274', '0.715']
500 ['0.275', '0.506']
600 ['0.274', '0.567']
700 ['0.275', '0.244']
800 ['0.270', '0.275']
900 ['0.272', '0.209']
1000 ['0.282', '0.308']
1100 ['0.273', '0.182']
1200 ['0.272', '0.334']
1300 ['0.271', '0.714']
1400 ['0.275', '0.614']
1500 ['0.269', '0.614']
1600 ['0.270', '0.303']
1700 ['0.273', '0.307']
1800 ['0.272', '0.034']
1900 ['0.269', '0.238']
2000 ['0.267', '0.153']
2100 ['0.271', '0.130']
2200 ['0.268', '0.439']
2300 ['0.267', '0.500']
2400 ['0.269', '0.267']
2500 ['0.270', '0.176']
2600 ['0.268', '0.165']
2700 ['0.265', '0.067']
2800 ['0.267', '0.090']
2900 ['0.267', '0.379']
3000 ['0.269', '0.192']
3100 ['0.269', '0.210']
3200 ['0.267', '0.099']
3300 ['0.267', '0.543']
3400 ['0.266', '0.116']
3500 ['0.267', '0.074']
3600 ['0.269', '0.084']
3700 ['0.267', '0.271']
Train: [1][3750/3750]	loss 0.054 (0.054)	Acc@1 81.250 (88.392)
0 ['0.266', '0.355']
100 ['0.266', '0.332']
200 ['0.266', '0.189']
300 ['0.266', '0.179']
400 ['0.263', '0.453']
500 ['0.263', '0.210']
600 ['0.266', '0.091']
700 ['0.268', '0.043']
800 ['0.266', '0.452']
900 ['0.265', '0.134']
1000 ['0.270', '0.200']
1100 ['0.263', '0.137']
1200 ['0.265', '0.274']
1300 ['0.265', '0.054']
1400 ['0.265', '0.201']
1500 ['0.266', '0.109']
1600 ['0.264', '0.444']
1700 ['0.262', '0.083']
1800 ['0.262', '0.409']
1900 ['0.263', '0.071']
2000 ['0.262', '0.097']
2100 ['0.266', '0.147']
2200 ['0.265', '0.157']
2300 ['0.264', '0.580']
2400 ['0.267', '0.086']
2500 ['0.264', '0.097']
2600 ['0.264', '0.387']
2700 ['0.272', '0.582']
2800 ['0.264', '0.286']
2900 ['0.265', '0.052']
3000 ['0.267', '0.117']
3100 ['0.269', '0.102']
3200 ['0.264', '0.215']
3300 ['0.264', '0.127']
3400 ['0.263', '0.265']
3500 ['0.266', '0.101']
3600 ['0.270', '0.347']
3700 ['0.265', '0.220']
Train: [2][3750/3750]	loss 0.023 (0.041)	Acc@1 100.000 (93.447)
0 ['0.270', '0.640']
100 ['0.266', '0.355']
200 ['0.267', '0.389']
300 ['0.264', '0.233']
400 ['0.267', '0.219']
500 ['0.266', '0.153']
600 ['0.266', '0.167']
700 ['0.265', '0.265']
800 ['0.266', '0.086']
900 ['0.268', '0.244']
1000 ['0.266', '0.132']
1100 ['0.267', '0.055']
1200 ['0.268', '0.142']
1300 ['0.267', '0.296']
1400 ['0.267', '0.190']
1500 ['0.267', '0.021']
1600 ['0.264', '0.090']
1700 ['0.266', '0.098']
1800 ['0.264', '0.248']
1900 ['0.264', '0.032']
2000 ['0.264', '0.051']
2100 ['0.266', '0.060']
2200 ['0.266', '0.148']
2300 ['0.264', '0.097']
2400 ['0.264', '0.145']
2500 ['0.264', '0.091']
2600 ['0.266', '0.151']
2700 ['0.265', '0.240']
2800 ['0.266', '0.133']
2900 ['0.264', '0.321']
3000 ['0.263', '0.047']
3100 ['0.263', '0.026']
3200 ['0.263', '0.057']
3300 ['0.264', '0.107']
3400 ['0.266', '0.209']
3500 ['0.265', '0.042']
3600 ['0.264', '0.110']
3700 ['0.265', '0.420']
Train: [3][3750/3750]	loss 0.038 (0.039)	Acc@1 100.000 (94.262)
0 ['0.266', '0.344']
100 ['0.267', '0.275']
200 ['0.268', '0.277']
300 ['0.267', '0.329']
400 ['0.264', '0.178']
500 ['0.265', '0.509']
600 ['0.265', '0.155']
700 ['0.265', '0.202']
800 ['0.265', '0.119']
900 ['0.264', '0.093']
1000 ['0.266', '0.139']
1100 ['0.266', '0.115']
1200 ['0.270', '0.181']
1300 ['0.265', '0.129']
1400 ['0.266', '0.067']
1500 ['0.266', '0.132']
1600 ['0.266', '0.206']
1700 ['0.265', '0.022']
1800 ['0.264', '0.366']
1900 ['0.266', '0.064']
2000 ['0.268', '0.604']
2100 ['0.266', '0.113']
2200 ['0.267', '0.134']
2300 ['0.265', '0.097']
2400 ['0.265', '0.293']
2500 ['0.265', '0.187']
2600 ['0.265', '0.095']
2700 ['0.265', '0.085']
2800 ['0.265', '0.012']
2900 ['0.264', '0.097']
3000 ['0.268', '0.153']
3100 ['0.265', '0.366']
3200 ['0.265', '0.133']
3300 ['0.265', '0.137']
3400 ['0.263', '0.055']
3500 ['0.266', '0.148']
3600 ['0.265', '0.142']
3700 ['0.266', '0.204']
Train: [4][3750/3750]	loss 0.034 (0.037)	Acc@1 93.750 (94.632)
0 ['0.267', '0.025']
100 ['0.265', '0.126']
200 ['0.264', '0.331']
300 ['0.265', '0.066']
400 ['0.263', '0.053']
500 ['0.264', '0.183']
600 ['0.266', '0.130']
700 ['0.264', '0.080']
800 ['0.264', '0.127']
900 ['0.267', '0.601']
1000 ['0.267', '0.327']
1100 ['0.264', '0.116']
1200 ['0.266', '0.168']
1300 ['0.265', '0.059']
1400 ['0.267', '0.112']
1500 ['0.266', '0.178']
1600 ['0.264', '0.448']
1700 ['0.265', '0.197']
1800 ['0.267', '0.125']
1900 ['0.267', '0.158']
2000 ['0.264', '0.220']
2100 ['0.266', '0.305']
2200 ['0.265', '0.185']
2300 ['0.263', '0.197']
2400 ['0.266', '0.636']
2500 ['0.265', '0.042']
2600 ['0.265', '0.068']
2700 ['0.266', '0.062']
2800 ['0.266', '0.101']
2900 ['0.266', '0.285']
3000 ['0.263', '0.132']
3100 ['0.266', '0.253']
3200 ['0.265', '0.155']
3300 ['0.265', '0.348']
3400 ['0.265', '0.335']
3500 ['0.264', '0.101']
3600 ['0.266', '0.067']
3700 ['0.266', '0.080']
Train: [5][3750/3750]	loss 0.043 (0.037)	Acc@1 87.500 (94.992)
Test model 1 on task 1
Test: [3/3]	loss 0.262 (0.245)	Acc@1 91.648 (92.090)
Test model 1 on task 2
Test: [3/3]	loss 0.173 (0.176)	Acc@1 94.967 (94.470)
Test model 1 on task 3
Test: [3/3]	loss 0.156 (0.159)	Acc@1 95.243 (94.930)
Test model 1 on task 4
Test: [3/3]	loss 0.157 (0.157)	Acc@1 94.358 (95.090)
Test model 1 on task 5
Test: [3/3]	loss 0.132 (0.153)	Acc@1 96.018 (95.320)
Test model 1 on task 6
Test: [3/3]	loss 0.135 (0.145)	Acc@1 96.460 (95.610)
Test model 1 on task 7
Test: [3/3]	loss 0.138 (0.148)	Acc@1 95.575 (95.490)
Test model 1 on task 8
Test: [3/3]	loss 0.140 (0.152)	Acc@1 95.520 (95.510)
Test model 1 on task 9
Test: [3/3]	loss 0.166 (0.160)	Acc@1 95.022 (95.260)
Test model 1 on task 10
Test: [3/3]	loss 0.140 (0.170)	Acc@1 96.128 (94.990)
Test model 1 on task 11
Test: [3/3]	loss 0.172 (0.167)	Acc@1 94.967 (95.120)
Test model 1 on task 12
Test: [3/3]	loss 0.156 (0.175)	Acc@1 95.686 (94.830)
############################################################ Avg acc: 94.89
Task 13 Model 1:
0 ['0.165', '3.121']
100 ['0.276', '0.990']
200 ['0.293', '0.725']
300 ['0.303', '0.433']
400 ['0.307', '0.426']
500 ['0.303', '0.443']
600 ['0.303', '0.280']
700 ['0.302', '0.524']
800 ['0.301', '0.331']
900 ['0.298', '0.750']
1000 ['0.300', '0.198']
1100 ['0.300', '0.236']
1200 ['0.300', '0.571']
1300 ['0.300', '0.410']
1400 ['0.298', '0.155']
1500 ['0.299', '0.190']
1600 ['0.295', '0.384']
1700 ['0.299', '0.314']
1800 ['0.298', '0.607']
1900 ['0.297', '0.242']
2000 ['0.296', '0.326']
2100 ['0.295', '0.335']
2200 ['0.296', '0.379']
2300 ['0.293', '0.101']
2400 ['0.293', '0.268']
2500 ['0.297', '0.083']
2600 ['0.292', '0.600']
2700 ['0.295', '0.044']
2800 ['0.292', '0.101']
2900 ['0.290', '0.168']
3000 ['0.291', '0.299']
3100 ['0.289', '0.363']
3200 ['0.291', '0.715']
3300 ['0.290', '0.189']
3400 ['0.291', '0.171']
3500 ['0.292', '0.167']
3600 ['0.290', '0.629']
3700 ['0.290', '0.195']
Train: [1][3750/3750]	loss 0.046 (0.053)	Acc@1 87.500 (87.938)
0 ['0.290', '0.171']
100 ['0.293', '0.823']
200 ['0.290', '0.298']
300 ['0.289', '0.063']
400 ['0.290', '0.203']
500 ['0.291', '0.183']
600 ['0.288', '0.217']
700 ['0.290', '0.281']
800 ['0.288', '0.091']
900 ['0.287', '0.058']
1000 ['0.287', '0.135']
1100 ['0.286', '0.405']
1200 ['0.288', '0.178']
1300 ['0.285', '0.262']
1400 ['0.289', '0.315']
1500 ['0.289', '0.212']
1600 ['0.287', '0.054']
1700 ['0.287', '0.042']
1800 ['0.287', '0.172']
1900 ['0.288', '0.419']
2000 ['0.286', '0.149']
2100 ['0.286', '0.475']
2200 ['0.286', '0.091']
2300 ['0.289', '0.212']
2400 ['0.287', '0.223']
2500 ['0.288', '0.364']
2600 ['0.286', '0.102']
2700 ['0.286', '0.152']
2800 ['0.285', '0.163']
2900 ['0.287', '0.185']
3000 ['0.285', '0.111']
3100 ['0.286', '0.317']
3200 ['0.287', '0.061']
3300 ['0.288', '0.080']
3400 ['0.285', '0.034']
3500 ['0.287', '0.083']
3600 ['0.287', '0.317']
3700 ['0.285', '0.057']
Train: [2][3750/3750]	loss 0.063 (0.040)	Acc@1 87.500 (92.990)
0 ['0.284', '0.171']
100 ['0.285', '0.264']
200 ['0.285', '0.067']
300 ['0.284', '0.132']
400 ['0.284', '0.045']
500 ['0.285', '0.209']
600 ['0.285', '0.281']
700 ['0.286', '0.072']
800 ['0.286', '0.119']
900 ['0.285', '0.342']
1000 ['0.287', '0.193']
1100 ['0.286', '0.268']
1200 ['0.285', '0.216']
1300 ['0.284', '0.126']
1400 ['0.286', '0.376']
1500 ['0.287', '0.230']
1600 ['0.286', '0.319']
1700 ['0.288', '0.082']
1800 ['0.287', '0.099']
1900 ['0.287', '0.114']
2000 ['0.287', '0.430']
2100 ['0.286', '0.355']
2200 ['0.290', '0.279']
2300 ['0.286', '0.075']
2400 ['0.286', '0.146']
2500 ['0.286', '0.196']
2600 ['0.287', '0.133']
2700 ['0.288', '0.211']
2800 ['0.288', '0.134']
2900 ['0.286', '0.051']
3000 ['0.284', '0.346']
3100 ['0.285', '0.195']
3200 ['0.286', '0.736']
3300 ['0.286', '0.054']
3400 ['0.286', '0.508']
3500 ['0.287', '0.176']
3600 ['0.285', '0.296']
3700 ['0.286', '0.112']
Train: [3][3750/3750]	loss 0.052 (0.038)	Acc@1 93.750 (93.873)
0 ['0.286', '0.247']
100 ['0.285', '0.058']
200 ['0.285', '0.147']
300 ['0.287', '0.178']
400 ['0.286', '0.351']
500 ['0.285', '0.287']
600 ['0.286', '0.256']
700 ['0.286', '0.063']
800 ['0.285', '0.150']
900 ['0.288', '0.077']
1000 ['0.285', '0.266']
1100 ['0.286', '0.073']
1200 ['0.287', '0.303']
1300 ['0.287', '0.119']
1400 ['0.286', '0.290']
1500 ['0.285', '0.290']
1600 ['0.285', '0.330']
1700 ['0.288', '0.143']
1800 ['0.286', '0.279']
1900 ['0.290', '0.140']
2000 ['0.287', '0.179']
2100 ['0.286', '0.118']
2200 ['0.286', '0.118']
2300 ['0.285', '0.200']
2400 ['0.288', '0.079']
2500 ['0.285', '0.216']
2600 ['0.285', '0.245']
2700 ['0.284', '0.209']
2800 ['0.285', '0.365']
2900 ['0.286', '0.262']
3000 ['0.285', '0.227']
3100 ['0.285', '0.340']
3200 ['0.286', '0.109']
3300 ['0.287', '0.135']
3400 ['0.285', '0.584']
3500 ['0.286', '0.147']
3600 ['0.285', '0.061']
3700 ['0.287', '0.306']
Train: [4][3750/3750]	loss 0.043 (0.037)	Acc@1 87.500 (94.282)
0 ['0.285', '0.100']
100 ['0.286', '0.147']
200 ['0.285', '0.075']
300 ['0.285', '0.407']
400 ['0.287', '0.096']
500 ['0.286', '0.362']
600 ['0.285', '0.110']
700 ['0.286', '0.018']
800 ['0.286', '0.348']
900 ['0.287', '0.099']
1000 ['0.285', '0.128']
1100 ['0.285', '0.658']
1200 ['0.286', '0.425']
1300 ['0.286', '0.231']
1400 ['0.287', '0.213']
1500 ['0.284', '0.141']
1600 ['0.286', '0.129']
1700 ['0.284', '0.226']
1800 ['0.285', '0.385']
1900 ['0.285', '0.323']
2000 ['0.288', '0.175']
2100 ['0.286', '0.071']
2200 ['0.285', '0.361']
2300 ['0.285', '0.237']
2400 ['0.287', '0.106']
2500 ['0.286', '0.247']
2600 ['0.287', '0.291']
2700 ['0.287', '0.183']
2800 ['0.287', '0.163']
2900 ['0.286', '0.134']
3000 ['0.286', '0.226']
3100 ['0.286', '0.169']
3200 ['0.286', '0.144']
3300 ['0.287', '0.087']
3400 ['0.291', '0.159']
3500 ['0.287', '0.153']
3600 ['0.287', '0.246']
3700 ['0.287', '0.274']
Train: [5][3750/3750]	loss 0.033 (0.036)	Acc@1 100.000 (94.535)
Test model 1 on task 1
Test: [3/3]	loss 0.278 (0.255)	Acc@1 90.985 (91.790)
Test model 1 on task 2
Test: [3/3]	loss 0.191 (0.182)	Acc@1 93.805 (94.220)
Test model 1 on task 3
Test: [3/3]	loss 0.153 (0.165)	Acc@1 95.465 (94.770)
Test model 1 on task 4
Test: [3/3]	loss 0.180 (0.164)	Acc@1 94.524 (94.780)
Test model 1 on task 5
Test: [3/3]	loss 0.170 (0.160)	Acc@1 94.801 (95.150)
Test model 1 on task 6
Test: [3/3]	loss 0.136 (0.151)	Acc@1 96.018 (95.430)
Test model 1 on task 7
Test: [3/3]	loss 0.168 (0.155)	Acc@1 95.077 (95.240)
Test model 1 on task 8
Test: [3/3]	loss 0.154 (0.158)	Acc@1 95.077 (95.270)
Test model 1 on task 9
Test: [3/3]	loss 0.162 (0.166)	Acc@1 95.354 (95.140)
Test model 1 on task 10
Test: [3/3]	loss 0.182 (0.177)	Acc@1 94.248 (94.640)
Test model 1 on task 11
Test: [3/3]	loss 0.180 (0.174)	Acc@1 94.358 (94.910)
Test model 1 on task 12
Test: [3/3]	loss 0.176 (0.180)	Acc@1 95.077 (94.800)
Test model 1 on task 13
Test: [3/3]	loss 0.158 (0.178)	Acc@1 95.852 (94.970)
############################################################ Avg acc: 94.70
Task 14 Model 1:
0 ['0.178', '3.554']
100 ['0.311', '0.811']
200 ['0.324', '0.743']
300 ['0.331', '0.848']
400 ['0.332', '0.750']
500 ['0.328', '0.573']
600 ['0.325', '0.310']
700 ['0.325', '0.300']
800 ['0.324', '0.677']
900 ['0.329', '0.596']
1000 ['0.324', '0.132']
1100 ['0.318', '0.535']
1200 ['0.317', '0.196']
1300 ['0.320', '0.510']
1400 ['0.318', '0.693']
1500 ['0.320', '0.547']
1600 ['0.318', '0.540']
1700 ['0.316', '0.231']
1800 ['0.318', '0.511']
1900 ['0.317', '0.181']
2000 ['0.318', '0.162']
2100 ['0.316', '0.187']
2200 ['0.316', '0.359']
2300 ['0.319', '0.711']
2400 ['0.318', '0.782']
2500 ['0.315', '0.208']
2600 ['0.315', '0.293']
2700 ['0.316', '0.105']
2800 ['0.315', '0.120']
2900 ['0.314', '0.320']
3000 ['0.313', '0.197']
3100 ['0.312', '0.072']
3200 ['0.315', '0.296']
3300 ['0.317', '0.237']
3400 ['0.317', '0.478']
3500 ['0.316', '0.096']
3600 ['0.316', '0.182']
3700 ['0.318', '0.141']
Train: [1][3750/3750]	loss 0.065 (0.052)	Acc@1 75.000 (87.483)
0 ['0.317', '0.346']
100 ['0.316', '0.183']
200 ['0.314', '0.081']
300 ['0.313', '0.609']
400 ['0.313', '0.244']
500 ['0.314', '0.156']
600 ['0.313', '0.267']
700 ['0.315', '0.069']
800 ['0.315', '0.566']
900 ['0.317', '0.155']
1000 ['0.317', '0.176']
1100 ['0.312', '0.075']
1200 ['0.317', '0.094']
1300 ['0.315', '0.020']
1400 ['0.313', '0.085']
1500 ['0.314', '0.232']
1600 ['0.313', '0.562']
1700 ['0.312', '0.167']
1800 ['0.314', '0.062']
1900 ['0.315', '0.163']
2000 ['0.313', '0.225']
2100 ['0.314', '0.349']
2200 ['0.313', '0.373']
2300 ['0.317', '0.332']
2400 ['0.314', '0.081']
2500 ['0.315', '0.529']
2600 ['0.314', '0.078']
2700 ['0.314', '0.231']
2800 ['0.315', '0.052']
2900 ['0.316', '0.306']
3000 ['0.316', '0.228']
3100 ['0.315', '0.383']
3200 ['0.315', '0.305']
3300 ['0.314', '0.185']
3400 ['0.314', '0.113']
3500 ['0.315', '0.481']
3600 ['0.314', '0.052']
3700 ['0.313', '0.268']
Train: [2][3750/3750]	loss 0.029 (0.041)	Acc@1 93.750 (92.452)
0 ['0.316', '0.219']
100 ['0.312', '0.109']
200 ['0.314', '0.060']
300 ['0.313', '0.169']
400 ['0.314', '0.272']
500 ['0.314', '0.783']
600 ['0.314', '0.051']
700 ['0.313', '0.181']
800 ['0.313', '0.090']
900 ['0.315', '0.503']
1000 ['0.314', '0.224']
1100 ['0.316', '0.066']
1200 ['0.315', '0.228']
1300 ['0.314', '0.087']
1400 ['0.312', '0.066']
1500 ['0.314', '0.286']
1600 ['0.315', '0.453']
1700 ['0.316', '0.075']
1800 ['0.318', '0.021']
1900 ['0.316', '0.183']
2000 ['0.314', '0.366']
2100 ['0.314', '0.391']
2200 ['0.315', '0.166']
2300 ['0.314', '0.134']
2400 ['0.314', '0.214']
2500 ['0.314', '0.167']
2600 ['0.316', '0.081']
2700 ['0.316', '0.095']
2800 ['0.316', '0.060']
2900 ['0.316', '0.110']
3000 ['0.314', '0.625']
3100 ['0.315', '0.191']
3200 ['0.315', '0.215']
3300 ['0.316', '0.122']
3400 ['0.317', '0.169']
3500 ['0.317', '0.048']
3600 ['0.315', '0.120']
3700 ['0.317', '0.137']
Train: [3][3750/3750]	loss 0.033 (0.039)	Acc@1 93.750 (93.345)
0 ['0.315', '0.285']
100 ['0.314', '0.239']
200 ['0.313', '0.188']
300 ['0.315', '0.215']
400 ['0.314', '0.069']
500 ['0.313', '0.047']
600 ['0.316', '0.142']
700 ['0.313', '0.279']
800 ['0.314', '0.087']
900 ['0.315', '0.204']
1000 ['0.316', '0.099']
1100 ['0.314', '0.190']
1200 ['0.317', '0.506']
1300 ['0.315', '0.354']
1400 ['0.315', '0.330']
1500 ['0.316', '0.135']
1600 ['0.317', '0.084']
1700 ['0.315', '0.110']
1800 ['0.317', '0.197']
1900 ['0.317', '0.181']
2000 ['0.315', '0.384']
2100 ['0.316', '0.433']
2200 ['0.317', '0.355']
2300 ['0.316', '0.048']
2400 ['0.316', '0.217']
2500 ['0.315', '0.435']
2600 ['0.316', '0.033']
2700 ['0.318', '0.163']
2800 ['0.316', '0.149']
2900 ['0.317', '0.309']
3000 ['0.317', '0.154']
3100 ['0.317', '0.065']
3200 ['0.316', '0.067']
3300 ['0.318', '0.171']
3400 ['0.317', '0.148']
3500 ['0.316', '0.053']
3600 ['0.317', '0.265']
3700 ['0.314', '0.370']
Train: [4][3750/3750]	loss 0.060 (0.038)	Acc@1 81.250 (93.758)
0 ['0.316', '0.074']
100 ['0.318', '0.087']
200 ['0.319', '0.066']
300 ['0.318', '0.112']
400 ['0.316', '0.450']
500 ['0.318', '0.183']
600 ['0.316', '0.313']
700 ['0.317', '0.061']
800 ['0.315', '0.329']
900 ['0.316', '0.094']
1000 ['0.315', '0.183']
1100 ['0.317', '0.151']
1200 ['0.315', '0.101']
1300 ['0.315', '0.130']
1400 ['0.316', '0.161']
1500 ['0.315', '0.179']
1600 ['0.315', '0.169']
1700 ['0.317', '0.191']
1800 ['0.315', '0.132']
1900 ['0.317', '0.173']
2000 ['0.317', '0.726']
2100 ['0.317', '0.078']
2200 ['0.315', '0.142']
2300 ['0.316', '0.313']
2400 ['0.318', '0.394']
2500 ['0.317', '0.202']
2600 ['0.318', '0.209']
2700 ['0.319', '0.089']
2800 ['0.317', '0.507']
2900 ['0.317', '0.201']
3000 ['0.317', '0.149']
3100 ['0.315', '0.245']
3200 ['0.317', '0.264']
3300 ['0.317', '0.255']
3400 ['0.316', '0.027']
3500 ['0.317', '0.112']
3600 ['0.315', '0.070']
3700 ['0.317', '0.083']
Train: [5][3750/3750]	loss 0.030 (0.038)	Acc@1 100.000 (94.013)
Test model 1 on task 1
Test: [3/3]	loss 0.289 (0.265)	Acc@1 91.150 (91.480)
Test model 1 on task 2
Test: [3/3]	loss 0.176 (0.187)	Acc@1 94.358 (94.060)
Test model 1 on task 3
Test: [3/3]	loss 0.167 (0.170)	Acc@1 94.358 (94.630)
Test model 1 on task 4
Test: [3/3]	loss 0.162 (0.169)	Acc@1 94.746 (94.660)
Test model 1 on task 5
Test: [3/3]	loss 0.163 (0.165)	Acc@1 94.801 (95.000)
Test model 1 on task 6
Test: [3/3]	loss 0.160 (0.156)	Acc@1 95.022 (95.150)
Test model 1 on task 7
Test: [3/3]	loss 0.164 (0.161)	Acc@1 94.912 (95.010)
Test model 1 on task 8
Test: [3/3]	loss 0.158 (0.163)	Acc@1 95.354 (95.180)
Test model 1 on task 9
Test: [3/3]	loss 0.165 (0.173)	Acc@1 95.077 (94.930)
Test model 1 on task 10
Test: [3/3]	loss 0.194 (0.184)	Acc@1 93.861 (94.350)
Test model 1 on task 11
Test: [3/3]	loss 0.175 (0.181)	Acc@1 95.520 (94.750)
Test model 1 on task 12
Test: [3/3]	loss 0.182 (0.186)	Acc@1 94.801 (94.590)
Test model 1 on task 13
Test: [3/3]	loss 0.179 (0.185)	Acc@1 94.967 (94.820)
Test model 1 on task 14
Test: [3/3]	loss 0.189 (0.207)	Acc@1 94.856 (93.790)
############################################################ Avg acc: 94.46
Task 15 Model 1:
0 ['0.200', '3.228']
100 ['0.360', '1.062']
200 ['0.370', '0.626']
300 ['0.367', '0.410']
400 ['0.369', '0.603']
500 ['0.368', '0.671']
600 ['0.369', '0.136']
700 ['0.373', '0.112']
800 ['0.370', '0.532']
900 ['0.368', '0.255']
1000 ['0.366', '0.335']
1100 ['0.365', '0.596']
1200 ['0.362', '0.508']
1300 ['0.360', '0.243']
1400 ['0.366', '0.720']
1500 ['0.361', '0.465']
1600 ['0.362', '0.263']
1700 ['0.361', '0.924']
1800 ['0.365', '0.453']
1900 ['0.359', '0.383']
2000 ['0.359', '0.314']
2100 ['0.359', '0.164']
2200 ['0.361', '0.472']
2300 ['0.363', '0.783']
2400 ['0.361', '0.204']
2500 ['0.359', '0.341']
2600 ['0.358', '0.340']
2700 ['0.357', '0.095']
2800 ['0.354', '0.446']
2900 ['0.359', '0.488']
3000 ['0.355', '0.264']
3100 ['0.357', '0.115']
3200 ['0.357', '0.159']
3300 ['0.356', '0.177']
3400 ['0.359', '0.468']
3500 ['0.356', '0.097']
3600 ['0.355', '0.250']
3700 ['0.357', '0.318']
Train: [1][3750/3750]	loss 0.036 (0.052)	Acc@1 93.750 (87.123)
0 ['0.355', '0.436']
100 ['0.359', '0.109']
200 ['0.355', '0.245']
300 ['0.357', '0.410']
400 ['0.355', '0.772']
500 ['0.354', '0.614']
600 ['0.354', '0.222']
700 ['0.354', '0.160']
800 ['0.355', '0.161']
900 ['0.355', '0.124']
1000 ['0.354', '0.105']
1100 ['0.355', '0.203']
1200 ['0.358', '0.241']
1300 ['0.357', '0.165']
1400 ['0.355', '0.321']
1500 ['0.355', '0.356']
1600 ['0.357', '0.037']
1700 ['0.357', '0.516']
1800 ['0.357', '0.381']
1900 ['0.359', '0.077']
2000 ['0.358', '0.098']
2100 ['0.356', '0.326']
2200 ['0.357', '0.536']
2300 ['0.355', '0.337']
2400 ['0.354', '0.208']
2500 ['0.354', '0.123']
2600 ['0.354', '0.131']
2700 ['0.354', '0.212']
2800 ['0.353', '0.190']
2900 ['0.356', '0.159']
3000 ['0.355', '0.675']
3100 ['0.356', '0.213']
3200 ['0.357', '0.774']
3300 ['0.357', '0.264']
3400 ['0.357', '0.340']
3500 ['0.356', '0.217']
3600 ['0.356', '0.103']
3700 ['0.355', '0.217']
Train: [2][3750/3750]	loss 0.037 (0.042)	Acc@1 93.750 (92.018)
0 ['0.356', '0.255']
100 ['0.355', '0.217']
200 ['0.355', '0.180']
300 ['0.356', '0.348']
400 ['0.357', '0.094']
500 ['0.358', '0.408']
600 ['0.355', '0.170']
700 ['0.357', '0.595']
800 ['0.356', '0.094']
900 ['0.354', '0.172']
1000 ['0.356', '0.368']
1100 ['0.358', '0.112']
1200 ['0.356', '0.166']
1300 ['0.355', '0.083']
1400 ['0.358', '0.130']
1500 ['0.354', '0.186']
1600 ['0.356', '0.121']
1700 ['0.357', '0.502']
1800 ['0.358', '0.190']
1900 ['0.360', '0.092']
2000 ['0.360', '0.436']
2100 ['0.358', '0.202']
2200 ['0.356', '0.058']
2300 ['0.357', '0.384']
2400 ['0.357', '0.099']
2500 ['0.357', '0.218']
2600 ['0.356', '0.457']
2700 ['0.356', '0.200']
2800 ['0.358', '0.565']
2900 ['0.359', '0.584']
3000 ['0.356', '0.068']
3100 ['0.355', '0.157']
3200 ['0.356', '0.172']
3300 ['0.359', '0.059']
3400 ['0.358', '0.270']
3500 ['0.358', '0.114']
3600 ['0.358', '0.194']
3700 ['0.357', '0.197']
Train: [3][3750/3750]	loss 0.061 (0.040)	Acc@1 81.250 (92.825)
0 ['0.357', '0.318']
100 ['0.357', '0.125']
200 ['0.359', '0.095']
300 ['0.357', '0.481']
400 ['0.354', '0.592']
500 ['0.356', '0.267']
600 ['0.361', '0.245']
700 ['0.359', '0.393']
800 ['0.361', '0.158']
900 ['0.360', '0.237']
1000 ['0.358', '0.274']
1100 ['0.358', '0.518']
1200 ['0.359', '0.097']
1300 ['0.358', '0.176']
1400 ['0.360', '0.151']
1500 ['0.358', '0.243']
1600 ['0.356', '0.229']
1700 ['0.358', '0.320']
1800 ['0.359', '0.040']
1900 ['0.359', '0.096']
2000 ['0.361', '0.054']
2100 ['0.358', '0.279']
2200 ['0.360', '0.259']
2300 ['0.361', '0.149']
2400 ['0.356', '0.286']
2500 ['0.358', '0.336']
2600 ['0.357', '0.185']
2700 ['0.358', '0.190']
2800 ['0.358', '0.114']
2900 ['0.357', '0.215']
3000 ['0.358', '0.439']
3100 ['0.359', '0.260']
3200 ['0.359', '0.264']
3300 ['0.357', '0.244']
3400 ['0.356', '0.100']
3500 ['0.357', '0.229']
3600 ['0.358', '0.145']
3700 ['0.356', '0.277']
Train: [4][3750/3750]	loss 0.046 (0.039)	Acc@1 87.500 (93.252)
0 ['0.358', '0.127']
100 ['0.358', '0.366']
200 ['0.355', '0.201']
300 ['0.357', '0.089']
400 ['0.355', '0.234']
500 ['0.358', '0.143']
600 ['0.357', '0.552']
700 ['0.359', '0.289']
800 ['0.359', '0.228']
900 ['0.358', '0.343']
1000 ['0.358', '0.092']
1100 ['0.357', '0.319']
1200 ['0.359', '0.159']
1300 ['0.358', '0.328']
1400 ['0.358', '0.151']
1500 ['0.358', '0.381']
1600 ['0.359', '0.273']
1700 ['0.360', '0.295']
1800 ['0.359', '0.355']
1900 ['0.358', '0.056']
2000 ['0.359', '0.276']
2100 ['0.359', '0.092']
2200 ['0.360', '0.177']
2300 ['0.359', '0.218']
2400 ['0.360', '0.149']
2500 ['0.359', '0.375']
2600 ['0.358', '0.061']
2700 ['0.359', '0.543']
2800 ['0.359', '0.045']
2900 ['0.359', '0.139']
3000 ['0.360', '0.327']
3100 ['0.359', '0.151']
3200 ['0.358', '0.450']
3300 ['0.357', '0.295']
3400 ['0.358', '0.099']
3500 ['0.358', '0.065']
3600 ['0.358', '0.087']
3700 ['0.358', '0.115']
Train: [5][3750/3750]	loss 0.036 (0.039)	Acc@1 93.750 (93.465)
Test model 1 on task 1
Test: [3/3]	loss 0.254 (0.274)	Acc@1 92.201 (91.180)
Test model 1 on task 2
Test: [3/3]	loss 0.179 (0.191)	Acc@1 93.529 (93.910)
Test model 1 on task 3
Test: [3/3]	loss 0.168 (0.174)	Acc@1 94.746 (94.510)
Test model 1 on task 4
Test: [3/3]	loss 0.174 (0.174)	Acc@1 93.916 (94.410)
Test model 1 on task 5
Test: [3/3]	loss 0.170 (0.172)	Acc@1 94.912 (94.740)
Test model 1 on task 6
Test: [3/3]	loss 0.161 (0.162)	Acc@1 94.856 (94.950)
Test model 1 on task 7
Test: [3/3]	loss 0.168 (0.168)	Acc@1 95.409 (94.780)
Test model 1 on task 8
Test: [3/3]	loss 0.178 (0.170)	Acc@1 94.414 (94.910)
Test model 1 on task 9
Test: [3/3]	loss 0.178 (0.179)	Acc@1 94.912 (94.830)
Test model 1 on task 10
Test: [3/3]	loss 0.203 (0.192)	Acc@1 92.976 (94.090)
Test model 1 on task 11
Test: [3/3]	loss 0.210 (0.186)	Acc@1 93.805 (94.610)
Test model 1 on task 12
Test: [3/3]	loss 0.181 (0.192)	Acc@1 94.690 (94.340)
Test model 1 on task 13
Test: [3/3]	loss 0.178 (0.193)	Acc@1 94.856 (94.420)
Test model 1 on task 14
Test: [3/3]	loss 0.204 (0.215)	Acc@1 94.192 (93.560)
Test model 1 on task 15
Test: [3/3]	loss 0.241 (0.220)	Acc@1 92.976 (93.570)
############################################################ Avg acc: 94.19
Task 16 Model 1:
0 ['0.216', '3.682']
100 ['0.374', '1.692']
200 ['0.393', '0.565']
300 ['0.397', '0.809']
400 ['0.404', '0.601']
500 ['0.404', '0.552']
600 ['0.403', '0.500']
700 ['0.395', '0.306']
800 ['0.399', '0.219']
900 ['0.395', '0.288']
1000 ['0.398', '0.248']
1100 ['0.393', '0.511']
1200 ['0.392', '0.294']
1300 ['0.391', '0.550']
1400 ['0.391', '0.301']
1500 ['0.395', '0.684']
1600 ['0.389', '0.146']
1700 ['0.393', '0.465']
1800 ['0.395', '0.423']
1900 ['0.393', '0.266']
2000 ['0.392', '0.339']
2100 ['0.392', '0.143']
2200 ['0.389', '0.281']
2300 ['0.385', '0.371']
2400 ['0.387', '0.166']
2500 ['0.390', '0.450']
2600 ['0.391', '0.157']
2700 ['0.390', '0.174']
2800 ['0.389', '0.366']
2900 ['0.388', '0.430']
3000 ['0.387', '0.150']
3100 ['0.388', '0.340']
3200 ['0.390', '0.539']
3300 ['0.387', '0.543']
3400 ['0.387', '0.540']
3500 ['0.385', '0.582']
3600 ['0.393', '0.456']
3700 ['0.388', '0.437']
Train: [1][3750/3750]	loss 0.045 (0.054)	Acc@1 93.750 (85.588)
0 ['0.387', '0.237']
100 ['0.389', '0.339']
200 ['0.387', '0.178']
300 ['0.392', '0.102']
400 ['0.388', '0.433']
500 ['0.391', '0.299']
600 ['0.387', '0.172']
700 ['0.386', '0.165']
800 ['0.391', '0.481']
900 ['0.388', '0.307']
1000 ['0.385', '0.193']
1100 ['0.383', '0.469']
1200 ['0.384', '0.449']
1300 ['0.386', '0.375']
1400 ['0.389', '0.260']
1500 ['0.387', '0.327']
1600 ['0.391', '0.151']
1700 ['0.389', '0.166']
1800 ['0.388', '0.123']
1900 ['0.388', '0.380']
2000 ['0.387', '0.213']
2100 ['0.389', '0.146']
2200 ['0.389', '0.255']
2300 ['0.387', '0.283']
2400 ['0.387', '0.170']
2500 ['0.385', '0.691']
2600 ['0.386', '0.357']
2700 ['0.387', '0.390']
2800 ['0.388', '0.238']
2900 ['0.388', '0.604']
3000 ['0.388', '0.265']
3100 ['0.389', '0.285']
3200 ['0.387', '0.063']
3300 ['0.386', '0.140']
3400 ['0.387', '0.159']
3500 ['0.389', '0.219']
3600 ['0.388', '0.349']
3700 ['0.390', '0.117']
Train: [2][3750/3750]	loss 0.038 (0.043)	Acc@1 87.500 (91.205)
0 ['0.394', '0.896']
100 ['0.388', '0.127']
200 ['0.389', '0.170']
300 ['0.389', '0.339']
400 ['0.389', '0.272']
500 ['0.389', '0.360']
600 ['0.389', '0.342']
700 ['0.386', '0.225']
800 ['0.387', '0.635']
900 ['0.388', '0.185']
1000 ['0.387', '0.496']
1100 ['0.387', '0.185']
1200 ['0.389', '0.367']
1300 ['0.388', '0.320']
1400 ['0.386', '0.497']
1500 ['0.389', '0.183']
1600 ['0.390', '0.102']
1700 ['0.388', '0.437']
1800 ['0.388', '0.314']
1900 ['0.387', '0.681']
2000 ['0.390', '0.372']
2100 ['0.388', '0.332']
2200 ['0.393', '0.568']
2300 ['0.392', '0.054']
2400 ['0.392', '0.254']
2500 ['0.389', '0.249']
2600 ['0.390', '0.242']
2700 ['0.387', '0.205']
2800 ['0.389', '0.433']
2900 ['0.390', '0.326']
3000 ['0.392', '0.259']
3100 ['0.391', '0.102']
3200 ['0.389', '0.152']
3300 ['0.387', '0.173']
3400 ['0.387', '0.389']
3500 ['0.389', '0.663']
3600 ['0.390', '0.033']
3700 ['0.391', '0.989']
Train: [3][3750/3750]	loss 0.056 (0.042)	Acc@1 87.500 (91.978)
0 ['0.390', '0.222']
100 ['0.390', '0.064']
200 ['0.389', '0.441']
300 ['0.390', '0.258']
400 ['0.389', '0.481']
500 ['0.390', '0.054']
600 ['0.390', '0.545']
700 ['0.391', '0.075']
800 ['0.390', '0.293']
900 ['0.391', '0.122']
1000 ['0.391', '0.362']
1100 ['0.390', '0.220']
1200 ['0.390', '0.096']
1300 ['0.390', '0.124']
1400 ['0.391', '0.334']
1500 ['0.390', '0.192']
1600 ['0.391', '0.167']
1700 ['0.390', '0.184']
1800 ['0.391', '0.282']
1900 ['0.391', '0.538']
2000 ['0.391', '0.099']
2100 ['0.390', '0.268']
2200 ['0.392', '0.164']
2300 ['0.391', '0.578']
2400 ['0.392', '0.144']
2500 ['0.389', '0.256']
2600 ['0.389', '0.155']
2700 ['0.389', '0.474']
2800 ['0.391', '0.171']
2900 ['0.392', '0.472']
3000 ['0.392', '0.187']
3100 ['0.391', '0.294']
3200 ['0.392', '0.147']
3300 ['0.392', '0.331']
3400 ['0.390', '0.411']
3500 ['0.390', '0.347']
3600 ['0.390', '0.466']
3700 ['0.390', '0.079']
Train: [4][3750/3750]	loss 0.035 (0.041)	Acc@1 93.750 (92.500)
0 ['0.390', '0.188']
100 ['0.391', '0.469']
200 ['0.389', '0.154']
300 ['0.389', '0.326']
400 ['0.390', '0.107']
500 ['0.391', '0.156']
600 ['0.393', '0.192']
700 ['0.391', '0.272']
800 ['0.393', '0.242']
900 ['0.391', '0.073']
1000 ['0.392', '0.226']
1100 ['0.390', '0.312']
1200 ['0.390', '1.027']
1300 ['0.390', '0.122']
1400 ['0.391', '0.094']
1500 ['0.390', '0.502']
1600 ['0.391', '0.187']
1700 ['0.390', '0.223']
1800 ['0.390', '0.548']
1900 ['0.392', '0.100']
2000 ['0.391', '0.215']
2100 ['0.390', '0.358']
2200 ['0.391', '0.269']
2300 ['0.391', '0.249']
2400 ['0.390', '0.391']
2500 ['0.391', '0.067']
2600 ['0.393', '0.361']
2700 ['0.391', '0.361']
2800 ['0.392', '0.464']
2900 ['0.390', '0.252']
3000 ['0.392', '0.334']
3100 ['0.391', '0.343']
3200 ['0.391', '0.109']
3300 ['0.391', '0.028']
3400 ['0.392', '0.467']
3500 ['0.391', '0.238']
3600 ['0.390', '0.185']
3700 ['0.391', '0.347']
Train: [5][3750/3750]	loss 0.033 (0.040)	Acc@1 100.000 (92.680)
Test model 1 on task 1
Test: [3/3]	loss 0.270 (0.276)	Acc@1 91.372 (91.150)
Test model 1 on task 2
Test: [3/3]	loss 0.173 (0.197)	Acc@1 94.192 (93.690)
Test model 1 on task 3
Test: [3/3]	loss 0.173 (0.180)	Acc@1 94.524 (94.320)
Test model 1 on task 4
Test: [3/3]	loss 0.169 (0.179)	Acc@1 94.635 (94.130)
Test model 1 on task 5
Test: [3/3]	loss 0.176 (0.176)	Acc@1 94.635 (94.600)
Test model 1 on task 6
Test: [3/3]	loss 0.163 (0.169)	Acc@1 95.299 (94.690)
Test model 1 on task 7
Test: [3/3]	loss 0.191 (0.174)	Acc@1 94.192 (94.500)
Test model 1 on task 8
Test: [3/3]	loss 0.168 (0.175)	Acc@1 94.967 (94.740)
Test model 1 on task 9
Test: [3/3]	loss 0.166 (0.184)	Acc@1 95.188 (94.570)
Test model 1 on task 10
Test: [3/3]	loss 0.194 (0.196)	Acc@1 94.027 (93.960)
Test model 1 on task 11
Test: [3/3]	loss 0.196 (0.193)	Acc@1 94.524 (94.350)
Test model 1 on task 12
Test: [3/3]	loss 0.205 (0.198)	Acc@1 93.805 (94.170)
Test model 1 on task 13
Test: [3/3]	loss 0.208 (0.198)	Acc@1 94.856 (94.380)
Test model 1 on task 14
Test: [3/3]	loss 0.236 (0.221)	Acc@1 92.810 (93.330)
Test model 1 on task 15
Test: [3/3]	loss 0.211 (0.227)	Acc@1 94.303 (93.410)
Test model 1 on task 16
Test: [3/3]	loss 0.226 (0.243)	Acc@1 93.584 (92.720)
############################################################ Avg acc: 93.92
Task 17 Model 1:
0 ['0.248', '3.954']
100 ['0.407', '0.608']
200 ['0.429', '0.570']
300 ['0.439', '0.356']
400 ['0.440', '1.080']
500 ['0.441', '0.586']
600 ['0.439', '0.283']
700 ['0.440', '0.771']
800 ['0.440', '0.496']
900 ['0.436', '0.422']
1000 ['0.435', '0.742']
1100 ['0.436', '0.408']
1200 ['0.435', '0.187']
1300 ['0.433', '0.596']
1400 ['0.431', '0.150']
1500 ['0.438', '0.484']
1600 ['0.432', '0.891']
1700 ['0.429', '0.717']
1800 ['0.429', '0.297']
1900 ['0.431', '0.589']
2000 ['0.429', '0.589']
2100 ['0.432', '0.350']
2200 ['0.429', '0.764']
2300 ['0.432', '0.517']
2400 ['0.431', '0.452']
2500 ['0.429', '0.402']
2600 ['0.431', '0.377']
2700 ['0.429', '0.399']
2800 ['0.434', '0.735']
2900 ['0.432', '0.494']
3000 ['0.429', '0.208']
3100 ['0.430', '0.339']
3200 ['0.429', '0.301']
3300 ['0.431', '0.258']
3400 ['0.430', '0.590']
3500 ['0.430', '0.353']
3600 ['0.431', '0.273']
3700 ['0.431', '0.404']
Train: [1][3750/3750]	loss 0.044 (0.054)	Acc@1 87.500 (85.358)
0 ['0.429', '0.246']
100 ['0.428', '0.416']
200 ['0.429', '0.305']
300 ['0.428', '0.552']
400 ['0.429', '0.288']
500 ['0.430', '0.498']
600 ['0.433', '0.277']
700 ['0.432', '0.074']
800 ['0.428', '0.609']
900 ['0.429', '0.326']
1000 ['0.429', '0.573']
1100 ['0.427', '0.247']
1200 ['0.429', '0.131']
1300 ['0.427', '0.168']
1400 ['0.429', '0.475']
1500 ['0.430', '0.316']
1600 ['0.427', '1.098']
1700 ['0.428', '0.513']
1800 ['0.430', '0.578']
1900 ['0.429', '0.070']
2000 ['0.430', '0.396']
2100 ['0.431', '0.316']
2200 ['0.431', '0.305']
2300 ['0.430', '0.130']
2400 ['0.429', '0.233']
2500 ['0.429', '0.288']
2600 ['0.430', '0.258']
2700 ['0.428', '0.100']
2800 ['0.429', '0.284']
2900 ['0.430', '0.282']
3000 ['0.427', '0.146']
3100 ['0.429', '0.153']
3200 ['0.428', '0.067']
3300 ['0.431', '0.219']
3400 ['0.429', '0.307']
3500 ['0.429', '0.163']
3600 ['0.428', '0.223']
3700 ['0.430', '0.432']
Train: [2][3750/3750]	loss 0.072 (0.044)	Acc@1 93.750 (90.742)
0 ['0.433', '0.248']
100 ['0.430', '0.164']
200 ['0.428', '0.159']
300 ['0.432', '0.158']
400 ['0.429', '0.166']
500 ['0.431', '0.135']
600 ['0.429', '0.302']
700 ['0.429', '0.120']
800 ['0.431', '0.264']
900 ['0.430', '0.290']
1000 ['0.430', '0.100']
1100 ['0.427', '0.458']
1200 ['0.427', '0.228']
1300 ['0.430', '0.391']
1400 ['0.431', '0.615']
1500 ['0.429', '0.294']
1600 ['0.429', '0.083']
1700 ['0.428', '0.200']
1800 ['0.429', '0.110']
1900 ['0.431', '0.193']
2000 ['0.429', '0.148']
2100 ['0.428', '0.265']
2200 ['0.428', '0.081']
2300 ['0.428', '0.356']
2400 ['0.430', '0.230']
2500 ['0.432', '0.245']
2600 ['0.427', '0.050']
2700 ['0.429', '0.095']
2800 ['0.433', '0.148']
2900 ['0.433', '0.333']
3000 ['0.430', '0.212']
3100 ['0.432', '0.249']
3200 ['0.431', '0.391']
3300 ['0.431', '0.215']
3400 ['0.433', '0.321']
3500 ['0.431', '0.758']
3600 ['0.430', '0.183']
3700 ['0.427', '0.280']
Train: [3][3750/3750]	loss 0.055 (0.042)	Acc@1 87.500 (91.433)
0 ['0.427', '0.245']
100 ['0.428', '0.270']
200 ['0.430', '0.137']
300 ['0.431', '0.336']
400 ['0.433', '0.222']
500 ['0.431', '0.385']
600 ['0.430', '0.311']
700 ['0.430', '0.238']
800 ['0.431', '0.311']
900 ['0.431', '0.439']
1000 ['0.435', '0.285']
1100 ['0.431', '0.066']
1200 ['0.431', '0.419']
1300 ['0.431', '0.296']
1400 ['0.431', '0.208']
1500 ['0.429', '0.362']
1600 ['0.432', '0.140']
1700 ['0.429', '0.509']
1800 ['0.429', '0.099']
1900 ['0.429', '0.264']
2000 ['0.430', '0.247']
2100 ['0.430', '0.139']
2200 ['0.430', '0.169']
2300 ['0.429', '0.248']
2400 ['0.431', '0.179']
2500 ['0.432', '0.541']
2600 ['0.432', '0.388']
2700 ['0.431', '0.372']
2800 ['0.433', '0.317']
2900 ['0.429', '0.478']
3000 ['0.430', '0.377']
3100 ['0.431', '0.259']
3200 ['0.432', '0.392']
3300 ['0.430', '0.114']
3400 ['0.430', '0.073']
3500 ['0.430', '0.305']
3600 ['0.430', '0.221']
3700 ['0.430', '0.316']
Train: [4][3750/3750]	loss 0.064 (0.042)	Acc@1 75.000 (91.905)
0 ['0.431', '0.238']
100 ['0.432', '0.239']
200 ['0.433', '0.664']
300 ['0.431', '0.530']
400 ['0.432', '0.330']
500 ['0.432', '0.213']
600 ['0.433', '0.290']
700 ['0.433', '0.171']
800 ['0.431', '0.146']
900 ['0.430', '0.199']
1000 ['0.432', '0.403']
1100 ['0.431', '0.395']
1200 ['0.429', '0.301']
1300 ['0.430', '0.214']
1400 ['0.431', '0.161']
1500 ['0.431', '0.692']
1600 ['0.432', '0.264']
1700 ['0.432', '0.143']
1800 ['0.430', '0.487']
1900 ['0.429', '0.176']
2000 ['0.430', '0.091']
2100 ['0.429', '0.253']
2200 ['0.435', '0.105']
2300 ['0.435', '0.230']
2400 ['0.434', '0.115']
2500 ['0.433', '0.096']
2600 ['0.433', '0.077']
2700 ['0.434', '0.041']
2800 ['0.431', '0.317']
2900 ['0.432', '0.276']
3000 ['0.434', '0.152']
3100 ['0.432', '0.194']
3200 ['0.430', '0.239']
3300 ['0.432', '0.342']
3400 ['0.429', '0.140']
3500 ['0.435', '0.296']
3600 ['0.429', '0.188']
3700 ['0.430', '0.201']
Train: [5][3750/3750]	loss 0.029 (0.041)	Acc@1 100.000 (92.052)
Test model 1 on task 1
Test: [3/3]	loss 0.275 (0.281)	Acc@1 90.431 (90.930)
Test model 1 on task 2
Test: [3/3]	loss 0.201 (0.202)	Acc@1 93.418 (93.530)
Test model 1 on task 3
Test: [3/3]	loss 0.204 (0.185)	Acc@1 93.639 (94.050)
Test model 1 on task 4
Test: [3/3]	loss 0.171 (0.184)	Acc@1 94.469 (94.050)
Test model 1 on task 5
Test: [3/3]	loss 0.192 (0.180)	Acc@1 94.082 (94.470)
Test model 1 on task 6
Test: [3/3]	loss 0.175 (0.172)	Acc@1 94.690 (94.600)
Test model 1 on task 7
Test: [3/3]	loss 0.187 (0.176)	Acc@1 94.137 (94.550)
Test model 1 on task 8
Test: [3/3]	loss 0.187 (0.180)	Acc@1 94.248 (94.550)
Test model 1 on task 9
Test: [3/3]	loss 0.196 (0.189)	Acc@1 94.192 (94.330)
Test model 1 on task 10
Test: [3/3]	loss 0.197 (0.199)	Acc@1 93.861 (93.970)
Test model 1 on task 11
Test: [3/3]	loss 0.193 (0.198)	Acc@1 94.690 (94.200)
Test model 1 on task 12
Test: [3/3]	loss 0.196 (0.203)	Acc@1 93.916 (94.050)
Test model 1 on task 13
Test: [3/3]	loss 0.208 (0.205)	Acc@1 94.192 (94.170)
Test model 1 on task 14
Test: [3/3]	loss 0.228 (0.227)	Acc@1 92.920 (93.200)
Test model 1 on task 15
Test: [3/3]	loss 0.227 (0.231)	Acc@1 93.584 (93.190)
Test model 1 on task 16
Test: [3/3]	loss 0.243 (0.249)	Acc@1 92.644 (92.640)
Test model 1 on task 17
Test: [3/3]	loss 0.257 (0.258)	Acc@1 92.644 (92.390)
############################################################ Avg acc: 93.70
Task 18 Model 1:
0 ['0.265', '3.342']
100 ['0.418', '1.586']
200 ['0.452', '0.798']
300 ['0.462', '0.561']
400 ['0.469', '0.560']
500 ['0.472', '0.482']
600 ['0.473', '0.227']
700 ['0.474', '0.324']
800 ['0.473', '0.614']
900 ['0.475', '0.316']
1000 ['0.471', '0.391']
1100 ['0.469', '0.204']
1200 ['0.471', '0.709']
1300 ['0.470', '0.228']
1400 ['0.470', '0.244']
1500 ['0.471', '0.346']
1600 ['0.472', '0.427']
1700 ['0.468', '0.698']
1800 ['0.466', '0.337']
1900 ['0.466', '0.345']
2000 ['0.468', '0.206']
2100 ['0.468', '0.458']
2200 ['0.467', '0.878']
2300 ['0.468', '0.261']
2400 ['0.465', '0.428']
2500 ['0.467', '0.275']
2600 ['0.467', '0.564']
2700 ['0.468', '0.439']
2800 ['0.466', '0.394']
2900 ['0.467', '0.361']
3000 ['0.469', '0.252']
3100 ['0.468', '0.365']
3200 ['0.466', '0.262']
3300 ['0.465', '0.184']
3400 ['0.467', '0.431']
3500 ['0.466', '0.223']
3600 ['0.463', '0.687']
3700 ['0.463', '0.649']
Train: [1][3750/3750]	loss 0.035 (0.053)	Acc@1 100.000 (84.793)
0 ['0.465', '0.362']
100 ['0.465', '0.264']
200 ['0.466', '0.128']
300 ['0.467', '0.088']
400 ['0.465', '0.568']
500 ['0.466', '0.352']
600 ['0.468', '0.772']
700 ['0.465', '0.456']
800 ['0.466', '0.303']
900 ['0.465', '0.116']
1000 ['0.465', '0.259']
1100 ['0.465', '0.227']
1200 ['0.469', '0.222']
1300 ['0.468', '0.248']
1400 ['0.470', '0.498']
1500 ['0.470', '0.347']
1600 ['0.469', '0.295']
1700 ['0.466', '0.356']
1800 ['0.466', '0.241']
1900 ['0.469', '0.174']
2000 ['0.466', '0.358']
2100 ['0.466', '0.226']
2200 ['0.465', '0.207']
2300 ['0.467', '0.437']
2400 ['0.465', '0.585']
2500 ['0.468', '0.294']
2600 ['0.471', '0.162']
2700 ['0.468', '0.261']
2800 ['0.468', '0.283']
2900 ['0.467', '0.172']
3000 ['0.467', '0.315']
3100 ['0.467', '0.424']
3200 ['0.468', '0.381']
3300 ['0.467', '0.152']
3400 ['0.464', '0.289']
3500 ['0.465', '0.272']
3600 ['0.466', '0.406']
3700 ['0.466', '0.164']
Train: [2][3750/3750]	loss 0.034 (0.044)	Acc@1 100.000 (90.233)
0 ['0.465', '0.363']
100 ['0.463', '0.277']
200 ['0.463', '0.185']
300 ['0.463', '0.154']
400 ['0.465', '0.375']
500 ['0.467', '0.135']
600 ['0.464', '0.208']
700 ['0.466', '0.337']
800 ['0.469', '0.224']
900 ['0.467', '0.212']
1000 ['0.467', '0.300']
1100 ['0.468', '0.552']
1200 ['0.467', '0.175']
1300 ['0.469', '0.186']
1400 ['0.467', '0.396']
1500 ['0.464', '0.379']
1600 ['0.469', '0.234']
1700 ['0.468', '0.416']
1800 ['0.467', '0.151']
1900 ['0.469', '0.572']
2000 ['0.466', '0.604']
2100 ['0.466', '0.347']
2200 ['0.470', '0.236']
2300 ['0.470', '0.580']
2400 ['0.474', '0.223']
2500 ['0.470', '0.343']
2600 ['0.468', '0.187']
2700 ['0.467', '0.086']
2800 ['0.468', '0.170']
2900 ['0.469', '0.125']
3000 ['0.471', '0.375']
3100 ['0.468', '0.396']
3200 ['0.470', '0.164']
3300 ['0.469', '0.310']
3400 ['0.471', '0.510']
3500 ['0.471', '0.120']
3600 ['0.470', '0.292']
3700 ['0.470', '0.220']
Train: [3][3750/3750]	loss 0.034 (0.043)	Acc@1 93.750 (91.048)
0 ['0.471', '0.393']
100 ['0.471', '0.457']
200 ['0.470', '0.171']
300 ['0.473', '0.387']
400 ['0.470', '0.311']
500 ['0.468', '0.193']
600 ['0.469', '0.348']
700 ['0.471', '0.254']
800 ['0.469', '0.297']
900 ['0.469', '0.242']
1000 ['0.470', '0.143']
1100 ['0.467', '0.121']
1200 ['0.467', '0.315']
1300 ['0.466', '0.250']
1400 ['0.467', '0.394']
1500 ['0.472', '0.432']
1600 ['0.468', '0.447']
1700 ['0.468', '0.086']
1800 ['0.467', '0.248']
1900 ['0.469', '0.641']
2000 ['0.469', '0.297']
2100 ['0.471', '0.188']
2200 ['0.469', '0.475']
2300 ['0.471', '0.474']
2400 ['0.471', '0.847']
2500 ['0.469', '0.381']
2600 ['0.469', '0.490']
2700 ['0.470', '0.223']
2800 ['0.472', '0.153']
2900 ['0.470', '0.112']
3000 ['0.470', '0.057']
3100 ['0.470', '0.278']
3200 ['0.473', '0.396']
3300 ['0.473', '0.160']
3400 ['0.470', '0.179']
3500 ['0.469', '0.052']
3600 ['0.471', '0.158']
3700 ['0.471', '0.062']
Train: [4][3750/3750]	loss 0.050 (0.042)	Acc@1 87.500 (91.392)
0 ['0.474', '0.282']
100 ['0.471', '0.107']
200 ['0.472', '0.238']
300 ['0.470', '0.279']
400 ['0.468', '0.083']
500 ['0.469', '0.278']
600 ['0.467', '0.252']
700 ['0.469', '0.386']
800 ['0.468', '0.096']
900 ['0.469', '0.473']
1000 ['0.471', '0.140']
1100 ['0.469', '0.441']
1200 ['0.469', '0.196']
1300 ['0.469', '0.504']
1400 ['0.473', '0.327']
1500 ['0.469', '0.275']
1600 ['0.472', '0.219']
1700 ['0.470', '0.128']
1800 ['0.469', '0.164']
1900 ['0.472', '0.110']
2000 ['0.472', '0.110']
2100 ['0.471', '0.383']
2200 ['0.470', '0.307']
2300 ['0.471', '0.247']
2400 ['0.469', '0.156']
2500 ['0.470', '0.282']
2600 ['0.470', '0.313']
2700 ['0.469', '0.237']
2800 ['0.468', '0.240']
2900 ['0.472', '0.190']
3000 ['0.475', '0.328']
3100 ['0.469', '0.139']
3200 ['0.473', '0.138']
3300 ['0.472', '0.217']
3400 ['0.474', '0.345']
3500 ['0.473', '0.090']
3600 ['0.472', '0.421']
3700 ['0.471', '0.289']
Train: [5][3750/3750]	loss 0.047 (0.042)	Acc@1 87.500 (91.620)
Test model 1 on task 1
Test: [3/3]	loss 0.319 (0.284)	Acc@1 90.210 (90.740)
Test model 1 on task 2
Test: [3/3]	loss 0.212 (0.208)	Acc@1 93.086 (93.290)
Test model 1 on task 3
Test: [3/3]	loss 0.147 (0.189)	Acc@1 95.409 (93.860)
Test model 1 on task 4
Test: [3/3]	loss 0.197 (0.190)	Acc@1 92.754 (93.660)
Test model 1 on task 5
Test: [3/3]	loss 0.194 (0.183)	Acc@1 93.916 (94.380)
Test model 1 on task 6
Test: [3/3]	loss 0.185 (0.178)	Acc@1 93.639 (94.340)
Test model 1 on task 7
Test: [3/3]	loss 0.182 (0.180)	Acc@1 94.248 (94.270)
Test model 1 on task 8
Test: [3/3]	loss 0.183 (0.185)	Acc@1 94.192 (94.250)
Test model 1 on task 9
Test: [3/3]	loss 0.198 (0.194)	Acc@1 93.695 (94.290)
Test model 1 on task 10
Test: [3/3]	loss 0.207 (0.203)	Acc@1 93.529 (93.890)
Test model 1 on task 11
Test: [3/3]	loss 0.185 (0.203)	Acc@1 94.580 (94.060)
Test model 1 on task 12
Test: [3/3]	loss 0.204 (0.206)	Acc@1 94.082 (93.960)
Test model 1 on task 13
Test: [3/3]	loss 0.226 (0.211)	Acc@1 94.082 (94.020)
Test model 1 on task 14
Test: [3/3]	loss 0.248 (0.232)	Acc@1 92.478 (93.050)
Test model 1 on task 15
Test: [3/3]	loss 0.250 (0.236)	Acc@1 92.699 (93.090)
Test model 1 on task 16
Test: [3/3]	loss 0.253 (0.256)	Acc@1 92.699 (92.360)
Test model 1 on task 17
Test: [3/3]	loss 0.283 (0.264)	Acc@1 91.980 (92.200)
Test model 1 on task 18
Test: [3/3]	loss 0.250 (0.268)	Acc@1 93.142 (92.410)
############################################################ Avg acc: 93.45
Task 19 Model 1:
0 ['0.276', '2.891']
100 ['0.452', '1.479']
200 ['0.495', '1.172']
300 ['0.511', '0.399']
400 ['0.517', '1.028']
500 ['0.514', '0.684']
600 ['0.523', '0.269']
700 ['0.518', '0.869']
800 ['0.518', '0.536']
900 ['0.517', '1.528']
1000 ['0.523', '0.470']
1100 ['0.522', '0.657']
1200 ['0.524', '0.464']
1300 ['0.519', '0.554']
1400 ['0.516', '0.129']
1500 ['0.520', '0.210']
1600 ['0.517', '0.325']
1700 ['0.517', '0.288']
1800 ['0.516', '0.497']
1900 ['0.517', '0.319']
2000 ['0.519', '0.714']
2100 ['0.519', '0.483']
2200 ['0.520', '0.404']
2300 ['0.517', '0.501']
2400 ['0.515', '0.647']
2500 ['0.516', '0.217']
2600 ['0.510', '0.449']
2700 ['0.512', '0.467']
2800 ['0.512', '0.079']
2900 ['0.512', '0.547']
3000 ['0.516', '0.436']
3100 ['0.515', '0.217']
3200 ['0.516', '0.344']
3300 ['0.516', '0.213']
3400 ['0.512', '0.466']
3500 ['0.514', '0.618']
3600 ['0.515', '0.612']
3700 ['0.514', '0.455']
Train: [1][3750/3750]	loss 0.050 (0.056)	Acc@1 81.250 (82.988)
0 ['0.514', '0.337']
100 ['0.516', '0.552']
200 ['0.514', '0.433']
300 ['0.513', '0.350']
400 ['0.515', '0.151']
500 ['0.515', '0.601']
600 ['0.514', '0.696']
700 ['0.517', '0.405']
800 ['0.518', '0.140']
900 ['0.517', '1.137']
1000 ['0.516', '0.091']
1100 ['0.515', '0.265']
1200 ['0.517', '0.261']
1300 ['0.519', '0.193']
1400 ['0.516', '0.594']
1500 ['0.516', '0.408']
1600 ['0.519', '0.753']
1700 ['0.518', '0.411']
1800 ['0.518', '0.446']
1900 ['0.517', '0.497']
2000 ['0.519', '0.262']
2100 ['0.520', '0.180']
2200 ['0.517', '0.300']
2300 ['0.515', '0.171']
2400 ['0.513', '0.337']
2500 ['0.518', '0.248']
2600 ['0.515', '0.225']
2700 ['0.513', '0.252']
2800 ['0.513', '0.242']
2900 ['0.516', '0.422']
3000 ['0.514', '0.202']
3100 ['0.518', '0.438']
3200 ['0.517', '0.162']
3300 ['0.517', '0.372']
3400 ['0.518', '0.153']
3500 ['0.517', '0.278']
3600 ['0.515', '0.368']
3700 ['0.515', '0.745']
Train: [2][3750/3750]	loss 0.048 (0.047)	Acc@1 81.250 (88.997)
0 ['0.519', '0.310']
100 ['0.519', '0.260']
200 ['0.515', '0.346']
300 ['0.518', '0.413']
400 ['0.518', '0.418']
500 ['0.516', '0.676']
600 ['0.516', '0.357']
700 ['0.517', '0.205']
800 ['0.517', '0.397']
900 ['0.514', '0.358']
1000 ['0.516', '0.148']
1100 ['0.518', '0.394']
1200 ['0.519', '0.284']
1300 ['0.518', '0.190']
1400 ['0.519', '0.253']
1500 ['0.519', '0.209']
1600 ['0.518', '0.357']
1700 ['0.517', '0.495']
1800 ['0.517', '0.619']
1900 ['0.520', '0.499']
2000 ['0.518', '0.448']
2100 ['0.517', '0.425']
2200 ['0.517', '0.232']
2300 ['0.515', '0.394']
2400 ['0.518', '0.484']
2500 ['0.518', '0.344']
2600 ['0.519', '0.286']
2700 ['0.516', '0.650']
2800 ['0.520', '0.280']
2900 ['0.521', '0.536']
3000 ['0.520', '0.239']
3100 ['0.521', '0.364']
3200 ['0.520', '0.585']
3300 ['0.520', '0.440']
3400 ['0.517', '0.386']
3500 ['0.519', '0.282']
3600 ['0.520', '0.145']
3700 ['0.519', '0.439']
Train: [3][3750/3750]	loss 0.038 (0.045)	Acc@1 93.750 (89.925)
0 ['0.519', '0.449']
100 ['0.519', '0.251']
200 ['0.519', '0.113']
300 ['0.521', '0.274']
400 ['0.520', '0.392']
500 ['0.520', '0.544']
600 ['0.519', '0.668']
700 ['0.519', '0.946']
800 ['0.521', '0.433']
900 ['0.518', '0.462']
1000 ['0.520', '0.481']
1100 ['0.517', '0.330']
1200 ['0.520', '0.149']
1300 ['0.518', '0.163']
1400 ['0.515', '0.185']
1500 ['0.516', '0.226']
1600 ['0.516', '0.469']
1700 ['0.516', '0.226']
1800 ['0.518', '0.308']
1900 ['0.518', '0.144']
2000 ['0.520', '0.428']
2100 ['0.521', '0.088']
2200 ['0.518', '0.577']
2300 ['0.518', '0.316']
2400 ['0.521', '0.289']
2500 ['0.518', '0.379']
2600 ['0.520', '0.235']
2700 ['0.522', '0.235']
2800 ['0.517', '0.550']
2900 ['0.519', '0.501']
3000 ['0.516', '0.110']
3100 ['0.516', '0.401']
3200 ['0.517', '0.360']
3300 ['0.516', '0.423']
3400 ['0.517', '0.199']
3500 ['0.520', '0.263']
3600 ['0.518', '0.397']
3700 ['0.518', '0.424']
Train: [4][3750/3750]	loss 0.050 (0.045)	Acc@1 93.750 (90.238)
0 ['0.520', '0.453']
100 ['0.518', '0.282']
200 ['0.517', '0.222']
300 ['0.518', '0.246']
400 ['0.519', '0.164']
500 ['0.518', '0.255']
600 ['0.520', '0.496']
700 ['0.518', '0.659']
800 ['0.520', '0.382']
900 ['0.525', '0.559']
1000 ['0.520', '0.385']
1100 ['0.518', '0.207']
1200 ['0.520', '0.175']
1300 ['0.520', '0.299']
1400 ['0.519', '0.716']
1500 ['0.516', '0.401']
1600 ['0.519', '0.161']
1700 ['0.517', '0.223']
1800 ['0.519', '0.377']
1900 ['0.518', '0.501']
2000 ['0.518', '0.484']
2100 ['0.523', '0.191']
2200 ['0.517', '0.308']
2300 ['0.515', '0.330']
2400 ['0.518', '0.248']
2500 ['0.519', '0.110']
2600 ['0.518', '0.426']
2700 ['0.519', '0.337']
2800 ['0.520', '0.318']
2900 ['0.520', '0.486']
3000 ['0.521', '0.127']
3100 ['0.519', '0.316']
3200 ['0.519', '0.122']
3300 ['0.517', '0.248']
3400 ['0.517', '0.279']
3500 ['0.519', '0.124']
3600 ['0.519', '0.387']
3700 ['0.518', '0.096']
Train: [5][3750/3750]	loss 0.059 (0.045)	Acc@1 75.000 (90.428)
Test model 1 on task 1
Test: [3/3]	loss 0.266 (0.289)	Acc@1 91.040 (90.540)
Test model 1 on task 2
Test: [3/3]	loss 0.197 (0.211)	Acc@1 93.529 (93.070)
Test model 1 on task 3
Test: [3/3]	loss 0.178 (0.192)	Acc@1 93.916 (93.930)
Test model 1 on task 4
Test: [3/3]	loss 0.178 (0.195)	Acc@1 94.082 (93.560)
Test model 1 on task 5
Test: [3/3]	loss 0.162 (0.187)	Acc@1 94.524 (94.320)
Test model 1 on task 6
Test: [3/3]	loss 0.204 (0.183)	Acc@1 93.252 (94.250)
Test model 1 on task 7
Test: [3/3]	loss 0.190 (0.183)	Acc@1 93.916 (94.160)
Test model 1 on task 8
Test: [3/3]	loss 0.188 (0.190)	Acc@1 94.635 (94.250)
Test model 1 on task 9
Test: [3/3]	loss 0.221 (0.197)	Acc@1 92.754 (94.140)
Test model 1 on task 10
Test: [3/3]	loss 0.196 (0.207)	Acc@1 94.192 (93.630)
Test model 1 on task 11
Test: [3/3]	loss 0.224 (0.208)	Acc@1 93.639 (93.820)
Test model 1 on task 12
Test: [3/3]	loss 0.201 (0.211)	Acc@1 93.805 (93.820)
Test model 1 on task 13
Test: [3/3]	loss 0.230 (0.217)	Acc@1 93.197 (93.830)
Test model 1 on task 14
Test: [3/3]	loss 0.214 (0.238)	Acc@1 93.197 (92.890)
Test model 1 on task 15
Test: [3/3]	loss 0.252 (0.241)	Acc@1 92.478 (92.860)
Test model 1 on task 16
Test: [3/3]	loss 0.257 (0.263)	Acc@1 92.257 (92.250)
Test model 1 on task 17
Test: [3/3]	loss 0.280 (0.269)	Acc@1 92.257 (92.130)
Test model 1 on task 18
Test: [3/3]	loss 0.278 (0.274)	Acc@1 92.478 (92.120)
Test model 1 on task 19
Test: [3/3]	loss 0.336 (0.317)	Acc@1 89.215 (90.550)
############################################################ Avg acc: 93.16
Task 20 Model 1:
0 ['0.321', '4.370']
100 ['0.568', '1.416']
200 ['0.613', '1.190']
300 ['0.610', '0.797']
400 ['0.613', '0.851']
500 ['0.608', '0.922']
600 ['0.605', '0.426']
700 ['0.609', '0.531']
800 ['0.610', '1.067']
900 ['0.607', '0.188']
1000 ['0.607', '0.326']
1100 ['0.605', '0.370']
1200 ['0.601', '0.554']
1300 ['0.600', '0.672']
1400 ['0.600', '0.369']
1500 ['0.595', '0.565']
1600 ['0.594', '0.390']
1700 ['0.603', '0.413']
1800 ['0.595', '0.198']
1900 ['0.601', '0.339']
2000 ['0.593', '0.318']
2100 ['0.593', '0.982']
2200 ['0.592', '0.135']
2300 ['0.596', '0.303']
2400 ['0.597', '0.630']
2500 ['0.596', '0.416']
2600 ['0.593', '0.916']
2700 ['0.594', '0.336']
2800 ['0.597', '0.310']
2900 ['0.595', '0.273']
3000 ['0.594', '0.182']
3100 ['0.598', '0.529']
3200 ['0.595', '0.340']
3300 ['0.597', '0.529']
3400 ['0.596', '0.152']
3500 ['0.597', '0.567']
3600 ['0.594', '0.190']
3700 ['0.592', '0.183']
Train: [1][3750/3750]	loss 0.062 (0.058)	Acc@1 87.500 (82.985)
0 ['0.590', '0.165']
100 ['0.595', '0.431']
200 ['0.595', '1.034']
300 ['0.594', '0.268']
400 ['0.594', '0.217']
500 ['0.592', '0.199']
600 ['0.594', '0.166']
700 ['0.593', '0.601']
800 ['0.594', '0.222']
900 ['0.596', '0.524']
1000 ['0.590', '0.431']
1100 ['0.596', '0.203']
1200 ['0.594', '0.645']
1300 ['0.590', '0.289']
1400 ['0.593', '0.257']
1500 ['0.590', '0.299']
1600 ['0.592', '0.709']
1700 ['0.591', '0.197']
1800 ['0.594', '0.288']
1900 ['0.593', '0.194']
2000 ['0.592', '0.273']
2100 ['0.593', '0.272']
2200 ['0.595', '0.792']
2300 ['0.594', '0.214']
2400 ['0.595', '0.750']
2500 ['0.596', '0.472']
2600 ['0.598', '0.363']
2700 ['0.597', '0.369']
2800 ['0.595', '0.148']
2900 ['0.595', '0.432']
3000 ['0.593', '0.302']
3100 ['0.595', '0.379']
3200 ['0.595', '0.694']
3300 ['0.596', '0.385']
3400 ['0.594', '0.257']
3500 ['0.599', '0.123']
3600 ['0.597', '0.292']
3700 ['0.594', '0.180']
Train: [2][3750/3750]	loss 0.049 (0.049)	Acc@1 87.500 (88.885)
0 ['0.596', '0.399']
100 ['0.594', '0.356']
200 ['0.597', '0.189']
300 ['0.596', '0.154']
400 ['0.599', '0.435']
500 ['0.596', '0.623']
600 ['0.598', '1.007']
700 ['0.594', '0.454']
800 ['0.596', '0.374']
900 ['0.595', '0.369']
1000 ['0.595', '0.911']
1100 ['0.595', '0.470']
1200 ['0.595', '0.402']
1300 ['0.598', '0.312']
1400 ['0.595', '0.324']
1500 ['0.598', '0.303']
1600 ['0.598', '0.473']
1700 ['0.594', '0.547']
1800 ['0.596', '0.328']
1900 ['0.595', '0.286']
2000 ['0.594', '0.245']
2100 ['0.593', '0.463']
2200 ['0.593', '0.257']
2300 ['0.596', '0.367']
2400 ['0.597', '0.155']
2500 ['0.598', '0.415']
2600 ['0.594', '0.324']
2700 ['0.596', '0.541']
2800 ['0.593', '0.170']
2900 ['0.592', '0.103']
3000 ['0.595', '0.398']
3100 ['0.595', '0.605']
3200 ['0.593', '0.278']
3300 ['0.597', '0.321']
3400 ['0.593', '0.268']
3500 ['0.594', '0.295']
3600 ['0.594', '0.148']
3700 ['0.595', '0.290']
Train: [3][3750/3750]	loss 0.039 (0.048)	Acc@1 100.000 (89.442)
0 ['0.597', '0.125']
100 ['0.595', '0.180']
200 ['0.594', '0.267']
300 ['0.593', '0.673']
400 ['0.594', '0.252']
500 ['0.596', '0.401']
600 ['0.599', '0.192']
700 ['0.598', '0.102']
800 ['0.597', '0.339']
900 ['0.596', '0.352']
1000 ['0.597', '0.271']
1100 ['0.600', '0.565']
1200 ['0.596', '0.557']
1300 ['0.593', '0.503']
1400 ['0.596', '0.317']
1500 ['0.593', '0.490']
1600 ['0.594', '0.490']
1700 ['0.595', '0.838']
1800 ['0.596', '0.653']
1900 ['0.594', '0.245']
2000 ['0.594', '0.361']
2100 ['0.597', '0.295']
2200 ['0.598', '0.411']
2300 ['0.595', '0.570']
2400 ['0.598', '0.229']
2500 ['0.594', '0.125']
2600 ['0.594', '0.129']
2700 ['0.592', '0.072']
2800 ['0.596', '0.275']
2900 ['0.595', '0.322']
3000 ['0.593', '0.294']
3100 ['0.597', '0.180']
3200 ['0.596', '0.383']
3300 ['0.595', '0.570']
3400 ['0.597', '0.351']
3500 ['0.596', '0.778']
3600 ['0.596', '0.399']
3700 ['0.595', '0.717']
Train: [4][3750/3750]	loss 0.063 (0.047)	Acc@1 81.250 (89.823)
0 ['0.598', '0.203']
100 ['0.596', '0.141']
200 ['0.593', '0.775']
300 ['0.598', '0.312']
400 ['0.594', '0.260']
500 ['0.596', '0.225']
600 ['0.597', '0.274']
700 ['0.597', '0.140']
800 ['0.597', '0.383']
900 ['0.595', '0.368']
1000 ['0.596', '0.365']
1100 ['0.593', '0.468']
1200 ['0.595', '0.264']
1300 ['0.600', '0.386']
1400 ['0.594', '0.175']
1500 ['0.598', '0.224']
1600 ['0.595', '1.104']
1700 ['0.597', '0.223']
1800 ['0.594', '0.464']
1900 ['0.595', '0.610']
2000 ['0.598', '0.302']
2100 ['0.596', '0.230']
2200 ['0.595', '0.329']
2300 ['0.594', '0.273']
2400 ['0.596', '0.371']
2500 ['0.596', '0.165']
2600 ['0.595', '0.330']
2700 ['0.595', '0.606']
2800 ['0.593', '0.397']
2900 ['0.593', '0.334']
3000 ['0.598', '0.245']
3100 ['0.597', '0.424']
3200 ['0.605', '0.217']
3300 ['0.598', '0.680']
3400 ['0.596', '0.418']
3500 ['0.597', '0.202']
3600 ['0.598', '0.501']
3700 ['0.597', '0.302']
Train: [5][3750/3750]	loss 0.035 (0.047)	Acc@1 100.000 (89.900)
Test model 1 on task 1
Test: [3/3]	loss 0.283 (0.294)	Acc@1 90.708 (90.350)
Test model 1 on task 2
Test: [3/3]	loss 0.193 (0.217)	Acc@1 94.137 (92.910)
Test model 1 on task 3
Test: [3/3]	loss 0.197 (0.195)	Acc@1 93.584 (93.860)
Test model 1 on task 4
Test: [3/3]	loss 0.209 (0.199)	Acc@1 93.308 (93.500)
Test model 1 on task 5
Test: [3/3]	loss 0.200 (0.191)	Acc@1 93.695 (94.290)
Test model 1 on task 6
Test: [3/3]	loss 0.172 (0.186)	Acc@1 94.192 (94.070)
Test model 1 on task 7
Test: [3/3]	loss 0.205 (0.187)	Acc@1 93.363 (94.130)
Test model 1 on task 8
Test: [3/3]	loss 0.177 (0.192)	Acc@1 94.690 (94.120)
Test model 1 on task 9
Test: [3/3]	loss 0.183 (0.201)	Acc@1 94.635 (94.090)
Test model 1 on task 10
Test: [3/3]	loss 0.210 (0.213)	Acc@1 93.584 (93.530)
Test model 1 on task 11
Test: [3/3]	loss 0.211 (0.212)	Acc@1 93.695 (93.700)
Test model 1 on task 12
Test: [3/3]	loss 0.230 (0.215)	Acc@1 92.588 (93.630)
Test model 1 on task 13
Test: [3/3]	loss 0.220 (0.220)	Acc@1 92.976 (93.600)
Test model 1 on task 14
Test: [3/3]	loss 0.248 (0.243)	Acc@1 91.980 (92.780)
Test model 1 on task 15
Test: [3/3]	loss 0.247 (0.245)	Acc@1 92.976 (92.790)
Test model 1 on task 16
Test: [3/3]	loss 0.276 (0.270)	Acc@1 91.482 (92.000)
Test model 1 on task 17
Test: [3/3]	loss 0.270 (0.274)	Acc@1 91.869 (91.920)
Test model 1 on task 18
Test: [3/3]	loss 0.290 (0.281)	Acc@1 91.482 (92.030)
Test model 1 on task 19
Test: [3/3]	loss 0.313 (0.323)	Acc@1 90.487 (90.250)
Test model 1 on task 20
Test: [3/3]	loss 0.343 (0.333)	Acc@1 89.712 (90.370)
############################################################ Avg acc: 92.90
Task 21 Model 1:
0 ['0.342', '4.382']
100 ['0.587', '1.492']
200 ['0.613', '1.225']
300 ['0.641', '1.178']
400 ['0.650', '1.050']
500 ['0.644', '0.577']
600 ['0.645', '0.837']
700 ['0.646', '0.452']
800 ['0.645', '1.052']
900 ['0.642', '0.653']
1000 ['0.642', '0.338']
1100 ['0.642', '0.424']
1200 ['0.642', '0.666']
1300 ['0.636', '0.350']
1400 ['0.635', '0.424']
1500 ['0.639', '0.118']
1600 ['0.636', '0.324']
1700 ['0.641', '0.250']
1800 ['0.640', '0.698']
1900 ['0.641', '0.633']
2000 ['0.641', '0.555']
2100 ['0.639', '0.305']
2200 ['0.637', '0.616']
2300 ['0.641', '1.041']
2400 ['0.640', '0.206']
2500 ['0.642', '0.162']
2600 ['0.640', '0.541']
2700 ['0.640', '0.583']
2800 ['0.644', '0.254']
2900 ['0.642', '0.213']
3000 ['0.641', '0.315']
3100 ['0.642', '0.843']
3200 ['0.642', '0.482']
3300 ['0.640', '0.497']
3400 ['0.639', '0.719']
3500 ['0.644', '0.502']
3600 ['0.642', '0.305']
3700 ['0.641', '0.541']
Train: [1][3750/3750]	loss 0.048 (0.059)	Acc@1 87.500 (81.117)
0 ['0.641', '0.340']
100 ['0.641', '0.331']
200 ['0.643', '0.322']
300 ['0.640', '0.619']
400 ['0.638', '0.128']
500 ['0.638', '0.522']
600 ['0.641', '0.749']
700 ['0.640', '1.188']
800 ['0.639', '0.525']
900 ['0.640', '0.517']
1000 ['0.643', '0.246']
1100 ['0.645', '0.172']
1200 ['0.645', '0.847']
1300 ['0.643', '0.579']
1400 ['0.644', '0.550']
1500 ['0.645', '0.437']
1600 ['0.648', '0.338']
1700 ['0.645', '0.315']
1800 ['0.646', '0.527']
1900 ['0.642', '0.597']
2000 ['0.644', '0.575']
2100 ['0.645', '0.261']
2200 ['0.644', '0.543']
2300 ['0.646', '0.772']
2400 ['0.645', '0.444']
2500 ['0.647', '0.520']
2600 ['0.645', '0.247']
2700 ['0.650', '0.372']
2800 ['0.650', '0.254']
2900 ['0.651', '0.269']
3000 ['0.645', '1.025']
3100 ['0.645', '0.233']
3200 ['0.646', '0.462']
3300 ['0.646', '0.341']
3400 ['0.643', '0.100']
3500 ['0.647', '0.567']
3600 ['0.645', '0.651']
3700 ['0.646', '0.608']
Train: [2][3750/3750]	loss 0.042 (0.051)	Acc@1 100.000 (87.445)
0 ['0.644', '0.561']
100 ['0.648', '0.972']
200 ['0.642', '0.275']
300 ['0.648', '0.268']
400 ['0.644', '0.756']
500 ['0.645', '0.300']
600 ['0.648', '0.309']
700 ['0.649', '0.630']
800 ['0.646', '0.948']
900 ['0.647', '0.194']
1000 ['0.644', '0.422']
1100 ['0.645', '1.117']
1200 ['0.645', '0.293']
1300 ['0.644', '0.448']
1400 ['0.648', '0.639']
1500 ['0.648', '0.217']
1600 ['0.647', '0.231']
1700 ['0.646', '0.188']
1800 ['0.644', '0.460']
1900 ['0.647', '0.598']
2000 ['0.646', '0.485']
2100 ['0.648', '0.194']
2200 ['0.647', '0.405']
2300 ['0.649', '0.695']
2400 ['0.647', '0.287']
2500 ['0.647', '0.589']
2600 ['0.647', '0.489']
2700 ['0.643', '0.542']
2800 ['0.651', '0.185']
2900 ['0.647', '0.227']
3000 ['0.648', '0.497']
3100 ['0.648', '0.281']
3200 ['0.650', '0.427']
3300 ['0.649', '0.334']
3400 ['0.645', '0.325']
3500 ['0.647', '0.281']
3600 ['0.645', '0.374']
3700 ['0.645', '1.072']
Train: [3][3750/3750]	loss 0.044 (0.050)	Acc@1 87.500 (88.240)
0 ['0.646', '0.366']
100 ['0.650', '0.105']
200 ['0.647', '0.295']
300 ['0.651', '0.338']
400 ['0.652', '0.481']
500 ['0.649', '0.193']
600 ['0.649', '0.144']
700 ['0.649', '0.900']
800 ['0.651', '0.254']
900 ['0.648', '0.876']
1000 ['0.647', '0.276']
1100 ['0.646', '0.424']
1200 ['0.646', '1.077']
1300 ['0.647', '0.315']
1400 ['0.647', '0.201']
1500 ['0.647', '0.772']
1600 ['0.651', '0.193']
1700 ['0.644', '0.387']
1800 ['0.648', '0.371']
1900 ['0.648', '0.242']
2000 ['0.645', '0.738']
2100 ['0.646', '0.238']
2200 ['0.646', '0.540']
2300 ['0.645', '0.512']
2400 ['0.644', '0.319']
2500 ['0.647', '0.222']
2600 ['0.647', '0.692']
2700 ['0.646', '0.332']
2800 ['0.645', '0.448']
2900 ['0.648', '0.161']
3000 ['0.649', '0.083']
3100 ['0.651', '0.071']
3200 ['0.647', '0.226']
3300 ['0.648', '0.356']
3400 ['0.646', '0.160']
3500 ['0.647', '0.248']
3600 ['0.646', '0.137']
3700 ['0.648', '0.407']
Train: [4][3750/3750]	loss 0.039 (0.049)	Acc@1 100.000 (88.698)
0 ['0.649', '0.243']
100 ['0.651', '0.303']
200 ['0.652', '0.943']
300 ['0.650', '0.680']
400 ['0.645', '0.311']
500 ['0.649', '0.260']
600 ['0.649', '0.300']
700 ['0.645', '0.176']
800 ['0.646', '0.726']
900 ['0.648', '0.102']
1000 ['0.644', '0.812']
1100 ['0.646', '0.361']
1200 ['0.651', '0.359']
1300 ['0.648', '0.218']
1400 ['0.649', '0.573']
1500 ['0.647', '0.683']
1600 ['0.651', '0.272']
1700 ['0.649', '0.357']
1800 ['0.646', '0.100']
1900 ['0.647', '0.563']
2000 ['0.647', '0.343']
2100 ['0.648', '0.875']
2200 ['0.650', '0.445']
2300 ['0.647', '0.781']
2400 ['0.646', '0.326']
2500 ['0.647', '0.142']
2600 ['0.647', '0.396']
2700 ['0.649', '0.250']
2800 ['0.649', '0.307']
2900 ['0.648', '0.682']
3000 ['0.647', '0.573']
3100 ['0.649', '0.563']
3200 ['0.649', '0.211']
3300 ['0.647', '0.119']
3400 ['0.649', '0.653']
3500 ['0.646', '0.372']
3600 ['0.651', '0.380']
3700 ['0.649', '0.878']
Train: [5][3750/3750]	loss 0.056 (0.049)	Acc@1 81.250 (88.997)
Test model 1 on task 1
Test: [3/3]	loss 0.295 (0.300)	Acc@1 89.934 (90.180)
Test model 1 on task 2
Test: [3/3]	loss 0.200 (0.219)	Acc@1 93.308 (92.810)
Test model 1 on task 3
Test: [3/3]	loss 0.201 (0.199)	Acc@1 93.363 (93.830)
Test model 1 on task 4
Test: [3/3]	loss 0.215 (0.203)	Acc@1 92.257 (93.350)
Test model 1 on task 5
Test: [3/3]	loss 0.193 (0.193)	Acc@1 94.524 (94.140)
Test model 1 on task 6
Test: [3/3]	loss 0.187 (0.190)	Acc@1 93.916 (93.910)
Test model 1 on task 7
Test: [3/3]	loss 0.209 (0.190)	Acc@1 93.308 (94.110)
Test model 1 on task 8
Test: [3/3]	loss 0.208 (0.197)	Acc@1 94.027 (93.880)
Test model 1 on task 9
Test: [3/3]	loss 0.205 (0.206)	Acc@1 93.639 (93.940)
Test model 1 on task 10
Test: [3/3]	loss 0.241 (0.219)	Acc@1 92.035 (93.350)
Test model 1 on task 11
Test: [3/3]	loss 0.212 (0.218)	Acc@1 93.805 (93.420)
Test model 1 on task 12
Test: [3/3]	loss 0.216 (0.219)	Acc@1 93.805 (93.310)
Test model 1 on task 13
Test: [3/3]	loss 0.226 (0.224)	Acc@1 93.639 (93.380)
Test model 1 on task 14
Test: [3/3]	loss 0.247 (0.248)	Acc@1 93.086 (92.640)
Test model 1 on task 15
Test: [3/3]	loss 0.250 (0.249)	Acc@1 92.865 (92.620)
Test model 1 on task 16
Test: [3/3]	loss 0.272 (0.275)	Acc@1 91.538 (91.660)
Test model 1 on task 17
Test: [3/3]	loss 0.281 (0.275)	Acc@1 91.869 (91.830)
Test model 1 on task 18
Test: [3/3]	loss 0.296 (0.287)	Acc@1 92.091 (91.800)
Test model 1 on task 19
Test: [3/3]	loss 0.312 (0.326)	Acc@1 90.210 (90.130)
Test model 1 on task 20
Test: [3/3]	loss 0.337 (0.338)	Acc@1 91.095 (90.300)
Test model 1 on task 21
Test: [3/3]	loss 0.379 (0.364)	Acc@1 89.270 (89.460)
############################################################ Avg acc: 92.57
Task 22 Model 1:
0 ['0.374', '4.408']
100 ['0.600', '1.790']
200 ['0.645', '1.278']
300 ['0.676', '0.800']
400 ['0.682', '0.765']
500 ['0.687', '0.617']
600 ['0.688', '1.072']
700 ['0.687', '0.722']
800 ['0.695', '0.996']
900 ['0.691', '0.607']
1000 ['0.687', '0.909']
1100 ['0.684', '0.910']
1200 ['0.698', '0.426']
1300 ['0.697', '0.394']
1400 ['0.695', '0.354']
1500 ['0.693', '0.602']
1600 ['0.695', '0.473']
1700 ['0.693', '0.499']
1800 ['0.697', '0.993']
1900 ['0.693', '0.212']
2000 ['0.694', '0.259']
2100 ['0.693', '0.817']
2200 ['0.698', '0.408']
2300 ['0.698', '0.483']
2400 ['0.692', '0.500']
2500 ['0.693', '0.443']
2600 ['0.697', '0.330']
2700 ['0.694', '0.212']
2800 ['0.695', '0.544']
2900 ['0.692', '0.327']
3000 ['0.694', '0.619']
3100 ['0.693', '0.401']
3200 ['0.696', '0.383']
3300 ['0.696', '0.597']
3400 ['0.697', '0.488']
3500 ['0.701', '0.684']
3600 ['0.693', '0.647']
3700 ['0.698', '0.963']
Train: [1][3750/3750]	loss 0.047 (0.061)	Acc@1 87.500 (79.413)
0 ['0.699', '0.387']
100 ['0.700', '0.386']
200 ['0.700', '0.659']
300 ['0.699', '0.438']
400 ['0.702', '0.502']
500 ['0.698', '0.990']
600 ['0.700', '0.624']
700 ['0.701', '0.291']
800 ['0.698', '0.319']
900 ['0.698', '0.636']
1000 ['0.701', '0.243']
1100 ['0.700', '0.263']
1200 ['0.697', '0.758']
1300 ['0.702', '0.487']
1400 ['0.704', '0.481']
1500 ['0.701', '0.301']
1600 ['0.700', '0.174']
1700 ['0.705', '0.438']
1800 ['0.701', '0.218']
1900 ['0.705', '0.265']
2000 ['0.703', '0.474']
2100 ['0.700', '0.265']
2200 ['0.700', '0.490']
2300 ['0.702', '0.567']
2400 ['0.704', '0.191']
2500 ['0.706', '0.264']
2600 ['0.703', '0.458']
2700 ['0.703', '0.612']
2800 ['0.700', '0.604']
2900 ['0.709', '0.472']
3000 ['0.704', '0.589']
3100 ['0.705', '0.259']
3200 ['0.707', '0.195']
3300 ['0.703', '0.416']
3400 ['0.712', '0.126']
3500 ['0.705', '0.321']
3600 ['0.704', '0.745']
3700 ['0.706', '0.333']
Train: [2][3750/3750]	loss 0.053 (0.053)	Acc@1 81.250 (85.835)
0 ['0.707', '0.398']
100 ['0.707', '0.205']
200 ['0.706', '0.596']
300 ['0.711', '0.337']
400 ['0.707', '0.348']
500 ['0.705', '0.538']
600 ['0.702', '0.299']
700 ['0.706', '0.087']
800 ['0.702', '1.260']
900 ['0.705', '0.319']
1000 ['0.706', '0.360']
1100 ['0.705', '0.664']
1200 ['0.707', '0.372']
1300 ['0.707', '0.430']
1400 ['0.709', '0.521']
1500 ['0.707', '0.189']
1600 ['0.706', '0.421']
1700 ['0.704', '0.590']
1800 ['0.703', '0.163']
1900 ['0.706', '0.255']
2000 ['0.708', '0.364']
2100 ['0.705', '0.570']
2200 ['0.713', '0.378']
2300 ['0.710', '0.370']
2400 ['0.711', '0.641']
2500 ['0.707', '0.343']
2600 ['0.705', '0.133']
2700 ['0.705', '0.483']
2800 ['0.708', '0.660']
2900 ['0.704', '0.447']
3000 ['0.704', '0.457']
3100 ['0.703', '0.828']
3200 ['0.708', '0.493']
3300 ['0.710', '0.245']
3400 ['0.710', '0.246']
3500 ['0.708', '0.353']
3600 ['0.711', '0.481']
3700 ['0.708', '0.481']
Train: [3][3750/3750]	loss 0.051 (0.053)	Acc@1 87.500 (86.457)
0 ['0.710', '0.300']
100 ['0.709', '0.931']
200 ['0.703', '0.235']
300 ['0.708', '0.325']
400 ['0.705', '0.396']
500 ['0.702', '0.427']
600 ['0.704', '0.471']
700 ['0.700', '0.312']
800 ['0.705', '0.210']
900 ['0.704', '0.120']
1000 ['0.710', '0.831']
1100 ['0.703', '0.432']
1200 ['0.700', '0.301']
1300 ['0.704', '0.746']
1400 ['0.704', '0.565']
1500 ['0.706', '0.301']
1600 ['0.707', '0.786']
1700 ['0.710', '0.587']
1800 ['0.706', '0.636']
1900 ['0.711', '0.406']
2000 ['0.713', '0.433']
2100 ['0.707', '0.706']
2200 ['0.708', '0.488']
2300 ['0.708', '0.619']
2400 ['0.705', '0.766']
2500 ['0.707', '0.445']
2600 ['0.707', '0.728']
2700 ['0.708', '0.183']
2800 ['0.707', '0.319']
2900 ['0.709', '0.095']
3000 ['0.706', '0.307']
3100 ['0.708', '0.298']
3200 ['0.708', '0.415']
3300 ['0.711', '0.272']
3400 ['0.710', '0.515']
3500 ['0.710', '0.355']
3600 ['0.711', '0.374']
3700 ['0.713', '0.810']
Train: [4][3750/3750]	loss 0.046 (0.052)	Acc@1 87.500 (86.728)
0 ['0.711', '0.459']
100 ['0.713', '0.297']
200 ['0.709', '0.242']
300 ['0.710', '0.476']
400 ['0.708', '0.410']
500 ['0.706', '0.384']
600 ['0.705', '0.282']
700 ['0.705', '0.614']
800 ['0.709', '0.317']
900 ['0.707', '0.441']
1000 ['0.711', '0.713']
1100 ['0.709', '0.330']
1200 ['0.712', '0.473']
1300 ['0.708', '0.802']
1400 ['0.713', '0.640']
1500 ['0.710', '0.188']
1600 ['0.710', '0.413']
1700 ['0.710', '0.734']
1800 ['0.711', '0.313']
1900 ['0.707', '0.568']
2000 ['0.707', '0.434']
2100 ['0.709', '0.504']
2200 ['0.706', '0.457']
2300 ['0.706', '0.594']
2400 ['0.714', '0.373']
2500 ['0.712', '0.367']
2600 ['0.715', '0.718']
2700 ['0.713', '0.749']
2800 ['0.714', '0.449']
2900 ['0.709', '0.315']
3000 ['0.712', '0.483']
3100 ['0.712', '0.257']
3200 ['0.711', '0.142']
3300 ['0.706', '0.466']
3400 ['0.709', '0.318']
3500 ['0.708', '0.363']
3600 ['0.709', '0.492']
3700 ['0.706', '0.356']
Train: [5][3750/3750]	loss 0.047 (0.052)	Acc@1 81.250 (86.935)
Test model 1 on task 1
Test: [3/3]	loss 0.313 (0.302)	Acc@1 89.768 (90.100)
Test model 1 on task 2
Test: [3/3]	loss 0.201 (0.221)	Acc@1 93.418 (92.690)
Test model 1 on task 3
Test: [3/3]	loss 0.207 (0.200)	Acc@1 93.695 (93.750)
Test model 1 on task 4
Test: [3/3]	loss 0.220 (0.206)	Acc@1 92.588 (93.270)
Test model 1 on task 5
Test: [3/3]	loss 0.208 (0.196)	Acc@1 93.695 (94.080)
Test model 1 on task 6
Test: [3/3]	loss 0.180 (0.192)	Acc@1 94.580 (93.780)
Test model 1 on task 7
Test: [3/3]	loss 0.200 (0.194)	Acc@1 93.750 (93.940)
Test model 1 on task 8
Test: [3/3]	loss 0.202 (0.201)	Acc@1 93.639 (93.730)
Test model 1 on task 9
Test: [3/3]	loss 0.215 (0.208)	Acc@1 93.750 (93.810)
Test model 1 on task 10
Test: [3/3]	loss 0.230 (0.223)	Acc@1 93.031 (93.190)
Test model 1 on task 11
Test: [3/3]	loss 0.204 (0.222)	Acc@1 93.363 (93.210)
Test model 1 on task 12
Test: [3/3]	loss 0.223 (0.224)	Acc@1 93.418 (93.310)
Test model 1 on task 13
Test: [3/3]	loss 0.220 (0.228)	Acc@1 93.529 (93.300)
Test model 1 on task 14
Test: [3/3]	loss 0.267 (0.254)	Acc@1 91.538 (92.170)
Test model 1 on task 15
Test: [3/3]	loss 0.239 (0.253)	Acc@1 92.754 (92.520)
Test model 1 on task 16
Test: [3/3]	loss 0.280 (0.281)	Acc@1 91.427 (91.500)
Test model 1 on task 17
Test: [3/3]	loss 0.261 (0.279)	Acc@1 92.201 (91.770)
Test model 1 on task 18
Test: [3/3]	loss 0.298 (0.292)	Acc@1 91.261 (91.670)
Test model 1 on task 19
Test: [3/3]	loss 0.338 (0.331)	Acc@1 89.934 (89.910)
Test model 1 on task 20
Test: [3/3]	loss 0.322 (0.344)	Acc@1 90.542 (90.070)
Test model 1 on task 21
Test: [3/3]	loss 0.396 (0.369)	Acc@1 87.777 (89.150)
Test model 1 on task 22
Test: [3/3]	loss 0.432 (0.416)	Acc@1 87.721 (87.700)
############################################################ Avg acc: 92.21
Task 23 Model 1:
0 ['0.433', '3.994']
100 ['0.722', '1.552']
200 ['0.754', '0.865']
300 ['0.772', '0.785']
400 ['0.774', '0.630']
500 ['0.763', '0.624']
600 ['0.769', '0.454']
700 ['0.769', '0.786']
800 ['0.767', '0.320']
900 ['0.769', '1.021']
1000 ['0.768', '0.581']
1100 ['0.768', '0.569']
1200 ['0.769', '0.548']
1300 ['0.774', '0.451']
1400 ['0.771', '0.330']
1500 ['0.769', '0.355']
1600 ['0.764', '0.525']
1700 ['0.769', '0.435']
1800 ['0.770', '0.611']
1900 ['0.762', '0.421']
2000 ['0.766', '0.603']
2100 ['0.770', '0.240']
2200 ['0.766', '0.461']
2300 ['0.770', '0.648']
2400 ['0.771', '0.329']
2500 ['0.769', '0.555']
2600 ['0.773', '0.524']
2700 ['0.774', '0.488']
2800 ['0.775', '0.430']
2900 ['0.770', '0.606']
3000 ['0.771', '0.339']
3100 ['0.769', '0.348']
3200 ['0.768', '0.523']
3300 ['0.766', '0.551']
3400 ['0.767', '0.343']
3500 ['0.771', '0.343']
3600 ['0.772', '0.314']
3700 ['0.770', '0.378']
Train: [1][3750/3750]	loss 0.049 (0.061)	Acc@1 87.500 (80.310)
0 ['0.768', '0.816']
100 ['0.772', '0.617']
200 ['0.775', '0.141']
300 ['0.770', '0.105']
400 ['0.774', '0.561']
500 ['0.778', '0.361']
600 ['0.770', '0.286']
700 ['0.776', '0.542']
800 ['0.772', '0.919']
900 ['0.772', '0.603']
1000 ['0.774', '0.490']
1100 ['0.778', '0.195']
1200 ['0.775', '0.647']
1300 ['0.771', '0.382']
1400 ['0.773', '0.185']
1500 ['0.776', '0.471']
1600 ['0.772', '0.618']
1700 ['0.779', '0.685']
1800 ['0.774', '0.388']
1900 ['0.779', '0.233']
2000 ['0.774', '0.383']
2100 ['0.780', '0.342']
2200 ['0.780', '0.422']
2300 ['0.785', '0.320']
2400 ['0.777', '0.380']
2500 ['0.779', '0.472']
2600 ['0.775', '0.334']
2700 ['0.776', '0.589']
2800 ['0.778', '0.281']
2900 ['0.777', '0.299']
3000 ['0.780', '0.704']
3100 ['0.775', '0.393']
3200 ['0.773', '0.604']
3300 ['0.777', '0.367']
3400 ['0.777', '0.280']
3500 ['0.776', '0.739']
3600 ['0.779', '0.401']
3700 ['0.776', '0.484']
Train: [2][3750/3750]	loss 0.061 (0.054)	Acc@1 81.250 (86.337)
0 ['0.781', '0.448']
100 ['0.777', '0.752']
200 ['0.781', '0.160']
300 ['0.782', '0.410']
400 ['0.781', '0.497']
500 ['0.781', '0.871']
600 ['0.783', '0.782']
700 ['0.774', '0.561']
800 ['0.775', '0.251']
900 ['0.781', '0.473']
1000 ['0.780', '0.730']
1100 ['0.785', '0.371']
1200 ['0.783', '0.271']
1300 ['0.780', '0.418']
1400 ['0.778', '0.440']
1500 ['0.783', '0.773']
1600 ['0.782', '0.376']
1700 ['0.782', '0.391']
1800 ['0.782', '0.586']
1900 ['0.780', '0.345']
2000 ['0.774', '0.406']
2100 ['0.777', '0.352']
2200 ['0.777', '0.482']
2300 ['0.782', '0.344']
2400 ['0.779', '0.308']
2500 ['0.780', '0.387']
2600 ['0.775', '0.383']
2700 ['0.778', '0.306']
2800 ['0.779', '0.216']
2900 ['0.773', '0.408']
3000 ['0.774', '0.164']
3100 ['0.778', '0.284']
3200 ['0.777', '0.809']
3300 ['0.779', '0.243']
3400 ['0.780', '0.484']
3500 ['0.776', '0.238']
3600 ['0.776', '0.448']
3700 ['0.779', '0.403']
Train: [3][3750/3750]	loss 0.070 (0.053)	Acc@1 75.000 (86.907)
0 ['0.777', '0.485']
100 ['0.776', '0.324']
200 ['0.780', '0.310']
300 ['0.785', '0.490']
400 ['0.778', '0.304']
500 ['0.777', '0.519']
600 ['0.781', '0.473']
700 ['0.779', '0.330']
800 ['0.783', '0.433']
900 ['0.775', '0.406']
1000 ['0.776', '0.492']
1100 ['0.775', '0.441']
1200 ['0.776', '0.165']
1300 ['0.777', '0.255']
1400 ['0.780', '0.305']
1500 ['0.779', '0.719']
1600 ['0.782', '0.382']
1700 ['0.782', '0.679']
1800 ['0.778', '0.537']
1900 ['0.775', '0.330']
2000 ['0.776', '0.335']
2100 ['0.777', '0.266']
2200 ['0.779', '0.147']
2300 ['0.779', '0.312']
2400 ['0.779', '0.371']
2500 ['0.782', '0.621']
2600 ['0.777', '0.190']
2700 ['0.776', '0.288']
2800 ['0.777', '0.533']
2900 ['0.779', '0.442']
3000 ['0.780', '0.466']
3100 ['0.779', '0.249']
3200 ['0.775', '0.183']
3300 ['0.779', '0.401']
3400 ['0.778', '0.325']
3500 ['0.777', '0.301']
3600 ['0.778', '0.336']
3700 ['0.778', '0.203']
Train: [4][3750/3750]	loss 0.065 (0.053)	Acc@1 68.750 (87.075)
0 ['0.779', '0.506']
100 ['0.779', '0.362']
200 ['0.778', '0.379']
300 ['0.779', '0.323']
400 ['0.778', '0.373']
500 ['0.779', '0.123']
600 ['0.777', '0.400']
700 ['0.775', '0.567']
800 ['0.777', '0.199']
900 ['0.776', '0.242']
1000 ['0.781', '0.559']
1100 ['0.779', '0.278']
1200 ['0.779', '0.288']
1300 ['0.786', '0.498']
1400 ['0.780', '0.441']
1500 ['0.782', '0.324']
1600 ['0.779', '0.385']
1700 ['0.779', '0.482']
1800 ['0.781', '0.485']
1900 ['0.782', '0.338']
2000 ['0.780', '0.720']
2100 ['0.777', '0.523']
2200 ['0.780', '0.549']
2300 ['0.783', '0.345']
2400 ['0.780', '0.140']
2500 ['0.783', '0.410']
2600 ['0.781', '0.293']
2700 ['0.779', '0.644']
2800 ['0.781', '0.500']
2900 ['0.781', '0.304']
3000 ['0.778', '0.280']
3100 ['0.776', '0.411']
3200 ['0.779', '0.560']
3300 ['0.778', '0.860']
3400 ['0.777', '0.555']
3500 ['0.776', '0.501']
3600 ['0.779', '0.651']
3700 ['0.778', '0.490']
Train: [5][3750/3750]	loss 0.050 (0.053)	Acc@1 87.500 (87.312)
Test model 1 on task 1
Test: [3/3]	loss 0.311 (0.308)	Acc@1 89.768 (89.930)
Test model 1 on task 2
Test: [3/3]	loss 0.236 (0.226)	Acc@1 92.201 (92.570)
Test model 1 on task 3
Test: [3/3]	loss 0.195 (0.204)	Acc@1 93.197 (93.620)
Test model 1 on task 4
Test: [3/3]	loss 0.223 (0.211)	Acc@1 92.976 (93.090)
Test model 1 on task 5
Test: [3/3]	loss 0.204 (0.199)	Acc@1 93.695 (93.970)
Test model 1 on task 6
Test: [3/3]	loss 0.195 (0.195)	Acc@1 93.750 (93.830)
Test model 1 on task 7
Test: [3/3]	loss 0.207 (0.197)	Acc@1 93.695 (93.840)
Test model 1 on task 8
Test: [3/3]	loss 0.187 (0.205)	Acc@1 93.805 (93.570)
Test model 1 on task 9
Test: [3/3]	loss 0.217 (0.214)	Acc@1 93.252 (93.540)
Test model 1 on task 10
Test: [3/3]	loss 0.239 (0.225)	Acc@1 93.197 (93.120)
Test model 1 on task 11
Test: [3/3]	loss 0.232 (0.223)	Acc@1 93.418 (93.270)
Test model 1 on task 12
Test: [3/3]	loss 0.222 (0.228)	Acc@1 93.197 (93.110)
Test model 1 on task 13
Test: [3/3]	loss 0.230 (0.233)	Acc@1 93.584 (93.110)
Test model 1 on task 14
Test: [3/3]	loss 0.251 (0.257)	Acc@1 92.257 (92.180)
Test model 1 on task 15
Test: [3/3]	loss 0.273 (0.257)	Acc@1 91.482 (92.280)
Test model 1 on task 16
Test: [3/3]	loss 0.280 (0.284)	Acc@1 91.316 (91.430)
Test model 1 on task 17
Test: [3/3]	loss 0.294 (0.281)	Acc@1 91.427 (91.760)
Test model 1 on task 18
Test: [3/3]	loss 0.304 (0.296)	Acc@1 90.431 (91.280)
Test model 1 on task 19
Test: [3/3]	loss 0.340 (0.334)	Acc@1 89.491 (89.780)
Test model 1 on task 20
Test: [3/3]	loss 0.362 (0.350)	Acc@1 89.712 (89.680)
Test model 1 on task 21
Test: [3/3]	loss 0.382 (0.373)	Acc@1 88.662 (89.140)
Test model 1 on task 22
Test: [3/3]	loss 0.422 (0.422)	Acc@1 86.836 (87.620)
Test model 1 on task 23
Test: [3/3]	loss 0.430 (0.408)	Acc@1 87.279 (88.010)
############################################################ Avg acc: 91.90
Task 24 Model 1:
0 ['0.421', '4.196']
100 ['0.648', '1.252']
200 ['0.711', '0.848']
300 ['0.740', '0.958']
400 ['0.740', '0.483']
500 ['0.741', '1.243']
600 ['0.751', '0.376']
700 ['0.753', '0.577']
800 ['0.752', '1.014']
900 ['0.754', '0.407']
1000 ['0.750', '0.551']
1100 ['0.749', '0.739']
1200 ['0.751', '0.499']
1300 ['0.751', '0.408']
1400 ['0.749', '0.621']
1500 ['0.748', '0.746']
1600 ['0.756', '0.360']
1700 ['0.758', '0.252']
1800 ['0.756', '0.440']
1900 ['0.754', '0.380']
2000 ['0.762', '0.461']
2100 ['0.767', '0.422']
2200 ['0.758', '0.481']
2300 ['0.757', '0.599']
2400 ['0.757', '0.546']
2500 ['0.763', '0.419']
2600 ['0.763', '0.647']
2700 ['0.758', '0.577']
2800 ['0.755', '0.740']
2900 ['0.758', '0.325']
3000 ['0.763', '0.214']
3100 ['0.763', '0.517']
3200 ['0.762', '0.838']
3300 ['0.768', '0.717']
3400 ['0.762', '0.653']
3500 ['0.762', '0.208']
3600 ['0.764', '0.701']
3700 ['0.763', '0.660']
Train: [1][3750/3750]	loss 0.048 (0.059)	Acc@1 87.500 (79.183)
0 ['0.765', '0.580']
100 ['0.765', '0.729']
200 ['0.771', '0.505']
300 ['0.762', '0.690']
400 ['0.767', '0.133']
500 ['0.764', '0.540']
600 ['0.770', '0.840']
700 ['0.770', '0.384']
800 ['0.770', '0.432']
900 ['0.766', '0.391']
1000 ['0.761', '0.213']
1100 ['0.767', '0.293']
1200 ['0.769', '0.238']
1300 ['0.766', '0.422']
1400 ['0.769', '0.663']
1500 ['0.769', '0.482']
1600 ['0.774', '0.313']
1700 ['0.777', '0.337']
1800 ['0.778', '0.526']
1900 ['0.774', '0.520']
2000 ['0.770', '0.402']
2100 ['0.769', '0.202']
2200 ['0.770', '0.414']
2300 ['0.772', '0.452']
2400 ['0.768', '0.722']
2500 ['0.769', '0.426']
2600 ['0.770', '0.514']
2700 ['0.770', '0.276']
2800 ['0.771', '0.631']
2900 ['0.770', '0.259']
3000 ['0.770', '0.581']
3100 ['0.765', '0.649']
3200 ['0.764', '0.356']
3300 ['0.769', '0.490']
3400 ['0.770', '0.302']
3500 ['0.772', '0.514']
3600 ['0.772', '0.824']
3700 ['0.771', '0.384']
Train: [2][3750/3750]	loss 0.046 (0.053)	Acc@1 93.750 (84.632)
0 ['0.777', '0.228']
100 ['0.773', '0.288']
200 ['0.772', '0.289']
300 ['0.774', '0.716']
400 ['0.774', '0.622']
500 ['0.777', '0.504']
600 ['0.774', '0.500']
700 ['0.769', '0.462']
800 ['0.772', '0.403']
900 ['0.771', '0.259']
1000 ['0.776', '0.360']
1100 ['0.780', '0.153']
1200 ['0.777', '0.333']
1300 ['0.774', '0.286']
1400 ['0.776', '0.645']
1500 ['0.779', '0.565']
1600 ['0.773', '0.177']
1700 ['0.773', '0.557']
1800 ['0.775', '0.715']
1900 ['0.773', '0.804']
2000 ['0.769', '1.002']
2100 ['0.772', '0.355']
2200 ['0.774', '0.279']
2300 ['0.773', '0.573']
2400 ['0.777', '0.310']
2500 ['0.771', '0.675']
2600 ['0.773', '0.660']
2700 ['0.776', '0.634']
2800 ['0.778', '0.515']
2900 ['0.775', '0.126']
3000 ['0.780', '0.261']
3100 ['0.779', '0.573']
3200 ['0.774', '0.250']
3300 ['0.775', '0.505']
3400 ['0.773', '0.432']
3500 ['0.775', '0.426']
3600 ['0.771', '0.486']
3700 ['0.773', '0.280']
Train: [3][3750/3750]	loss 0.076 (0.052)	Acc@1 75.000 (85.320)
0 ['0.773', '0.189']
100 ['0.771', '0.337']
200 ['0.774', '0.226']
300 ['0.778', '0.469']
400 ['0.775', '0.704']
500 ['0.781', '0.534']
600 ['0.775', '0.272']
700 ['0.772', '0.892']
800 ['0.774', '0.548']
900 ['0.776', '0.372']
1000 ['0.777', '0.435']
1100 ['0.777', '0.191']
1200 ['0.775', '0.963']
1300 ['0.776', '0.202']
1400 ['0.778', '0.794']
1500 ['0.777', '0.530']
1600 ['0.776', '0.443']
1700 ['0.779', '0.287']
1800 ['0.778', '0.463']
1900 ['0.778', '0.239']
2000 ['0.777', '0.806']
2100 ['0.778', '0.556']
2200 ['0.778', '0.439']
2300 ['0.774', '0.449']
2400 ['0.775', '0.241']
2500 ['0.776', '0.665']
2600 ['0.778', '0.348']
2700 ['0.775', '0.716']
2800 ['0.777', '1.155']
2900 ['0.774', '0.445']
3000 ['0.777', '0.861']
3100 ['0.777', '0.705']
3200 ['0.778', '0.269']
3300 ['0.776', '0.304']
3400 ['0.780', '0.514']
3500 ['0.775', '0.422']
3600 ['0.775', '0.771']
3700 ['0.778', '0.170']
Train: [4][3750/3750]	loss 0.048 (0.052)	Acc@1 87.500 (85.508)
0 ['0.777', '0.424']
100 ['0.778', '0.700']
200 ['0.774', '0.683']
300 ['0.776', '0.252']
400 ['0.772', '0.425']
500 ['0.776', '0.264']
600 ['0.778', '0.323']
700 ['0.779', '0.276']
800 ['0.783', '0.349']
900 ['0.777', '0.372']
1000 ['0.776', '0.382']
1100 ['0.776', '0.320']
1200 ['0.780', '0.258']
1300 ['0.776', '0.370']
1400 ['0.776', '0.407']
1500 ['0.779', '0.264']
1600 ['0.781', '0.364']
1700 ['0.775', '0.465']
1800 ['0.774', '0.750']
1900 ['0.775', '0.289']
2000 ['0.778', '0.427']
2100 ['0.776', '0.182']
2200 ['0.781', '0.432']
2300 ['0.778', '0.607']
2400 ['0.780', '0.304']
2500 ['0.783', '0.481']
2600 ['0.780', '0.368']
2700 ['0.776', '0.645']
2800 ['0.782', '0.651']
2900 ['0.776', '0.333']
3000 ['0.777', '0.557']
3100 ['0.777', '0.230']
3200 ['0.771', '0.565']
3300 ['0.774', '0.383']
3400 ['0.777', '0.752']
3500 ['0.774', '0.499']
3600 ['0.778', '0.323']
3700 ['0.776', '0.277']
Train: [5][3750/3750]	loss 0.050 (0.052)	Acc@1 87.500 (85.613)
Test model 1 on task 1
Test: [3/3]	loss 0.307 (0.312)	Acc@1 90.100 (89.880)
Test model 1 on task 2
Test: [3/3]	loss 0.231 (0.227)	Acc@1 92.533 (92.510)
Test model 1 on task 3
Test: [3/3]	loss 0.218 (0.207)	Acc@1 93.197 (93.460)
Test model 1 on task 4
Test: [3/3]	loss 0.239 (0.214)	Acc@1 91.704 (92.930)
Test model 1 on task 5
Test: [3/3]	loss 0.190 (0.200)	Acc@1 94.027 (93.920)
Test model 1 on task 6
Test: [3/3]	loss 0.219 (0.198)	Acc@1 93.308 (93.810)
Test model 1 on task 7
Test: [3/3]	loss 0.184 (0.200)	Acc@1 94.414 (93.830)
Test model 1 on task 8
Test: [3/3]	loss 0.209 (0.208)	Acc@1 93.695 (93.570)
Test model 1 on task 9
Test: [3/3]	loss 0.210 (0.218)	Acc@1 93.308 (93.420)
Test model 1 on task 10
Test: [3/3]	loss 0.256 (0.227)	Acc@1 92.035 (93.170)
Test model 1 on task 11
Test: [3/3]	loss 0.246 (0.227)	Acc@1 92.754 (93.050)
Test model 1 on task 12
Test: [3/3]	loss 0.251 (0.232)	Acc@1 92.257 (92.990)
Test model 1 on task 13
Test: [3/3]	loss 0.221 (0.235)	Acc@1 93.695 (92.980)
Test model 1 on task 14
Test: [3/3]	loss 0.251 (0.261)	Acc@1 92.699 (91.980)
Test model 1 on task 15
Test: [3/3]	loss 0.265 (0.259)	Acc@1 91.980 (92.140)
Test model 1 on task 16
Test: [3/3]	loss 0.295 (0.288)	Acc@1 91.538 (91.180)
Test model 1 on task 17
Test: [3/3]	loss 0.254 (0.284)	Acc@1 92.920 (91.540)
Test model 1 on task 18
Test: [3/3]	loss 0.290 (0.301)	Acc@1 91.538 (91.200)
Test model 1 on task 19
Test: [3/3]	loss 0.332 (0.337)	Acc@1 90.542 (89.760)
Test model 1 on task 20
Test: [3/3]	loss 0.351 (0.354)	Acc@1 89.934 (89.710)
Test model 1 on task 21
Test: [3/3]	loss 0.362 (0.378)	Acc@1 89.381 (88.950)
Test model 1 on task 22
Test: [3/3]	loss 0.431 (0.428)	Acc@1 87.168 (87.320)
Test model 1 on task 23
Test: [3/3]	loss 0.401 (0.413)	Acc@1 88.827 (87.910)
Test model 1 on task 24
Test: [3/3]	loss 0.448 (0.452)	Acc@1 86.615 (86.080)
############################################################ Avg acc: 91.55
Task 25 Model 1:
0 ['0.468', '3.862']
100 ['0.727', '1.583']
200 ['0.786', '1.225']
300 ['0.799', '0.892']
400 ['0.811', '0.492']
500 ['0.814', '0.829']
600 ['0.826', '0.549']
700 ['0.824', '1.009']
800 ['0.827', '0.632']
900 ['0.827', '0.826']
1000 ['0.828', '0.934']
1100 ['0.827', '0.516']
1200 ['0.832', '0.627']
1300 ['0.844', '0.910']
1400 ['0.835', '0.684']
1500 ['0.845', '0.163']
1600 ['0.845', '0.307']
1700 ['0.847', '0.643']
1800 ['0.846', '1.094']
1900 ['0.841', '0.452']
2000 ['0.841', '0.367']
2100 ['0.844', '0.245']
2200 ['0.844', '0.523']
2300 ['0.844', '0.873']
2400 ['0.851', '0.618']
2500 ['0.858', '0.625']
2600 ['0.857', '0.562']
2700 ['0.860', '0.413']
2800 ['0.857', '0.394']
2900 ['0.856', '0.102']
3000 ['0.864', '0.301']
3100 ['0.862', '0.484']
3200 ['0.860', '0.650']
3300 ['0.862', '0.998']
3400 ['0.863', '0.950']
3500 ['0.863', '0.368']
3600 ['0.865', '0.877']
3700 ['0.856', '0.495']
Train: [1][3750/3750]	loss 0.063 (0.062)	Acc@1 81.250 (77.533)
0 ['0.863', '0.400']
100 ['0.862', '0.651']
200 ['0.867', '0.283']
300 ['0.865', '0.267']
400 ['0.860', '0.257']
500 ['0.859', '0.454']
600 ['0.859', '0.413']
700 ['0.862', '0.395']
800 ['0.865', '0.558']
900 ['0.867', '0.578']
1000 ['0.869', '0.305']
1100 ['0.865', '0.494']
1200 ['0.868', '0.452']
1300 ['0.867', '0.317']
1400 ['0.871', '1.136']
1500 ['0.868', '0.708']
1600 ['0.867', '0.288']
1700 ['0.866', '0.470']
1800 ['0.869', '0.803']
1900 ['0.871', '0.580']
2000 ['0.870', '0.175']
2100 ['0.873', '0.221']
2200 ['0.866', '0.157']
2300 ['0.870', '0.273']
2400 ['0.869', '0.834']
2500 ['0.868', '0.465']
2600 ['0.869', '0.508']
2700 ['0.869', '0.289']
2800 ['0.869', '0.369']
2900 ['0.868', '0.386']
3000 ['0.868', '0.472']
3100 ['0.872', '0.774']
3200 ['0.868', '0.380']
3300 ['0.877', '0.615']
3400 ['0.866', '0.241']
3500 ['0.865', '1.193']
3600 ['0.863', '0.930']
3700 ['0.870', '0.711']
Train: [2][3750/3750]	loss 0.048 (0.056)	Acc@1 93.750 (83.937)
0 ['0.875', '0.424']
100 ['0.872', '0.181']
200 ['0.873', '0.386']
300 ['0.866', '0.281']
400 ['0.870', '0.307']
500 ['0.876', '0.666']
600 ['0.872', '1.007']
700 ['0.874', '0.686']
800 ['0.872', '0.744']
900 ['0.867', '0.159']
1000 ['0.869', '0.646']
1100 ['0.870', '0.407']
1200 ['0.874', '0.441']
1300 ['0.872', '0.431']
1400 ['0.874', '0.376']
1500 ['0.873', '0.856']
1600 ['0.873', '0.834']
1700 ['0.872', '0.496']
1800 ['0.874', '0.923']
1900 ['0.871', '0.404']
2000 ['0.875', '0.723']
2100 ['0.878', '0.510']
2200 ['0.872', '0.307']
2300 ['0.872', '0.342']
2400 ['0.867', '0.539']
2500 ['0.868', '0.206']
2600 ['0.868', '0.326']
2700 ['0.869', '0.258']
2800 ['0.868', '0.423']
2900 ['0.865', '0.505']
3000 ['0.872', '0.256']
3100 ['0.869', '0.382']
3200 ['0.868', '0.332']
3300 ['0.872', '0.771']
3400 ['0.872', '0.867']
3500 ['0.878', '0.376']
3600 ['0.871', '0.456']
3700 ['0.874', '0.536']
Train: [3][3750/3750]	loss 0.055 (0.055)	Acc@1 93.750 (84.700)
0 ['0.872', '0.261']
100 ['0.872', '0.735']
200 ['0.872', '0.491']
300 ['0.877', '0.550']
400 ['0.871', '0.554']
500 ['0.876', '0.491']
600 ['0.872', '0.705']
700 ['0.875', '0.421']
800 ['0.879', '0.359']
900 ['0.874', '0.915']
1000 ['0.876', '0.483']
1100 ['0.872', '1.498']
1200 ['0.873', '0.424']
1300 ['0.866', '0.389']
1400 ['0.863', '0.577']
1500 ['0.873', '0.458']
1600 ['0.869', '0.672']
1700 ['0.869', '0.342']
1800 ['0.867', '0.451']
1900 ['0.869', '0.554']
2000 ['0.869', '0.239']
2100 ['0.865', '0.533']
2200 ['0.871', '0.324']
2300 ['0.867', '0.509']
2400 ['0.871', '0.735']
2500 ['0.873', '0.434']
2600 ['0.870', '0.465']
2700 ['0.870', '0.096']
2800 ['0.878', '0.464']
2900 ['0.875', '0.334']
3000 ['0.875', '0.528']
3100 ['0.876', '0.520']
3200 ['0.875', '0.615']
3300 ['0.871', '0.689']
3400 ['0.874', '0.763']
3500 ['0.873', '0.252']
3600 ['0.869', '0.384']
3700 ['0.872', '0.318']
Train: [4][3750/3750]	loss 0.044 (0.055)	Acc@1 93.750 (84.933)
0 ['0.867', '0.361']
100 ['0.869', '0.589']
200 ['0.870', '0.205']
300 ['0.870', '0.283']
400 ['0.871', '0.539']
500 ['0.869', '0.688']
600 ['0.871', '0.633']
700 ['0.868', '0.281']
800 ['0.870', '0.346']
900 ['0.874', '0.446']
1000 ['0.876', '0.709']
1100 ['0.875', '0.638']
1200 ['0.877', '0.167']
1300 ['0.871', '0.788']
1400 ['0.870', '0.313']
1500 ['0.876', '0.510']
1600 ['0.874', '0.287']
1700 ['0.873', '0.574']
1800 ['0.868', '1.043']
1900 ['0.867', '0.341']
2000 ['0.868', '0.172']
2100 ['0.875', '0.508']
2200 ['0.875', '0.528']
2300 ['0.873', '0.348']
2400 ['0.867', '0.748']
2500 ['0.869', '0.235']
2600 ['0.866', '0.481']
2700 ['0.869', '0.614']
2800 ['0.869', '0.519']
2900 ['0.870', '0.839']
3000 ['0.869', '0.451']
3100 ['0.873', '0.890']
3200 ['0.873', '0.565']
3300 ['0.871', '0.210']
3400 ['0.870', '0.402']
3500 ['0.875', '0.412']
3600 ['0.869', '0.809']
3700 ['0.869', '0.878']
Train: [5][3750/3750]	loss 0.055 (0.055)	Acc@1 81.250 (85.182)
Test model 1 on task 1
Test: [3/3]	loss 0.319 (0.316)	Acc@1 89.657 (89.640)
Test model 1 on task 2
Test: [3/3]	loss 0.257 (0.229)	Acc@1 91.704 (92.390)
Test model 1 on task 3
Test: [3/3]	loss 0.232 (0.207)	Acc@1 92.976 (93.490)
Test model 1 on task 4
Test: [3/3]	loss 0.192 (0.217)	Acc@1 93.695 (92.800)
Test model 1 on task 5
Test: [3/3]	loss 0.191 (0.203)	Acc@1 93.861 (93.780)
Test model 1 on task 6
Test: [3/3]	loss 0.196 (0.200)	Acc@1 94.027 (93.780)
Test model 1 on task 7
Test: [3/3]	loss 0.186 (0.202)	Acc@1 94.027 (93.790)
Test model 1 on task 8
Test: [3/3]	loss 0.196 (0.210)	Acc@1 94.303 (93.450)
Test model 1 on task 9
Test: [3/3]	loss 0.232 (0.221)	Acc@1 93.252 (93.330)
Test model 1 on task 10
Test: [3/3]	loss 0.220 (0.229)	Acc@1 93.252 (93.080)
Test model 1 on task 11
Test: [3/3]	loss 0.241 (0.230)	Acc@1 92.644 (93.100)
Test model 1 on task 12
Test: [3/3]	loss 0.228 (0.235)	Acc@1 93.142 (92.970)
Test model 1 on task 13
Test: [3/3]	loss 0.230 (0.239)	Acc@1 93.363 (93.020)
Test model 1 on task 14
Test: [3/3]	loss 0.230 (0.265)	Acc@1 92.312 (91.860)
Test model 1 on task 15
Test: [3/3]	loss 0.261 (0.263)	Acc@1 91.925 (92.090)
Test model 1 on task 16
Test: [3/3]	loss 0.296 (0.292)	Acc@1 91.206 (91.090)
Test model 1 on task 17
Test: [3/3]	loss 0.303 (0.287)	Acc@1 90.265 (91.390)
Test model 1 on task 18
Test: [3/3]	loss 0.272 (0.304)	Acc@1 92.091 (91.090)
Test model 1 on task 19
Test: [3/3]	loss 0.346 (0.339)	Acc@1 89.989 (89.570)
Test model 1 on task 20
Test: [3/3]	loss 0.348 (0.358)	Acc@1 89.712 (89.430)
Test model 1 on task 21
Test: [3/3]	loss 0.368 (0.381)	Acc@1 89.491 (88.870)
Test model 1 on task 22
Test: [3/3]	loss 0.417 (0.432)	Acc@1 88.053 (87.310)
Test model 1 on task 23
Test: [3/3]	loss 0.416 (0.418)	Acc@1 87.666 (87.850)
Test model 1 on task 24
Test: [3/3]	loss 0.472 (0.457)	Acc@1 85.675 (86.060)
Test model 1 on task 25
Test: [3/3]	loss 0.462 (0.470)	Acc@1 87.002 (86.630)
############################################################ Avg acc: 91.27
Task 26 Model 1:
0 ['0.493', '3.959']
100 ['0.752', '1.793']
200 ['0.789', '1.283']
300 ['0.822', '0.562']
400 ['0.840', '1.406']
500 ['0.849', '1.023']
600 ['0.862', '1.113']
700 ['0.858', '0.996']
800 ['0.867', '0.682']
900 ['0.872', '0.756']
1000 ['0.879', '0.633']
1100 ['0.875', '0.810']
1200 ['0.881', '0.740']
1300 ['0.877', '0.468']
1400 ['0.884', '0.916']
1500 ['0.886', '0.577']
1600 ['0.885', '0.537']
1700 ['0.889', '0.490']
1800 ['0.894', '0.822']
1900 ['0.894', '0.724']
2000 ['0.901', '0.552']
2100 ['0.899', '0.419']
2200 ['0.892', '0.405']
2300 ['0.892', '0.844']
2400 ['0.905', '0.860']
2500 ['0.905', '0.413']
2600 ['0.898', '0.560']
2700 ['0.900', '0.734']
2800 ['0.898', '0.240']
2900 ['0.901', '0.868']
3000 ['0.901', '0.747']
3100 ['0.896', '0.989']
3200 ['0.897', '0.245']
3300 ['0.908', '0.691']
3400 ['0.905', '0.761']
3500 ['0.910', '0.186']
3600 ['0.907', '1.085']
3700 ['0.907', '0.373']
Train: [1][3750/3750]	loss 0.051 (0.063)	Acc@1 87.500 (75.865)
0 ['0.909', '0.553']
100 ['0.907', '0.627']
200 ['0.908', '0.448']
300 ['0.903', '0.812']
400 ['0.906', '0.291']
500 ['0.908', '0.388']
600 ['0.904', '0.419']
700 ['0.912', '0.862']
800 ['0.911', '0.591']
900 ['0.911', '0.666']
1000 ['0.910', '0.273']
1100 ['0.907', '0.519']
1200 ['0.912', '0.283']
1300 ['0.909', '0.680']
1400 ['0.906', '0.745']
1500 ['0.899', '0.484']
1600 ['0.903', '0.646']
1700 ['0.913', '0.620']
1800 ['0.908', '0.427']
1900 ['0.907', '0.545']
2000 ['0.911', '0.253']
2100 ['0.906', '0.505']
2200 ['0.906', '0.738']
2300 ['0.904', '0.553']
2400 ['0.901', '0.280']
2500 ['0.902', '0.831']
2600 ['0.900', '0.699']
2700 ['0.906', '0.359']
2800 ['0.906', '0.419']
2900 ['0.907', '0.490']
3000 ['0.905', '0.517']
3100 ['0.912', '0.443']
3200 ['0.911', '0.896']
3300 ['0.911', '0.655']
3400 ['0.913', '0.854']
3500 ['0.908', '0.762']
3600 ['0.907', '0.758']
3700 ['0.907', '0.477']
Train: [2][3750/3750]	loss 0.073 (0.057)	Acc@1 68.750 (82.048)
0 ['0.910', '0.281']
100 ['0.908', '1.017']
200 ['0.908', '0.620']
300 ['0.910', '0.405']
400 ['0.911', '0.462']
500 ['0.910', '0.315']
600 ['0.906', '0.540']
700 ['0.904', '0.293']
800 ['0.903', '0.849']
900 ['0.904', '0.515']
1000 ['0.905', '0.561']
1100 ['0.908', '0.271']
1200 ['0.907', '0.696']
1300 ['0.908', '0.760']
1400 ['0.910', '0.544']
1500 ['0.909', '0.418']
1600 ['0.908', '0.531']
1700 ['0.913', '0.519']
1800 ['0.910', '0.732']
1900 ['0.915', '1.136']
2000 ['0.913', '0.187']
2100 ['0.914', '0.512']
2200 ['0.914', '0.356']
2300 ['0.911', '0.873']
2400 ['0.915', '0.673']
2500 ['0.916', '0.719']
2600 ['0.920', '0.856']
2700 ['0.906', '0.261']
2800 ['0.913', '0.349']
2900 ['0.905', '0.409']
3000 ['0.907', '0.397']
3100 ['0.908', '0.341']
3200 ['0.912', '0.784']
3300 ['0.910', '0.485']
3400 ['0.912', '0.311']
3500 ['0.909', '0.347']
3600 ['0.910', '0.587']
3700 ['0.909', '0.743']
Train: [3][3750/3750]	loss 0.069 (0.057)	Acc@1 75.000 (82.765)
0 ['0.911', '0.467']
100 ['0.910', '0.130']
200 ['0.911', '0.406']
300 ['0.919', '0.392']
400 ['0.910', '0.279']
500 ['0.915', '0.424']
600 ['0.917', '0.714']
700 ['0.910', '0.451']
800 ['0.913', '0.355']
900 ['0.912', '0.401']
1000 ['0.914', '0.328']
1100 ['0.913', '0.227']
1200 ['0.910', '0.567']
1300 ['0.916', '0.627']
1400 ['0.912', '0.559']
1500 ['0.909', '0.871']
1600 ['0.916', '0.930']
1700 ['0.912', '0.584']
1800 ['0.917', '0.170']
1900 ['0.915', '0.246']
2000 ['0.912', '0.621']
2100 ['0.913', '0.378']
2200 ['0.914', '0.467']
2300 ['0.914', '0.294']
2400 ['0.916', '0.672']
2500 ['0.909', '0.813']
2600 ['0.910', '0.790']
2700 ['0.916', '0.535']
2800 ['0.911', '0.257']
2900 ['0.916', '0.616']
3000 ['0.913', '0.654']
3100 ['0.905', '0.390']
3200 ['0.914', '0.575']
3300 ['0.911', '0.384']
3400 ['0.912', '0.213']
3500 ['0.913', '0.470']
3600 ['0.910', '0.500']
3700 ['0.915', '0.559']
Train: [4][3750/3750]	loss 0.065 (0.057)	Acc@1 81.250 (83.057)
0 ['0.914', '0.448']
100 ['0.916', '0.286']
200 ['0.909', '0.402']
300 ['0.911', '0.970']
400 ['0.913', '0.565']
500 ['0.918', '0.698']
600 ['0.906', '0.335']
700 ['0.913', '0.718']
800 ['0.913', '0.517']
900 ['0.916', '1.069']
1000 ['0.913', '0.593']
1100 ['0.915', '0.626']
1200 ['0.914', '0.905']
1300 ['0.907', '0.465']
1400 ['0.915', '0.324']
1500 ['0.916', '0.888']
1600 ['0.917', '0.687']
1700 ['0.918', '0.848']
1800 ['0.916', '0.562']
1900 ['0.917', '0.401']
2000 ['0.916', '0.590']
2100 ['0.915', '0.773']
2200 ['0.915', '0.475']
2300 ['0.914', '0.326']
2400 ['0.917', '0.486']
2500 ['0.921', '0.591']
2600 ['0.921', '0.557']
2700 ['0.917', '0.403']
2800 ['0.915', '0.547']
2900 ['0.913', '1.014']
3000 ['0.917', '0.601']
3100 ['0.913', '0.516']
3200 ['0.911', '0.246']
3300 ['0.908', '0.320']
3400 ['0.906', '0.498']
3500 ['0.913', '0.480']
3600 ['0.914', '0.781']
3700 ['0.906', '0.555']
Train: [5][3750/3750]	loss 0.061 (0.056)	Acc@1 87.500 (83.288)
Test model 1 on task 1
Test: [3/3]	loss 0.332 (0.316)	Acc@1 89.325 (89.680)
Test model 1 on task 2
Test: [3/3]	loss 0.263 (0.229)	Acc@1 91.538 (92.270)
Test model 1 on task 3
Test: [3/3]	loss 0.242 (0.209)	Acc@1 92.146 (93.520)
Test model 1 on task 4
Test: [3/3]	loss 0.187 (0.218)	Acc@1 93.750 (92.670)
Test model 1 on task 5
Test: [3/3]	loss 0.206 (0.205)	Acc@1 93.750 (93.730)
Test model 1 on task 6
Test: [3/3]	loss 0.209 (0.202)	Acc@1 93.916 (93.740)
Test model 1 on task 7
Test: [3/3]	loss 0.182 (0.204)	Acc@1 94.248 (93.590)
Test model 1 on task 8
Test: [3/3]	loss 0.202 (0.213)	Acc@1 93.916 (93.290)
Test model 1 on task 9
Test: [3/3]	loss 0.243 (0.224)	Acc@1 92.423 (93.310)
Test model 1 on task 10
Test: [3/3]	loss 0.223 (0.231)	Acc@1 93.142 (92.860)
Test model 1 on task 11
Test: [3/3]	loss 0.238 (0.231)	Acc@1 92.533 (92.960)
Test model 1 on task 12
Test: [3/3]	loss 0.227 (0.238)	Acc@1 93.308 (92.780)
Test model 1 on task 13
Test: [3/3]	loss 0.262 (0.242)	Acc@1 92.478 (92.800)
Test model 1 on task 14
Test: [3/3]	loss 0.251 (0.268)	Acc@1 92.478 (91.810)
Test model 1 on task 15
Test: [3/3]	loss 0.285 (0.267)	Acc@1 91.261 (91.870)
Test model 1 on task 16
Test: [3/3]	loss 0.284 (0.294)	Acc@1 91.150 (90.980)
Test model 1 on task 17
Test: [3/3]	loss 0.307 (0.290)	Acc@1 90.985 (91.470)
Test model 1 on task 18
Test: [3/3]	loss 0.305 (0.306)	Acc@1 90.597 (91.120)
Test model 1 on task 19
Test: [3/3]	loss 0.348 (0.343)	Acc@1 89.104 (89.420)
Test model 1 on task 20
Test: [3/3]	loss 0.368 (0.359)	Acc@1 89.049 (89.480)
Test model 1 on task 21
Test: [3/3]	loss 0.417 (0.385)	Acc@1 88.385 (88.730)
Test model 1 on task 22
Test: [3/3]	loss 0.414 (0.434)	Acc@1 88.108 (87.230)
Test model 1 on task 23
Test: [3/3]	loss 0.444 (0.424)	Acc@1 87.223 (87.680)
Test model 1 on task 24
Test: [3/3]	loss 0.450 (0.459)	Acc@1 85.841 (85.850)
Test model 1 on task 25
Test: [3/3]	loss 0.435 (0.475)	Acc@1 87.445 (86.450)
Test model 1 on task 26
Test: [3/3]	loss 0.532 (0.527)	Acc@1 83.684 (84.080)
############################################################ Avg acc: 90.90
Task 27 Model 1:
0 ['0.548', '2.960']
100 ['0.811', '0.944']
200 ['0.861', '1.441']
300 ['0.888', '1.317']
400 ['0.904', '1.177']
500 ['0.918', '0.888']
600 ['0.923', '0.801']
700 ['0.929', '1.034']
800 ['0.929', '0.598']
900 ['0.939', '0.526']
1000 ['0.939', '1.002']
1100 ['0.935', '0.781']
1200 ['0.935', '0.538']
1300 ['0.939', '0.669']
1400 ['0.946', '0.807']
1500 ['0.944', '1.226']
1600 ['0.947', '0.711']
1700 ['0.949', '0.560']
1800 ['0.950', '0.368']
1900 ['0.952', '0.675']
2000 ['0.953', '0.703']
2100 ['0.955', '0.352']
2200 ['0.954', '1.126']
2300 ['0.955', '0.590']
2400 ['0.959', '0.671']
2500 ['0.953', '0.644']
2600 ['0.957', '0.500']
2700 ['0.962', '0.893']
2800 ['0.961', '0.615']
2900 ['0.954', '0.864']
3000 ['0.950', '0.348']
3100 ['0.958', '0.442']
3200 ['0.955', '0.430']
3300 ['0.956', '0.473']
3400 ['0.956', '0.359']
3500 ['0.959', '0.356']
3600 ['0.959', '0.470']
3700 ['0.958', '0.367']
Train: [1][3750/3750]	loss 0.048 (0.063)	Acc@1 93.750 (75.937)
0 ['0.961', '0.680']
100 ['0.966', '0.571']
200 ['0.964', '0.319']
300 ['0.968', '0.788']
400 ['0.968', '0.359']
500 ['0.970', '0.721']
600 ['0.965', '0.850']
700 ['0.969', '0.654']
800 ['0.963', '1.220']
900 ['0.962', '0.901']
1000 ['0.959', '0.510']
1100 ['0.963', '0.287']
1200 ['0.958', '0.654']
1300 ['0.963', '0.914']
1400 ['0.963', '0.717']
1500 ['0.967', '0.426']
1600 ['0.968', '0.640']
1700 ['0.965', '0.478']
1800 ['0.966', '0.325']
1900 ['0.960', '0.435']
2000 ['0.966', '0.677']
2100 ['0.965', '0.392']
2200 ['0.963', '0.779']
2300 ['0.960', '0.498']
2400 ['0.959', '0.664']
2500 ['0.965', '0.687']
2600 ['0.956', '0.968']
2700 ['0.961', '0.214']
2800 ['0.964', '0.366']
2900 ['0.966', '0.466']
3000 ['0.969', '1.035']
3100 ['0.966', '0.530']
3200 ['0.966', '0.332']
3300 ['0.974', '0.791']
3400 ['0.970', '0.918']
3500 ['0.966', '1.142']
3600 ['0.965', '0.407']
3700 ['0.973', '0.997']
Train: [2][3750/3750]	loss 0.061 (0.057)	Acc@1 75.000 (81.788)
0 ['0.973', '0.547']
100 ['0.969', '0.511']
200 ['0.969', '0.790']
300 ['0.965', '0.518']
400 ['0.972', '0.432']
500 ['0.967', '1.062']
600 ['0.972', '0.571']
700 ['0.973', '0.268']
800 ['0.964', '1.085']
900 ['0.973', '0.614']
1000 ['0.968', '0.481']
1100 ['0.968', '0.362']
1200 ['0.968', '0.924']
1300 ['0.969', '0.642']
1400 ['0.970', '0.707']
1500 ['0.973', '0.573']
1600 ['0.968', '0.538']
1700 ['0.971', '0.795']
1800 ['0.963', '0.370']
1900 ['0.974', '0.712']
2000 ['0.973', '0.712']
2100 ['0.963', '0.443']
2200 ['0.974', '0.663']
2300 ['0.964', '0.624']
2400 ['0.973', '0.619']
2500 ['0.974', '0.742']
2600 ['0.966', '0.405']
2700 ['0.967', '0.870']
2800 ['0.966', '0.356']
2900 ['0.971', '0.982']
3000 ['0.977', '0.450']
3100 ['0.972', '0.604']
3200 ['0.969', '0.631']
3300 ['0.975', '0.473']
3400 ['0.977', '0.285']
3500 ['0.972', '0.129']
3600 ['0.971', '0.493']
3700 ['0.972', '0.860']
Train: [3][3750/3750]	loss 0.050 (0.057)	Acc@1 100.000 (82.443)
0 ['0.970', '0.668']
100 ['0.970', '0.492']
200 ['0.972', '0.682']
300 ['0.968', '0.821']
400 ['0.968', '0.511']
500 ['0.968', '0.490']
600 ['0.976', '0.691']
700 ['0.972', '0.424']
800 ['0.976', '0.310']
900 ['0.975', '0.231']
1000 ['0.971', '0.536']
1100 ['0.972', '0.478']
1200 ['0.973', '0.494']
1300 ['0.970', '0.256']
1400 ['0.967', '0.499']
1500 ['0.972', '0.657']
1600 ['0.974', '0.677']
1700 ['0.974', '0.449']
1800 ['0.974', '0.700']
1900 ['0.973', '0.400']
2000 ['0.977', '0.706']
2100 ['0.970', '0.314']
2200 ['0.974', '0.412']
2300 ['0.969', '0.470']
2400 ['0.975', '0.434']
2500 ['0.971', '0.210']
2600 ['0.974', '0.673']
2700 ['0.966', '0.284']
2800 ['0.972', '0.592']
2900 ['0.979', '0.798']
3000 ['0.977', '0.818']
3100 ['0.979', '0.239']
3200 ['0.976', '0.410']
3300 ['0.976', '0.673']
3400 ['0.976', '0.624']
3500 ['0.970', '0.887']
3600 ['0.969', '0.352']
3700 ['0.970', '0.554']
Train: [4][3750/3750]	loss 0.053 (0.057)	Acc@1 87.500 (82.673)
0 ['0.970', '0.473']
100 ['0.973', '0.310']
200 ['0.971', '0.459']
300 ['0.973', '0.896']
400 ['0.972', '0.468']
500 ['0.970', '0.996']
600 ['0.975', '0.542']
700 ['0.970', '0.893']
800 ['0.973', '0.693']
900 ['0.968', '0.721']
1000 ['0.975', '0.871']
1100 ['0.972', '0.376']
1200 ['0.969', '0.909']
1300 ['0.972', '0.324']
1400 ['0.973', '0.884']
1500 ['0.968', '0.296']
1600 ['0.976', '0.628']
1700 ['0.979', '0.587']
1800 ['0.974', '0.380']
1900 ['0.969', '0.552']
2000 ['0.973', '0.548']
2100 ['0.967', '0.556']
2200 ['0.967', '0.338']
2300 ['0.964', '0.653']
2400 ['0.968', '0.240']
2500 ['0.967', '0.560']
2600 ['0.967', '0.358']
2700 ['0.972', '0.411']
2800 ['0.971', '0.749']
2900 ['0.969', '0.377']
3000 ['0.978', '0.681']
3100 ['0.976', '0.647']
3200 ['0.981', '0.550']
3300 ['0.976', '0.204']
3400 ['0.976', '0.527']
3500 ['0.973', '0.409']
3600 ['0.974', '0.606']
3700 ['0.975', '0.566']
Train: [5][3750/3750]	loss 0.045 (0.057)	Acc@1 100.000 (82.802)
Test model 1 on task 1
Test: [3/3]	loss 0.297 (0.317)	Acc@1 90.431 (89.520)
Test model 1 on task 2
Test: [3/3]	loss 0.254 (0.234)	Acc@1 91.427 (92.160)
Test model 1 on task 3
Test: [3/3]	loss 0.207 (0.211)	Acc@1 93.529 (93.360)
Test model 1 on task 4
Test: [3/3]	loss 0.227 (0.220)	Acc@1 92.146 (92.620)
Test model 1 on task 5
Test: [3/3]	loss 0.239 (0.207)	Acc@1 93.308 (93.710)
Test model 1 on task 6
Test: [3/3]	loss 0.216 (0.205)	Acc@1 93.584 (93.690)
Test model 1 on task 7
Test: [3/3]	loss 0.228 (0.208)	Acc@1 92.644 (93.580)
Test model 1 on task 8
Test: [3/3]	loss 0.214 (0.219)	Acc@1 92.865 (93.090)
Test model 1 on task 9
Test: [3/3]	loss 0.210 (0.226)	Acc@1 94.027 (93.320)
Test model 1 on task 10
Test: [3/3]	loss 0.231 (0.234)	Acc@1 92.699 (92.750)
Test model 1 on task 11
Test: [3/3]	loss 0.236 (0.232)	Acc@1 92.644 (92.980)
Test model 1 on task 12
Test: [3/3]	loss 0.269 (0.240)	Acc@1 91.593 (92.760)
Test model 1 on task 13
Test: [3/3]	loss 0.240 (0.247)	Acc@1 92.920 (92.720)
Test model 1 on task 14
Test: [3/3]	loss 0.270 (0.271)	Acc@1 91.759 (91.760)
Test model 1 on task 15
Test: [3/3]	loss 0.274 (0.271)	Acc@1 92.091 (91.850)
Test model 1 on task 16
Test: [3/3]	loss 0.286 (0.301)	Acc@1 91.593 (90.870)
Test model 1 on task 17
Test: [3/3]	loss 0.289 (0.293)	Acc@1 91.482 (91.370)
Test model 1 on task 18
Test: [3/3]	loss 0.320 (0.309)	Acc@1 89.989 (90.940)
Test model 1 on task 19
Test: [3/3]	loss 0.336 (0.346)	Acc@1 88.883 (89.220)
Test model 1 on task 20
Test: [3/3]	loss 0.378 (0.362)	Acc@1 88.551 (89.360)
Test model 1 on task 21
Test: [3/3]	loss 0.381 (0.389)	Acc@1 89.712 (88.660)
Test model 1 on task 22
Test: [3/3]	loss 0.430 (0.438)	Acc@1 87.942 (87.090)
Test model 1 on task 23
Test: [3/3]	loss 0.426 (0.428)	Acc@1 87.279 (87.540)
Test model 1 on task 24
Test: [3/3]	loss 0.501 (0.466)	Acc@1 84.513 (85.600)
Test model 1 on task 25
Test: [3/3]	loss 0.475 (0.481)	Acc@1 86.117 (86.080)
Test model 1 on task 26
Test: [3/3]	loss 0.497 (0.530)	Acc@1 85.232 (84.000)
Test model 1 on task 27
Test: [3/3]	loss 0.542 (0.526)	Acc@1 83.296 (83.710)
############################################################ Avg acc: 90.53
Task 28 Model 1:
0 ['0.549', '4.284']
100 ['0.819', '1.586']
200 ['0.896', '1.275']
300 ['0.918', '1.573']
400 ['0.942', '1.314']
500 ['0.960', '0.776']
600 ['0.972', '0.829']
700 ['0.968', '1.221']
800 ['0.974', '0.834']
900 ['0.992', '0.527']
1000 ['1.001', '0.833']
1100 ['1.001', '0.674']
1200 ['1.000', '0.614']
1300 ['1.007', '0.710']
1400 ['1.007', '0.731']
1500 ['1.002', '0.538']
1600 ['1.013', '0.490']
1700 ['1.006', '0.934']
1800 ['1.019', '0.740']
1900 ['1.018', '0.807']
2000 ['1.020', '0.719']
2100 ['1.019', '0.679']
2200 ['1.026', '0.759']
2300 ['1.026', '0.720']
2400 ['1.029', '0.381']
2500 ['1.031', '0.751']
2600 ['1.037', '0.526']
2700 ['1.031', '0.921']
2800 ['1.031', '0.602']
2900 ['1.028', '0.891']
3000 ['1.023', '0.808']
3100 ['1.025', '0.537']
3200 ['1.017', '0.748']
3300 ['1.018', '0.712']
3400 ['1.020', '0.784']
3500 ['1.024', '0.843']
3600 ['1.021', '0.287']
3700 ['1.021', '0.797']
Train: [1][3750/3750]	loss 0.057 (0.066)	Acc@1 75.000 (73.235)
0 ['1.021', '0.709']
100 ['1.024', '0.892']
200 ['1.026', '0.421']
300 ['1.022', '0.723']
400 ['1.018', '0.414']
500 ['1.023', '0.351']
600 ['1.023', '0.444']
700 ['1.022', '0.721']
800 ['1.018', '0.434']
900 ['1.023', '0.652']
1000 ['1.024', '0.715']
1100 ['1.024', '0.519']
1200 ['1.021', '0.657']
1300 ['1.019', '0.603']
1400 ['1.023', '0.717']
1500 ['1.027', '0.582']
1600 ['1.031', '0.648']
1700 ['1.029', '0.434']
1800 ['1.028', '0.484']
1900 ['1.020', '0.686']
2000 ['1.026', '0.450']
2100 ['1.026', '0.801']
2200 ['1.026', '0.482']
2300 ['1.023', '0.542']
2400 ['1.024', '1.074']
2500 ['1.021', '0.294']
2600 ['1.026', '1.059']
2700 ['1.024', '0.436']
2800 ['1.031', '0.899']
2900 ['1.028', '0.584']
3000 ['1.023', '0.492']
3100 ['1.030', '0.424']
3200 ['1.024', '1.042']
3300 ['1.027', '0.676']
3400 ['1.026', '0.349']
3500 ['1.026', '0.633']
3600 ['1.027', '0.571']
3700 ['1.024', '0.463']
Train: [2][3750/3750]	loss 0.050 (0.059)	Acc@1 87.500 (80.343)
0 ['1.018', '0.628']
100 ['1.027', '0.393']
200 ['1.019', '0.668']
300 ['1.030', '0.552']
400 ['1.027', '0.721']
500 ['1.019', '0.292']
600 ['1.018', '0.629']
700 ['1.022', '0.558']
800 ['1.024', '0.686']
900 ['1.028', '0.452']
1000 ['1.021', '0.408']
1100 ['1.018', '0.223']
1200 ['1.015', '0.559']
1300 ['1.021', '0.716']
1400 ['1.030', '0.388']
1500 ['1.021', '0.288']
1600 ['1.021', '0.610']
1700 ['1.023', '0.498']
1800 ['1.019', '0.412']
1900 ['1.018', '0.559']
2000 ['1.022', '0.690']
2100 ['1.028', '0.585']
2200 ['1.030', '1.204']
2300 ['1.029', '0.849']
2400 ['1.028', '0.887']
2500 ['1.031', '0.696']
2600 ['1.027', '0.766']
2700 ['1.022', '0.569']
2800 ['1.026', '0.367']
2900 ['1.033', '0.332']
3000 ['1.028', '0.342']
3100 ['1.022', '0.528']
3200 ['1.028', '0.749']
3300 ['1.020', '0.462']
3400 ['1.024', '0.444']
3500 ['1.028', '0.856']
3600 ['1.025', '0.392']
3700 ['1.031', '0.463']
Train: [3][3750/3750]	loss 0.068 (0.059)	Acc@1 56.250 (81.148)
0 ['1.029', '0.361']
100 ['1.029', '0.447']
200 ['1.027', '0.440']
300 ['1.025', '0.598']
400 ['1.021', '0.756']
500 ['1.025', '0.747']
600 ['1.028', '0.537']
700 ['1.022', '0.285']
800 ['1.022', '0.667']
900 ['1.017', '0.917']
1000 ['1.019', '0.477']
1100 ['1.021', '0.525']
1200 ['1.019', '0.697']
1300 ['1.020', '0.756']
1400 ['1.027', '0.433']
1500 ['1.028', '0.421']
1600 ['1.028', '0.610']
1700 ['1.029', '0.469']
1800 ['1.024', '0.613']
1900 ['1.020', '0.452']
2000 ['1.025', '0.834']
2100 ['1.023', '0.348']
2200 ['1.022', '0.727']
2300 ['1.023', '0.292']
2400 ['1.023', '0.898']
2500 ['1.027', '0.277']
2600 ['1.026', '0.384']
2700 ['1.029', '0.603']
2800 ['1.026', '0.378']
2900 ['1.027', '0.534']
3000 ['1.030', '0.575']
3100 ['1.025', '0.489']
3200 ['1.022', '0.252']
3300 ['1.030', '0.573']
3400 ['1.027', '1.248']
3500 ['1.027', '0.786']
3600 ['1.031', '0.903']
3700 ['1.032', '0.613']
Train: [4][3750/3750]	loss 0.050 (0.059)	Acc@1 93.750 (81.390)
0 ['1.033', '0.693']
100 ['1.033', '0.627']
200 ['1.034', '0.552']
300 ['1.037', '0.550']
400 ['1.034', '0.483']
500 ['1.029', '0.637']
600 ['1.025', '0.682']
700 ['1.028', '0.420']
800 ['1.025', '0.652']
900 ['1.022', '0.233']
1000 ['1.029', '0.887']
1100 ['1.024', '0.173']
1200 ['1.027', '0.322']
1300 ['1.030', '0.544']
1400 ['1.029', '0.573']
1500 ['1.033', '0.555']
1600 ['1.028', '0.427']
1700 ['1.034', '0.641']
1800 ['1.033', '0.733']
1900 ['1.027', '0.341']
2000 ['1.025', '0.618']
2100 ['1.031', '0.626']
2200 ['1.030', '0.355']
2300 ['1.027', '0.764']
2400 ['1.028', '0.253']
2500 ['1.023', '0.518']
2600 ['1.025', '0.804']
2700 ['1.028', '0.339']
2800 ['1.028', '0.481']
2900 ['1.028', '0.524']
3000 ['1.023', '0.510']
3100 ['1.026', '0.534']
3200 ['1.022', '0.437']
3300 ['1.021', '0.657']
3400 ['1.023', '0.630']
3500 ['1.026', '0.495']
3600 ['1.026', '0.576']
3700 ['1.032', '0.708']
Train: [5][3750/3750]	loss 0.061 (0.058)	Acc@1 93.750 (81.545)
Test model 1 on task 1
Test: [3/3]	loss 0.305 (0.316)	Acc@1 89.934 (89.450)
Test model 1 on task 2
Test: [3/3]	loss 0.233 (0.230)	Acc@1 92.588 (92.330)
Test model 1 on task 3
Test: [3/3]	loss 0.225 (0.214)	Acc@1 92.312 (93.150)
Test model 1 on task 4
Test: [3/3]	loss 0.239 (0.222)	Acc@1 92.257 (92.510)
Test model 1 on task 5
Test: [3/3]	loss 0.216 (0.209)	Acc@1 93.308 (93.530)
Test model 1 on task 6
Test: [3/3]	loss 0.210 (0.208)	Acc@1 93.363 (93.550)
Test model 1 on task 7
Test: [3/3]	loss 0.197 (0.210)	Acc@1 94.027 (93.510)
Test model 1 on task 8
Test: [3/3]	loss 0.211 (0.223)	Acc@1 93.418 (92.960)
Test model 1 on task 9
Test: [3/3]	loss 0.223 (0.228)	Acc@1 93.584 (93.300)
Test model 1 on task 10
Test: [3/3]	loss 0.232 (0.236)	Acc@1 92.920 (92.640)
Test model 1 on task 11
Test: [3/3]	loss 0.249 (0.236)	Acc@1 92.533 (92.860)
Test model 1 on task 12
Test: [3/3]	loss 0.256 (0.242)	Acc@1 92.201 (92.750)
Test model 1 on task 13
Test: [3/3]	loss 0.260 (0.250)	Acc@1 92.754 (92.710)
Test model 1 on task 14
Test: [3/3]	loss 0.266 (0.275)	Acc@1 92.091 (91.550)
Test model 1 on task 15
Test: [3/3]	loss 0.291 (0.274)	Acc@1 91.372 (91.760)
Test model 1 on task 16
Test: [3/3]	loss 0.304 (0.304)	Acc@1 90.431 (90.720)
Test model 1 on task 17
Test: [3/3]	loss 0.284 (0.294)	Acc@1 92.091 (91.340)
Test model 1 on task 18
Test: [3/3]	loss 0.297 (0.311)	Acc@1 91.593 (91.080)
Test model 1 on task 19
Test: [3/3]	loss 0.345 (0.350)	Acc@1 89.768 (88.990)
Test model 1 on task 20
Test: [3/3]	loss 0.367 (0.363)	Acc@1 89.823 (89.430)
Test model 1 on task 21
Test: [3/3]	loss 0.429 (0.392)	Acc@1 87.445 (88.570)
Test model 1 on task 22
Test: [3/3]	loss 0.436 (0.441)	Acc@1 87.334 (87.010)
Test model 1 on task 23
Test: [3/3]	loss 0.437 (0.431)	Acc@1 87.555 (87.530)
Test model 1 on task 24
Test: [3/3]	loss 0.488 (0.470)	Acc@1 84.790 (85.440)
Test model 1 on task 25
Test: [3/3]	loss 0.500 (0.484)	Acc@1 85.454 (86.140)
Test model 1 on task 26
Test: [3/3]	loss 0.545 (0.529)	Acc@1 83.020 (83.930)
Test model 1 on task 27
Test: [3/3]	loss 0.538 (0.527)	Acc@1 83.075 (83.680)
Test model 1 on task 28
Test: [3/3]	loss 0.582 (0.600)	Acc@1 82.080 (81.500)
############################################################ Avg acc: 90.14
Task 29 Model 1:
0 ['0.604', '3.279']
100 ['0.865', '1.252']
200 ['0.913', '1.199']
300 ['0.952', '1.183']
400 ['0.971', '0.963']
500 ['0.977', '1.218']
600 ['0.986', '1.067']
700 ['0.989', '1.103']
800 ['1.007', '0.985']
900 ['1.005', '0.838']
1000 ['1.015', '0.906']
1100 ['1.011', '1.256']
1200 ['1.013', '0.719']
1300 ['1.018', '1.048']
1400 ['1.021', '0.843']
1500 ['1.029', '0.890']
1600 ['1.025', '0.856']
1700 ['1.032', '0.945']
1800 ['1.028', '0.518']
1900 ['1.032', '0.515']
2000 ['1.029', '0.471']
2100 ['1.032', '0.632']
2200 ['1.034', '1.005']
2300 ['1.039', '0.658']
2400 ['1.039', '0.751']
2500 ['1.043', '0.627']
2600 ['1.037', '0.261']
2700 ['1.041', '0.381']
2800 ['1.045', '0.900']
2900 ['1.038', '0.572']
3000 ['1.039', '0.709']
3100 ['1.043', '0.638']
3200 ['1.044', '0.482']
3300 ['1.045', '0.625']
3400 ['1.044', '0.445']
3500 ['1.044', '0.704']
3600 ['1.047', '0.704']
3700 ['1.049', '0.378']
Train: [1][3750/3750]	loss 0.056 (0.063)	Acc@1 93.750 (73.982)
0 ['1.051', '0.562']
100 ['1.052', '0.750']
200 ['1.046', '1.074']
300 ['1.049', '0.740']
400 ['1.046', '0.596']
500 ['1.051', '0.809']
600 ['1.045', '0.490']
700 ['1.048', '0.404']
800 ['1.044', '0.546']
900 ['1.044', '0.567']
1000 ['1.049', '0.671']
1100 ['1.048', '0.704']
1200 ['1.046', '0.618']
1300 ['1.056', '0.712']
1400 ['1.044', '1.135']
1500 ['1.051', '0.621']
1600 ['1.046', '0.572']
1700 ['1.055', '0.379']
1800 ['1.050', '0.603']
1900 ['1.051', '0.703']
2000 ['1.044', '0.583']
2100 ['1.050', '0.636']
2200 ['1.053', '0.637']
2300 ['1.049', '1.058']
2400 ['1.051', '0.353']
2500 ['1.047', '0.736']
2600 ['1.057', '0.660']
2700 ['1.052', '0.993']
2800 ['1.053', '0.768']
2900 ['1.051', '0.403']
3000 ['1.057', '0.541']
3100 ['1.050', '1.202']
3200 ['1.055', '0.844']
3300 ['1.049', '0.631']
3400 ['1.059', '0.593']
3500 ['1.054', '0.670']
3600 ['1.058', '0.676']
3700 ['1.052', '0.846']
Train: [2][3750/3750]	loss 0.051 (0.059)	Acc@1 81.250 (79.773)
0 ['1.057', '1.198']
100 ['1.053', '0.606']
200 ['1.055', '0.463']
300 ['1.054', '0.754']
400 ['1.054', '0.567']
500 ['1.057', '0.519']
600 ['1.051', '0.682']
700 ['1.055', '1.112']
800 ['1.051', '1.092']
900 ['1.053', '0.469']
1000 ['1.057', '0.575']
1100 ['1.056', '0.597']
1200 ['1.056', '0.994']
1300 ['1.063', '0.505']
1400 ['1.057', '0.465']
1500 ['1.055', '0.584']
1600 ['1.054', '0.567']
1700 ['1.055', '0.903']
1800 ['1.055', '0.789']
1900 ['1.058', '1.510']
2000 ['1.054', '0.679']
2100 ['1.057', '0.898']
2200 ['1.054', '0.627']
2300 ['1.050', '0.592']
2400 ['1.053', '0.448']
2500 ['1.059', '0.780']
2600 ['1.059', '0.817']
2700 ['1.064', '0.536']
2800 ['1.056', '1.007']
2900 ['1.052', '0.699']
3000 ['1.058', '0.565']
3100 ['1.056', '0.324']
3200 ['1.055', '0.470']
3300 ['1.054', '0.731']
3400 ['1.049', '0.728']
3500 ['1.049', '0.688']
3600 ['1.053', '0.712']
3700 ['1.047', '0.786']
Train: [3][3750/3750]	loss 0.061 (0.059)	Acc@1 75.000 (80.253)
0 ['1.052', '0.236']
100 ['1.051', '0.474']
200 ['1.060', '0.740']
300 ['1.057', '0.825']
400 ['1.058', '0.916']
500 ['1.061', '0.694']
600 ['1.064', '0.848']
700 ['1.056', '0.365']
800 ['1.052', '0.825']
900 ['1.061', '0.443']
1000 ['1.054', '0.720']
1100 ['1.052', '0.388']
1200 ['1.053', '0.506']
1300 ['1.054', '0.666']
1400 ['1.056', '0.524']
1500 ['1.056', '0.884']
1600 ['1.053', '0.469']
1700 ['1.058', '0.590']
1800 ['1.054', '0.484']
1900 ['1.055', '0.640']
2000 ['1.055', '0.384']
2100 ['1.060', '0.788']
2200 ['1.049', '0.799']
2300 ['1.054', '0.310']
2400 ['1.056', '0.673']
2500 ['1.055', '0.575']
2600 ['1.055', '0.715']
2700 ['1.056', '0.416']
2800 ['1.056', '0.503']
2900 ['1.055', '0.501']
3000 ['1.056', '1.401']
3100 ['1.058', '0.354']
3200 ['1.060', '0.791']
3300 ['1.061', '0.340']
3400 ['1.060', '0.555']
3500 ['1.054', '0.533']
3600 ['1.051', '0.836']
3700 ['1.053', '0.194']
Train: [4][3750/3750]	loss 0.056 (0.058)	Acc@1 87.500 (80.447)
0 ['1.054', '0.635']
100 ['1.059', '0.536']
200 ['1.057', '0.805']
300 ['1.056', '0.347']
400 ['1.049', '0.632']
500 ['1.059', '0.433']
600 ['1.051', '1.045']
700 ['1.053', '0.772']
800 ['1.060', '0.666']
900 ['1.051', '0.416']
1000 ['1.056', '0.591']
1100 ['1.054', '0.672']
1200 ['1.056', '0.339']
1300 ['1.059', '0.472']
1400 ['1.063', '0.629']
1500 ['1.059', '0.515']
1600 ['1.055', '0.372']
1700 ['1.059', '0.889']
1800 ['1.058', '0.543']
1900 ['1.064', '0.614']
2000 ['1.063', '0.701']
2100 ['1.059', '0.926']
2200 ['1.057', '0.549']
2300 ['1.057', '0.324']
2400 ['1.054', '0.597']
2500 ['1.061', '1.018']
2600 ['1.059', '0.695']
2700 ['1.059', '0.979']
2800 ['1.059', '0.651']
2900 ['1.063', '0.651']
3000 ['1.058', '0.717']
3100 ['1.063', '0.290']
3200 ['1.054', '0.646']
3300 ['1.051', '0.664']
3400 ['1.055', '0.666']
3500 ['1.057', '0.668']
3600 ['1.055', '0.574']
3700 ['1.055', '0.940']
Train: [5][3750/3750]	loss 0.057 (0.058)	Acc@1 87.500 (80.495)
Test model 1 on task 1
Test: [3/3]	loss 0.302 (0.314)	Acc@1 89.823 (89.430)
Test model 1 on task 2
Test: [3/3]	loss 0.237 (0.233)	Acc@1 92.588 (92.260)
Test model 1 on task 3
Test: [3/3]	loss 0.218 (0.215)	Acc@1 93.805 (93.170)
Test model 1 on task 4
Test: [3/3]	loss 0.226 (0.225)	Acc@1 92.312 (92.500)
Test model 1 on task 5
Test: [3/3]	loss 0.215 (0.211)	Acc@1 93.031 (93.610)
Test model 1 on task 6
Test: [3/3]	loss 0.202 (0.211)	Acc@1 93.639 (93.460)
Test model 1 on task 7
Test: [3/3]	loss 0.235 (0.212)	Acc@1 92.146 (93.410)
Test model 1 on task 8
Test: [3/3]	loss 0.230 (0.225)	Acc@1 92.423 (92.900)
Test model 1 on task 9
Test: [3/3]	loss 0.228 (0.230)	Acc@1 93.529 (93.280)
Test model 1 on task 10
Test: [3/3]	loss 0.238 (0.238)	Acc@1 92.865 (92.670)
Test model 1 on task 11
Test: [3/3]	loss 0.241 (0.239)	Acc@1 92.146 (92.680)
Test model 1 on task 12
Test: [3/3]	loss 0.238 (0.244)	Acc@1 92.367 (92.630)
Test model 1 on task 13
Test: [3/3]	loss 0.251 (0.251)	Acc@1 92.754 (92.640)
Test model 1 on task 14
Test: [3/3]	loss 0.286 (0.279)	Acc@1 90.708 (91.490)
Test model 1 on task 15
Test: [3/3]	loss 0.244 (0.277)	Acc@1 92.644 (91.720)
Test model 1 on task 16
Test: [3/3]	loss 0.292 (0.307)	Acc@1 91.040 (90.640)
Test model 1 on task 17
Test: [3/3]	loss 0.299 (0.297)	Acc@1 90.763 (91.240)
Test model 1 on task 18
Test: [3/3]	loss 0.322 (0.312)	Acc@1 90.985 (90.990)
Test model 1 on task 19
Test: [3/3]	loss 0.343 (0.351)	Acc@1 88.827 (88.930)
Test model 1 on task 20
Test: [3/3]	loss 0.383 (0.366)	Acc@1 88.772 (89.330)
Test model 1 on task 21
Test: [3/3]	loss 0.384 (0.395)	Acc@1 88.053 (88.270)
Test model 1 on task 22
Test: [3/3]	loss 0.449 (0.444)	Acc@1 86.781 (86.930)
Test model 1 on task 23
Test: [3/3]	loss 0.443 (0.435)	Acc@1 86.560 (87.260)
Test model 1 on task 24
Test: [3/3]	loss 0.464 (0.471)	Acc@1 85.122 (85.440)
Test model 1 on task 25
Test: [3/3]	loss 0.500 (0.487)	Acc@1 85.343 (85.840)
Test model 1 on task 26
Test: [3/3]	loss 0.537 (0.531)	Acc@1 83.794 (84.090)
Test model 1 on task 27
Test: [3/3]	loss 0.537 (0.528)	Acc@1 82.965 (83.550)
Test model 1 on task 28
Test: [3/3]	loss 0.614 (0.604)	Acc@1 80.918 (81.370)
Test model 1 on task 29
Test: [3/3]	loss 0.589 (0.598)	Acc@1 80.918 (81.460)
############################################################ Avg acc: 89.77
Task 30 Model 1:
0 ['0.636', '3.375']
100 ['0.994', '2.129']
200 ['1.054', '1.012']
300 ['1.078', '0.996']
400 ['1.074', '1.368']
500 ['1.090', '0.973']
600 ['1.091', '1.228']
700 ['1.092', '0.694']
800 ['1.099', '1.451']
900 ['1.098', '1.119']
1000 ['1.101', '1.428']
1100 ['1.103', '0.645']
1200 ['1.109', '0.540']
1300 ['1.115', '0.535']
1400 ['1.117', '0.661']
1500 ['1.117', '0.591']
1600 ['1.126', '0.999']
1700 ['1.116', '0.704']
1800 ['1.119', '0.854']
1900 ['1.122', '0.594']
2000 ['1.135', '0.583']
2100 ['1.131', '0.983']
2200 ['1.141', '0.930']
2300 ['1.130', '0.574']
2400 ['1.137', '1.003']
2500 ['1.143', '0.906']
2600 ['1.140', '0.737']
2700 ['1.141', '0.726']
2800 ['1.144', '0.328']
2900 ['1.141', '0.888']
3000 ['1.147', '0.596']
3100 ['1.138', '1.094']
3200 ['1.145', '0.964']
3300 ['1.141', '0.600']
3400 ['1.139', '0.811']
3500 ['1.145', '0.452']
3600 ['1.155', '0.620']
3700 ['1.160', '1.288']
Train: [1][3750/3750]	loss 0.060 (0.066)	Acc@1 81.250 (71.947)
0 ['1.147', '0.940']
100 ['1.156', '0.787']
200 ['1.151', '0.750']
300 ['1.148', '0.649']
400 ['1.152', '0.489']
500 ['1.147', '0.527']
600 ['1.154', '0.475']
700 ['1.150', '0.561']
800 ['1.158', '0.440']
900 ['1.151', '0.711']
1000 ['1.152', '0.535']
1100 ['1.150', '0.652']
1200 ['1.159', '0.959']
1300 ['1.154', '0.934']
1400 ['1.159', '0.641']
1500 ['1.158', '0.829']
1600 ['1.158', '0.791']
1700 ['1.161', '0.493']
1800 ['1.154', '0.466']
1900 ['1.149', '0.465']
2000 ['1.152', '0.389']
2100 ['1.145', '0.699']
2200 ['1.158', '0.757']
2300 ['1.159', '0.472']
2400 ['1.161', '0.614']
2500 ['1.156', '0.531']
2600 ['1.166', '1.216']
2700 ['1.151', '0.998']
2800 ['1.156', '0.969']
2900 ['1.149', '0.629']
3000 ['1.156', '1.459']
3100 ['1.154', '1.138']
3200 ['1.144', '0.715']
3300 ['1.156', '0.632']
3400 ['1.158', '0.557']
3500 ['1.158', '0.704']
3600 ['1.159', '0.321']
3700 ['1.154', '0.430']
Train: [2][3750/3750]	loss 0.058 (0.063)	Acc@1 81.250 (77.045)
0 ['1.158', '0.639']
100 ['1.156', '0.817']
200 ['1.151', '1.154']
300 ['1.147', '0.979']
400 ['1.145', '0.668']
500 ['1.155', '0.339']
600 ['1.163', '0.667']
700 ['1.158', '0.809']
800 ['1.159', '1.142']
900 ['1.165', '0.982']
1000 ['1.160', '0.425']
1100 ['1.158', '0.778']
1200 ['1.164', '0.864']
1300 ['1.158', '0.763']
1400 ['1.172', '0.690']
1500 ['1.161', '1.060']
1600 ['1.161', '0.665']
1700 ['1.151', '1.007']
1800 ['1.155', '0.414']
1900 ['1.154', '0.644']
2000 ['1.156', '1.017']
2100 ['1.161', '0.703']
2200 ['1.167', '0.602']
2300 ['1.154', '1.241']
2400 ['1.162', '0.667']
2500 ['1.161', '0.861']
2600 ['1.159', '0.686']
2700 ['1.157', '0.723']
2800 ['1.154', '0.800']
2900 ['1.159', '0.608']
3000 ['1.155', '0.624']
3100 ['1.159', '0.693']
3200 ['1.160', '0.845']
3300 ['1.157', '0.683']
3400 ['1.168', '0.851']
3500 ['1.166', '1.003']
3600 ['1.168', '0.988']
3700 ['1.166', '1.118']
Train: [3][3750/3750]	loss 0.066 (0.062)	Acc@1 75.000 (77.368)
0 ['1.159', '1.143']
100 ['1.169', '0.509']
200 ['1.155', '0.812']
300 ['1.159', '0.752']
400 ['1.164', '0.437']
500 ['1.160', '0.920']
600 ['1.163', '0.612']
700 ['1.159', '0.711']
800 ['1.156', '0.539']
900 ['1.156', '0.710']
1000 ['1.160', '0.735']
1100 ['1.156', '0.971']
1200 ['1.160', '0.617']
1300 ['1.154', '0.881']
1400 ['1.154', '1.002']
1500 ['1.158', '0.640']
1600 ['1.170', '0.454']
1700 ['1.167', '0.757']
1800 ['1.160', '0.822']
1900 ['1.156', '0.670']
2000 ['1.149', '0.279']
2100 ['1.158', '0.878']
2200 ['1.161', '0.654']
2300 ['1.155', '0.564']
2400 ['1.157', '0.916']
2500 ['1.157', '1.196']
2600 ['1.152', '0.371']
2700 ['1.156', '1.035']
2800 ['1.157', '0.830']
2900 ['1.158', '0.583']
3000 ['1.157', '0.496']
3100 ['1.158', '0.695']
3200 ['1.162', '0.716']
3300 ['1.161', '0.746']
3400 ['1.163', '0.773']
3500 ['1.156', '0.697']
3600 ['1.162', '0.598']
3700 ['1.160', '0.936']
Train: [4][3750/3750]	loss 0.068 (0.062)	Acc@1 87.500 (77.587)
0 ['1.158', '0.555']
100 ['1.159', '1.001']
200 ['1.167', '0.367']
300 ['1.158', '0.569']
400 ['1.158', '0.864']
500 ['1.161', '0.667']
600 ['1.163', '0.688']
700 ['1.164', '0.394']
800 ['1.161', '0.628']
900 ['1.170', '1.068']
1000 ['1.162', '0.792']
1100 ['1.159', '0.600']
1200 ['1.152', '0.714']
1300 ['1.165', '0.597']
1400 ['1.168', '0.550']
1500 ['1.160', '0.925']
1600 ['1.156', '0.856']
1700 ['1.161', '0.755']
1800 ['1.150', '0.588']
1900 ['1.162', '0.530']
2000 ['1.157', '0.734']
2100 ['1.155', '1.476']
2200 ['1.166', '0.925']
2300 ['1.162', '0.376']
2400 ['1.163', '0.528']
2500 ['1.171', '0.873']
2600 ['1.159', '0.498']
2700 ['1.156', '1.046']
2800 ['1.157', '0.800']
2900 ['1.159', '0.319']
3000 ['1.156', '0.736']
3100 ['1.159', '0.308']
3200 ['1.160', '0.925']
3300 ['1.161', '0.858']
3400 ['1.167', '0.656']
3500 ['1.159', '0.888']
3600 ['1.158', '1.085']
3700 ['1.152', '0.385']
Train: [5][3750/3750]	loss 0.071 (0.062)	Acc@1 68.750 (77.672)
Test model 1 on task 1
Test: [3/3]	loss 0.321 (0.313)	Acc@1 89.546 (89.570)
Test model 1 on task 2
Test: [3/3]	loss 0.244 (0.234)	Acc@1 91.372 (92.170)
Test model 1 on task 3
Test: [3/3]	loss 0.221 (0.217)	Acc@1 93.418 (93.110)
Test model 1 on task 4
Test: [3/3]	loss 0.220 (0.227)	Acc@1 92.644 (92.440)
Test model 1 on task 5
Test: [3/3]	loss 0.231 (0.215)	Acc@1 92.312 (93.400)
Test model 1 on task 6
Test: [3/3]	loss 0.198 (0.213)	Acc@1 93.971 (93.380)
Test model 1 on task 7
Test: [3/3]	loss 0.205 (0.215)	Acc@1 94.358 (93.410)
Test model 1 on task 8
Test: [3/3]	loss 0.230 (0.228)	Acc@1 92.478 (92.790)
Test model 1 on task 9
Test: [3/3]	loss 0.208 (0.231)	Acc@1 93.308 (93.100)
Test model 1 on task 10
Test: [3/3]	loss 0.249 (0.240)	Acc@1 92.312 (92.630)
Test model 1 on task 11
Test: [3/3]	loss 0.254 (0.243)	Acc@1 92.588 (92.500)
Test model 1 on task 12
Test: [3/3]	loss 0.233 (0.247)	Acc@1 93.031 (92.440)
Test model 1 on task 13
Test: [3/3]	loss 0.278 (0.255)	Acc@1 91.759 (92.400)
Test model 1 on task 14
Test: [3/3]	loss 0.278 (0.282)	Acc@1 91.980 (91.320)
Test model 1 on task 15
Test: [3/3]	loss 0.277 (0.280)	Acc@1 91.980 (91.640)
Test model 1 on task 16
Test: [3/3]	loss 0.313 (0.313)	Acc@1 91.040 (90.410)
Test model 1 on task 17
Test: [3/3]	loss 0.295 (0.300)	Acc@1 91.427 (91.060)
Test model 1 on task 18
Test: [3/3]	loss 0.317 (0.314)	Acc@1 90.487 (90.980)
Test model 1 on task 19
Test: [3/3]	loss 0.376 (0.355)	Acc@1 88.385 (88.900)
Test model 1 on task 20
Test: [3/3]	loss 0.369 (0.369)	Acc@1 89.436 (89.200)
Test model 1 on task 21
Test: [3/3]	loss 0.431 (0.397)	Acc@1 87.058 (88.200)
Test model 1 on task 22
Test: [3/3]	loss 0.457 (0.448)	Acc@1 85.951 (86.780)
Test model 1 on task 23
Test: [3/3]	loss 0.449 (0.437)	Acc@1 86.781 (87.280)
Test model 1 on task 24
Test: [3/3]	loss 0.434 (0.475)	Acc@1 87.113 (85.320)
Test model 1 on task 25
Test: [3/3]	loss 0.505 (0.490)	Acc@1 85.122 (85.760)
Test model 1 on task 26
Test: [3/3]	loss 0.543 (0.534)	Acc@1 83.020 (83.880)
Test model 1 on task 27
Test: [3/3]	loss 0.537 (0.532)	Acc@1 83.296 (83.580)
Test model 1 on task 28
Test: [3/3]	loss 0.642 (0.609)	Acc@1 79.093 (81.300)
Test model 1 on task 29
Test: [3/3]	loss 0.608 (0.599)	Acc@1 81.582 (81.290)
Test model 1 on task 30
Test: [3/3]	loss 0.673 (0.682)	Acc@1 78.208 (77.920)
############################################################ Avg acc: 89.27
Task 31 Model 1:
0 ['0.717', '4.495']
100 ['1.054', '1.712']
200 ['1.116', '1.332']
300 ['1.154', '1.430']
400 ['1.169', '1.192']
500 ['1.178', '1.407']
600 ['1.193', '0.937']
700 ['1.199', '0.939']
800 ['1.198', '0.964']
900 ['1.202', '0.452']
1000 ['1.220', '0.588']
1100 ['1.218', '0.849']
1200 ['1.210', '0.643']
1300 ['1.209', '0.494']
1400 ['1.212', '0.900']
1500 ['1.222', '1.080']
1600 ['1.229', '0.868']
1700 ['1.239', '0.535']
1800 ['1.245', '0.842']
1900 ['1.234', '1.050']
2000 ['1.234', '0.562']
2100 ['1.236', '0.480']
2200 ['1.235', '0.461']
2300 ['1.237', '0.592']
2400 ['1.248', '0.878']
2500 ['1.243', '0.835']
2600 ['1.248', '1.166']
2700 ['1.250', '0.474']
2800 ['1.253', '0.865']
2900 ['1.254', '1.661']
3000 ['1.252', '0.999']
3100 ['1.253', '0.962']
3200 ['1.248', '0.851']
3300 ['1.253', '0.562']
3400 ['1.254', '1.104']
3500 ['1.255', '0.538']
3600 ['1.259', '0.612']
3700 ['1.248', '0.571']
Train: [1][3750/3750]	loss 0.062 (0.068)	Acc@1 93.750 (71.805)
0 ['1.249', '1.298']
100 ['1.247', '0.571']
200 ['1.263', '0.388']
300 ['1.255', '0.610']
400 ['1.258', '0.806']
500 ['1.251', '0.954']
600 ['1.254', '0.988']
700 ['1.250', '0.900']
800 ['1.252', '0.792']
900 ['1.263', '0.651']
1000 ['1.254', '0.743']
1100 ['1.256', '0.287']
1200 ['1.252', '0.893']
1300 ['1.258', '0.835']
1400 ['1.265', '0.723']
1500 ['1.258', '0.911']
1600 ['1.266', '0.596']
1700 ['1.254', '0.511']
1800 ['1.253', '1.221']
1900 ['1.259', '0.469']
2000 ['1.261', '0.892']
2100 ['1.252', '0.412']
2200 ['1.257', '0.858']
2300 ['1.258', '0.699']
2400 ['1.257', '0.796']
2500 ['1.252', '0.640']
2600 ['1.251', '0.759']
2700 ['1.259', '0.702']
2800 ['1.262', '0.560']
2900 ['1.252', '0.523']
3000 ['1.263', '0.609']
3100 ['1.259', '0.815']
3200 ['1.254', '0.447']
3300 ['1.251', '0.677']
3400 ['1.262', '1.132']
3500 ['1.262', '0.604']
3600 ['1.259', '0.749']
3700 ['1.263', '0.433']
Train: [2][3750/3750]	loss 0.053 (0.065)	Acc@1 93.750 (77.098)
0 ['1.256', '1.170']
100 ['1.251', '0.422']
200 ['1.248', '0.571']
300 ['1.250', '0.771']
400 ['1.252', '0.390']
500 ['1.256', '1.281']
600 ['1.267', '0.874']
700 ['1.267', '0.746']
800 ['1.256', '0.653']
900 ['1.260', '1.116']
1000 ['1.258', '0.822']
1100 ['1.259', '1.025']
1200 ['1.252', '0.646']
1300 ['1.255', '0.734']
1400 ['1.259', '0.840']
1500 ['1.254', '0.540']
1600 ['1.261', '1.027']
1700 ['1.265', '0.823']
1800 ['1.256', '0.396']
1900 ['1.253', '0.692']
2000 ['1.261', '0.655']
2100 ['1.252', '0.416']
2200 ['1.259', '0.715']
2300 ['1.258', '0.900']
2400 ['1.258', '0.973']
2500 ['1.257', '0.722']
2600 ['1.266', '0.721']
2700 ['1.255', '0.621']
2800 ['1.264', '0.889']
2900 ['1.261', '0.632']
3000 ['1.256', '0.414']
3100 ['1.248', '0.906']
3200 ['1.256', '0.922']
3300 ['1.258', '0.512']
3400 ['1.255', '0.697']
3500 ['1.257', '0.826']
3600 ['1.255', '0.663']
3700 ['1.259', '0.657']
Train: [3][3750/3750]	loss 0.061 (0.064)	Acc@1 87.500 (77.587)
0 ['1.258', '0.524']
100 ['1.264', '0.565']
200 ['1.252', '0.585']
300 ['1.257', '0.548']
400 ['1.251', '0.766']
500 ['1.255', '1.094']
600 ['1.256', '0.544']
700 ['1.257', '0.792']
800 ['1.260', '0.933']
900 ['1.258', '0.999']
1000 ['1.255', '0.896']
1100 ['1.257', '0.311']
1200 ['1.271', '0.738']
1300 ['1.259', '0.722']
1400 ['1.250', '0.687']
1500 ['1.255', '1.068']
1600 ['1.253', '0.660']
1700 ['1.257', '0.308']
1800 ['1.259', '0.935']
1900 ['1.259', '0.706']
2000 ['1.256', '1.236']
2100 ['1.257', '0.470']
2200 ['1.254', '0.857']
2300 ['1.261', '0.868']
2400 ['1.263', '1.013']
2500 ['1.254', '0.534']
2600 ['1.264', '0.863']
2700 ['1.260', '0.635']
2800 ['1.247', '1.086']
2900 ['1.250', '0.713']
3000 ['1.263', '0.777']
3100 ['1.254', '0.482']
3200 ['1.266', '0.933']
3300 ['1.253', '0.985']
3400 ['1.266', '1.045']
3500 ['1.262', '0.804']
3600 ['1.259', '0.621']
3700 ['1.253', '0.794']
Train: [4][3750/3750]	loss 0.064 (0.064)	Acc@1 62.500 (77.632)
0 ['1.260', '0.511']
100 ['1.260', '0.966']
200 ['1.265', '0.320']
300 ['1.257', '0.473']
400 ['1.268', '0.432']
500 ['1.265', '0.437']
600 ['1.259', '0.744']
700 ['1.260', '0.535']
800 ['1.266', '0.778']
900 ['1.254', '0.673']
1000 ['1.257', '0.482']
1100 ['1.252', '1.409']
1200 ['1.259', '0.884']
1300 ['1.261', '0.909']
1400 ['1.246', '0.866']
1500 ['1.255', '0.722']
1600 ['1.262', '0.859']
1700 ['1.259', '1.006']
1800 ['1.260', '0.626']
1900 ['1.259', '0.590']
2000 ['1.256', '0.777']
2100 ['1.253', '0.715']
2200 ['1.266', '0.723']
2300 ['1.270', '1.183']
2400 ['1.258', '0.981']
2500 ['1.268', '0.475']
2600 ['1.260', '0.767']
2700 ['1.257', '0.955']
2800 ['1.263', '0.539']
2900 ['1.262', '0.556']
3000 ['1.255', '0.586']
3100 ['1.257', '0.544']
3200 ['1.252', '0.470']
3300 ['1.259', '0.675']
3400 ['1.255', '0.793']
3500 ['1.250', '0.443']
3600 ['1.253', '0.691']
3700 ['1.254', '0.397']
Train: [5][3750/3750]	loss 0.057 (0.064)	Acc@1 81.250 (77.802)
Test model 1 on task 1
Test: [3/3]	loss 0.297 (0.315)	Acc@1 89.768 (89.480)
Test model 1 on task 2
Test: [3/3]	loss 0.234 (0.234)	Acc@1 92.754 (92.200)
Test model 1 on task 3
Test: [3/3]	loss 0.210 (0.219)	Acc@1 93.363 (93.120)
Test model 1 on task 4
Test: [3/3]	loss 0.219 (0.230)	Acc@1 92.865 (92.270)
Test model 1 on task 5
Test: [3/3]	loss 0.219 (0.218)	Acc@1 93.197 (93.220)
Test model 1 on task 6
Test: [3/3]	loss 0.231 (0.216)	Acc@1 93.252 (93.290)
Test model 1 on task 7
Test: [3/3]	loss 0.221 (0.218)	Acc@1 93.308 (93.250)
Test model 1 on task 8
Test: [3/3]	loss 0.224 (0.230)	Acc@1 92.533 (92.750)
Test model 1 on task 9
Test: [3/3]	loss 0.257 (0.234)	Acc@1 92.367 (93.000)
Test model 1 on task 10
Test: [3/3]	loss 0.245 (0.242)	Acc@1 92.588 (92.510)
Test model 1 on task 11
Test: [3/3]	loss 0.217 (0.244)	Acc@1 93.861 (92.530)
Test model 1 on task 12
Test: [3/3]	loss 0.241 (0.248)	Acc@1 92.257 (92.490)
Test model 1 on task 13
Test: [3/3]	loss 0.221 (0.258)	Acc@1 93.750 (92.350)
Test model 1 on task 14
Test: [3/3]	loss 0.288 (0.283)	Acc@1 90.985 (91.380)
Test model 1 on task 15
Test: [3/3]	loss 0.280 (0.283)	Acc@1 91.538 (91.470)
Test model 1 on task 16
Test: [3/3]	loss 0.315 (0.316)	Acc@1 91.316 (90.420)
Test model 1 on task 17
Test: [3/3]	loss 0.298 (0.302)	Acc@1 90.708 (90.920)
Test model 1 on task 18
Test: [3/3]	loss 0.320 (0.317)	Acc@1 90.431 (90.790)
Test model 1 on task 19
Test: [3/3]	loss 0.351 (0.358)	Acc@1 88.993 (88.860)
Test model 1 on task 20
Test: [3/3]	loss 0.386 (0.374)	Acc@1 88.883 (88.960)
Test model 1 on task 21
Test: [3/3]	loss 0.439 (0.398)	Acc@1 86.338 (88.140)
Test model 1 on task 22
Test: [3/3]	loss 0.420 (0.451)	Acc@1 87.223 (86.750)
Test model 1 on task 23
Test: [3/3]	loss 0.436 (0.438)	Acc@1 87.721 (87.240)
Test model 1 on task 24
Test: [3/3]	loss 0.498 (0.478)	Acc@1 84.679 (85.170)
Test model 1 on task 25
Test: [3/3]	loss 0.472 (0.492)	Acc@1 85.785 (85.520)
Test model 1 on task 26
Test: [3/3]	loss 0.512 (0.537)	Acc@1 84.679 (83.760)
Test model 1 on task 27
Test: [3/3]	loss 0.504 (0.532)	Acc@1 84.071 (83.420)
Test model 1 on task 28
Test: [3/3]	loss 0.598 (0.614)	Acc@1 81.803 (80.970)
Test model 1 on task 29
Test: [3/3]	loss 0.577 (0.602)	Acc@1 81.692 (81.220)
Test model 1 on task 30
Test: [3/3]	loss 0.707 (0.689)	Acc@1 76.272 (77.740)
Test model 1 on task 31
Test: [3/3]	loss 0.693 (0.703)	Acc@1 78.595 (78.450)
############################################################ Avg acc: 88.83
Task 32 Model 1:
0 ['0.735', '3.533']
100 ['1.086', '1.551']
200 ['1.146', '2.107']
300 ['1.178', '1.179']
400 ['1.198', '1.274']
500 ['1.211', '1.623']
600 ['1.224', '0.953']
700 ['1.234', '1.345']
800 ['1.244', '0.763']
900 ['1.250', '0.615']
1000 ['1.249', '0.656']
1100 ['1.258', '0.694']
1200 ['1.255', '1.310']
1300 ['1.258', '0.712']
1400 ['1.261', '1.126']
1500 ['1.265', '0.754']
1600 ['1.273', '0.849']
1700 ['1.275', '0.493']
1800 ['1.281', '1.195']
1900 ['1.283', '0.596']
2000 ['1.296', '0.679']
2100 ['1.288', '0.683']
2200 ['1.299', '0.917']
2300 ['1.308', '0.372']
2400 ['1.305', '1.119']
2500 ['1.294', '0.707']
2600 ['1.300', '0.691']
2700 ['1.287', '0.919']
2800 ['1.296', '0.767']
2900 ['1.305', '0.879']
3000 ['1.291', '0.558']
3100 ['1.295', '0.879']
3200 ['1.300', '0.826']
3300 ['1.294', '1.388']
3400 ['1.290', '0.487']
3500 ['1.307', '0.821']
3600 ['1.305', '1.014']
3700 ['1.300', '0.777']
Train: [1][3750/3750]	loss 0.070 (0.070)	Acc@1 81.250 (68.377)
0 ['1.300', '1.294']
100 ['1.303', '1.194']
200 ['1.308', '0.610']
300 ['1.307', '0.957']
400 ['1.302', '1.064']
500 ['1.298', '0.551']
600 ['1.301', '1.426']
700 ['1.300', '0.521']
800 ['1.303', '0.641']
900 ['1.308', '0.870']
1000 ['1.307', '0.799']
1100 ['1.314', '0.692']
1200 ['1.308', '1.130']
1300 ['1.304', '0.609']
1400 ['1.311', '1.275']
1500 ['1.307', '1.189']
1600 ['1.303', '0.705']
1700 ['1.307', '1.180']
1800 ['1.300', '1.207']
1900 ['1.299', '1.106']
2000 ['1.303', '0.773']
2100 ['1.308', '1.011']
2200 ['1.319', '1.047']
2300 ['1.311', '0.429']
2400 ['1.311', '1.020']
2500 ['1.311', '0.680']
2600 ['1.307', '1.251']
2700 ['1.308', '1.041']
2800 ['1.313', '1.004']
2900 ['1.315', '0.833']
3000 ['1.302', '0.777']
3100 ['1.316', '1.174']
3200 ['1.313', '0.689']
3300 ['1.323', '0.925']
3400 ['1.312', '0.781']
3500 ['1.315', '0.928']
3600 ['1.315', '0.893']
3700 ['1.312', '0.870']
Train: [2][3750/3750]	loss 0.068 (0.067)	Acc@1 81.250 (73.773)
0 ['1.309', '1.306']
100 ['1.313', '0.755']
200 ['1.313', '0.796']
300 ['1.311', '0.511']
400 ['1.304', '0.718']
500 ['1.308', '0.845']
600 ['1.313', '1.258']
700 ['1.315', '0.733']
800 ['1.312', '1.179']
900 ['1.311', '1.148']
1000 ['1.319', '0.551']
1100 ['1.328', '1.070']
1200 ['1.317', '0.606']
1300 ['1.312', '0.924']
1400 ['1.309', '0.635']
1500 ['1.304', '0.526']
1600 ['1.300', '0.487']
1700 ['1.309', '0.951']
1800 ['1.307', '1.196']
1900 ['1.312', '0.428']
2000 ['1.317', '0.623']
2100 ['1.318', '0.731']
2200 ['1.321', '0.694']
2300 ['1.317', '0.392']
2400 ['1.308', '0.780']
2500 ['1.319', '0.535']
2600 ['1.308', '0.701']
2700 ['1.316', '0.637']
2800 ['1.313', '0.387']
2900 ['1.304', '0.628']
3000 ['1.305', '0.879']
3100 ['1.312', '0.946']
3200 ['1.315', '1.089']
3300 ['1.315', '0.706']
3400 ['1.323', '0.946']
3500 ['1.309', '0.585']
3600 ['1.305', '0.739']
3700 ['1.298', '0.619']
Train: [3][3750/3750]	loss 0.068 (0.066)	Acc@1 68.750 (74.702)
0 ['1.303', '0.641']
100 ['1.315', '0.833']
200 ['1.317', '0.916']
300 ['1.318', '0.824']
400 ['1.311', '0.563']
500 ['1.313', '0.899']
600 ['1.317', '0.660']
700 ['1.298', '0.761']
800 ['1.309', '0.577']
900 ['1.312', '0.658']
1000 ['1.300', '0.679']
1100 ['1.305', '1.125']
1200 ['1.305', '0.874']
1300 ['1.310', '0.772']
1400 ['1.315', '0.712']
1500 ['1.317', '0.818']
1600 ['1.310', '1.013']
1700 ['1.310', '0.999']
1800 ['1.316', '0.661']
1900 ['1.316', '0.991']
2000 ['1.311', '0.999']
2100 ['1.321', '0.807']
2200 ['1.312', '0.995']
2300 ['1.314', '0.849']
2400 ['1.310', '0.662']
2500 ['1.319', '0.701']
2600 ['1.308', '0.617']
2700 ['1.306', '0.603']
2800 ['1.309', '0.711']
2900 ['1.300', '0.802']
3000 ['1.310', '0.871']
3100 ['1.309', '1.305']
3200 ['1.312', '0.630']
3300 ['1.316', '0.646']
3400 ['1.300', '1.118']
3500 ['1.311', '0.623']
3600 ['1.313', '0.657']
3700 ['1.316', '0.971']
Train: [4][3750/3750]	loss 0.067 (0.066)	Acc@1 68.750 (74.937)
0 ['1.313', '0.863']
100 ['1.314', '0.834']
200 ['1.309', '1.465']
300 ['1.313', '0.899']
400 ['1.314', '1.315']
500 ['1.312', '0.849']
600 ['1.309', '0.947']
700 ['1.324', '0.649']
800 ['1.311', '1.021']
900 ['1.304', '1.109']
1000 ['1.308', '0.568']
1100 ['1.325', '1.099']
1200 ['1.314', '1.021']
1300 ['1.309', '1.081']
1400 ['1.305', '0.703']
1500 ['1.313', '0.753']
1600 ['1.316', '0.730']
1700 ['1.310', '1.253']
1800 ['1.317', '0.715']
1900 ['1.307', '1.102']
2000 ['1.313', '0.993']
2100 ['1.311', '1.199']
2200 ['1.318', '0.948']
2300 ['1.318', '0.900']
2400 ['1.319', '0.503']
2500 ['1.312', '1.028']
2600 ['1.310', '0.852']
2700 ['1.303', '0.693']
2800 ['1.316', '0.959']
2900 ['1.314', '1.062']
3000 ['1.319', '0.612']
3100 ['1.313', '0.871']
3200 ['1.307', '0.733']
3300 ['1.312', '0.961']
3400 ['1.309', '0.627']
3500 ['1.306', '0.616']
3600 ['1.312', '0.816']
3700 ['1.313', '0.819']
Train: [5][3750/3750]	loss 0.069 (0.066)	Acc@1 68.750 (75.030)
Test model 1 on task 1
Test: [3/3]	loss 0.341 (0.317)	Acc@1 88.883 (89.470)
Test model 1 on task 2
Test: [3/3]	loss 0.252 (0.237)	Acc@1 92.091 (92.030)
Test model 1 on task 3
Test: [3/3]	loss 0.225 (0.220)	Acc@1 92.478 (93.090)
Test model 1 on task 4
Test: [3/3]	loss 0.262 (0.232)	Acc@1 91.427 (92.430)
Test model 1 on task 5
Test: [3/3]	loss 0.207 (0.220)	Acc@1 93.418 (93.250)
Test model 1 on task 6
Test: [3/3]	loss 0.235 (0.217)	Acc@1 92.423 (93.250)
Test model 1 on task 7
Test: [3/3]	loss 0.197 (0.220)	Acc@1 94.414 (93.310)
Test model 1 on task 8
Test: [3/3]	loss 0.208 (0.231)	Acc@1 93.695 (92.710)
Test model 1 on task 9
Test: [3/3]	loss 0.237 (0.238)	Acc@1 92.644 (92.930)
Test model 1 on task 10
Test: [3/3]	loss 0.243 (0.243)	Acc@1 92.644 (92.460)
Test model 1 on task 11
Test: [3/3]	loss 0.240 (0.247)	Acc@1 92.810 (92.350)
Test model 1 on task 12
Test: [3/3]	loss 0.246 (0.249)	Acc@1 92.754 (92.620)
Test model 1 on task 13
Test: [3/3]	loss 0.279 (0.260)	Acc@1 91.869 (92.280)
Test model 1 on task 14
Test: [3/3]	loss 0.288 (0.285)	Acc@1 90.763 (91.210)
Test model 1 on task 15
Test: [3/3]	loss 0.297 (0.284)	Acc@1 90.431 (91.480)
Test model 1 on task 16
Test: [3/3]	loss 0.317 (0.318)	Acc@1 90.929 (90.440)
Test model 1 on task 17
Test: [3/3]	loss 0.288 (0.304)	Acc@1 91.095 (90.800)
Test model 1 on task 18
Test: [3/3]	loss 0.315 (0.320)	Acc@1 90.985 (90.740)
Test model 1 on task 19
Test: [3/3]	loss 0.350 (0.361)	Acc@1 88.385 (88.710)
Test model 1 on task 20
Test: [3/3]	loss 0.400 (0.375)	Acc@1 87.942 (88.950)
Test model 1 on task 21
Test: [3/3]	loss 0.409 (0.397)	Acc@1 87.223 (88.060)
Test model 1 on task 22
Test: [3/3]	loss 0.468 (0.452)	Acc@1 86.504 (86.640)
Test model 1 on task 23
Test: [3/3]	loss 0.456 (0.442)	Acc@1 86.670 (86.880)
Test model 1 on task 24
Test: [3/3]	loss 0.482 (0.482)	Acc@1 84.845 (85.140)
Test model 1 on task 25
Test: [3/3]	loss 0.512 (0.494)	Acc@1 84.735 (85.430)
Test model 1 on task 26
Test: [3/3]	loss 0.553 (0.537)	Acc@1 83.075 (83.710)
Test model 1 on task 27
Test: [3/3]	loss 0.551 (0.537)	Acc@1 83.075 (83.270)
Test model 1 on task 28
Test: [3/3]	loss 0.611 (0.614)	Acc@1 80.531 (80.770)
Test model 1 on task 29
Test: [3/3]	loss 0.613 (0.605)	Acc@1 80.863 (81.090)
Test model 1 on task 30
Test: [3/3]	loss 0.694 (0.690)	Acc@1 76.936 (77.670)
Test model 1 on task 31
Test: [3/3]	loss 0.712 (0.702)	Acc@1 78.429 (78.470)
Test model 1 on task 32
Test: [3/3]	loss 0.727 (0.754)	Acc@1 76.438 (76.270)
############################################################ Avg acc: 88.37
Task 33 Model 1:
0 ['0.801', '3.783']
100 ['1.082', '1.947']
200 ['1.182', '1.224']
300 ['1.218', '0.905']
400 ['1.250', '1.216']
500 ['1.269', '0.964']
600 ['1.288', '1.723']
700 ['1.290', '1.254']
800 ['1.313', '0.812']
900 ['1.321', '1.118']
1000 ['1.318', '1.027']
1100 ['1.330', '1.193']
1200 ['1.340', '0.615']
1300 ['1.336', '1.002']
1400 ['1.337', '1.218']
1500 ['1.344', '0.899']
1600 ['1.340', '1.025']
1700 ['1.351', '1.057']
1800 ['1.353', '0.768']
1900 ['1.353', '1.270']
2000 ['1.351', '0.709']
2100 ['1.362', '0.910']
2200 ['1.355', '0.931']
2300 ['1.357', '0.994']
2400 ['1.357', '0.970']
2500 ['1.368', '0.641']
2600 ['1.365', '0.533']
2700 ['1.369', '1.185']
2800 ['1.367', '0.669']
2900 ['1.369', '0.403']
3000 ['1.365', '1.203']
3100 ['1.373', '0.398']
3200 ['1.381', '0.671']
3300 ['1.366', '1.139']
3400 ['1.370', '1.314']
3500 ['1.363', '0.652']
3600 ['1.366', '0.750']
3700 ['1.362', '0.435']
Train: [1][3750/3750]	loss 0.069 (0.071)	Acc@1 75.000 (67.128)
0 ['1.359', '0.547']
100 ['1.367', '0.766']
200 ['1.361', '0.720']
300 ['1.373', '0.485']
400 ['1.369', '0.681']
500 ['1.371', '0.798']
600 ['1.374', '0.766']
700 ['1.374', '0.748']
800 ['1.372', '0.688']
900 ['1.376', '1.137']
1000 ['1.365', '0.766']
1100 ['1.369', '0.594']
1200 ['1.379', '0.885']
1300 ['1.375', '0.769']
1400 ['1.372', '1.043']
1500 ['1.375', '0.968']
1600 ['1.380', '0.827']
1700 ['1.368', '1.261']
1800 ['1.377', '0.566']
1900 ['1.370', '0.971']
2000 ['1.375', '0.520']
2100 ['1.371', '0.833']
2200 ['1.388', '1.299']
2300 ['1.375', '0.995']
2400 ['1.372', '0.706']
2500 ['1.375', '1.170']
2600 ['1.370', '1.188']
2700 ['1.368', '0.810']
2800 ['1.383', '0.442']
2900 ['1.382', '0.696']
3000 ['1.374', '1.143']
3100 ['1.379', '0.941']
3200 ['1.373', '0.546']
3300 ['1.386', '0.811']
3400 ['1.382', '0.927']
3500 ['1.377', '0.823']
3600 ['1.380', '0.835']
3700 ['1.378', '0.908']
Train: [2][3750/3750]	loss 0.091 (0.068)	Acc@1 50.000 (72.727)
0 ['1.381', '0.934']
100 ['1.376', '0.856']
200 ['1.368', '0.944']
300 ['1.379', '0.791']
400 ['1.383', '0.753']
500 ['1.376', '0.999']
600 ['1.379', '0.796']
700 ['1.382', '0.622']
800 ['1.382', '0.859']
900 ['1.384', '0.370']
1000 ['1.386', '0.898']
1100 ['1.382', '0.628']
1200 ['1.376', '0.424']
1300 ['1.382', '0.506']
1400 ['1.376', '1.205']
1500 ['1.390', '0.798']
1600 ['1.388', '0.820']
1700 ['1.380', '0.719']
1800 ['1.382', '0.927']
1900 ['1.378', '0.590']
2000 ['1.376', '0.603']
2100 ['1.377', '0.691']
2200 ['1.379', '0.896']
2300 ['1.383', '0.588']
2400 ['1.377', '0.838']
2500 ['1.380', '1.009']
2600 ['1.390', '1.194']
2700 ['1.389', '1.071']
2800 ['1.381', '0.450']
2900 ['1.381', '0.969']
3000 ['1.379', '1.154']
3100 ['1.377', '1.207']
3200 ['1.375', '1.008']
3300 ['1.378', '0.702']
3400 ['1.384', '0.572']
3500 ['1.384', '0.972']
3600 ['1.380', '0.889']
3700 ['1.385', '0.973']
Train: [3][3750/3750]	loss 0.068 (0.068)	Acc@1 68.750 (73.022)
0 ['1.385', '0.742']
100 ['1.379', '0.696']
200 ['1.380', '0.792']
300 ['1.379', '0.597']
400 ['1.378', '0.503']
500 ['1.375', '0.845']
600 ['1.380', '0.748']
700 ['1.381', '0.942']
800 ['1.390', '0.699']
900 ['1.392', '0.957']
1000 ['1.382', '0.790']
1100 ['1.385', '0.680']
1200 ['1.390', '0.681']
1300 ['1.388', '1.083']
1400 ['1.382', '0.935']
1500 ['1.390', '0.979']
1600 ['1.387', '0.790']
1700 ['1.390', '0.754']
1800 ['1.387', '1.185']
1900 ['1.392', '1.411']
2000 ['1.390', '0.647']
2100 ['1.385', '0.536']
2200 ['1.375', '0.621']
2300 ['1.379', '0.909']
2400 ['1.386', '0.927']
2500 ['1.385', '0.797']
2600 ['1.381', '1.031']
2700 ['1.383', '0.764']
2800 ['1.386', '0.574']
2900 ['1.388', '0.794']
3000 ['1.383', '0.920']
3100 ['1.375', '0.827']
3200 ['1.382', '1.329']
3300 ['1.385', '0.512']
3400 ['1.379', '0.467']
3500 ['1.377', '1.168']
3600 ['1.382', '0.557']
3700 ['1.384', '0.598']
Train: [4][3750/3750]	loss 0.070 (0.067)	Acc@1 62.500 (73.313)
0 ['1.372', '0.882']
100 ['1.378', '0.809']
200 ['1.387', '0.651']
300 ['1.389', '0.597']
400 ['1.390', '0.678']
500 ['1.393', '0.640']
600 ['1.386', '1.120']
700 ['1.383', '0.598']
800 ['1.384', '0.597']
900 ['1.392', '0.604']
1000 ['1.389', '0.401']
1100 ['1.388', '0.738']
1200 ['1.388', '0.697']
1300 ['1.392', '1.023']
1400 ['1.391', '0.691']
1500 ['1.375', '0.910']
1600 ['1.383', '0.651']
1700 ['1.379', '0.981']
1800 ['1.387', '1.092']
1900 ['1.388', '0.753']
2000 ['1.379', '0.758']
2100 ['1.389', '0.525']
2200 ['1.383', '0.503']
2300 ['1.387', '0.557']
2400 ['1.398', '1.071']
2500 ['1.387', '1.284']
2600 ['1.390', '0.593']
2700 ['1.384', '0.743']
2800 ['1.381', '0.945']
2900 ['1.387', '0.633']
3000 ['1.380', '1.109']
3100 ['1.380', '0.643']
3200 ['1.378', '1.069']
3300 ['1.383', '1.140']
3400 ['1.387', '0.976']
3500 ['1.384', '0.847']
3600 ['1.376', '0.596']
3700 ['1.385', '1.665']
Train: [5][3750/3750]	loss 0.064 (0.067)	Acc@1 81.250 (73.412)
Test model 1 on task 1
Test: [3/3]	loss 0.305 (0.316)	Acc@1 90.431 (89.580)
Test model 1 on task 2
Test: [3/3]	loss 0.249 (0.239)	Acc@1 91.648 (92.060)
Test model 1 on task 3
Test: [3/3]	loss 0.198 (0.220)	Acc@1 93.086 (93.020)
Test model 1 on task 4
Test: [3/3]	loss 0.230 (0.233)	Acc@1 92.865 (92.330)
Test model 1 on task 5
Test: [3/3]	loss 0.216 (0.222)	Acc@1 93.197 (93.270)
Test model 1 on task 6
Test: [3/3]	loss 0.216 (0.220)	Acc@1 93.418 (93.080)
Test model 1 on task 7
Test: [3/3]	loss 0.215 (0.223)	Acc@1 93.418 (93.200)
Test model 1 on task 8
Test: [3/3]	loss 0.218 (0.232)	Acc@1 93.142 (92.700)
Test model 1 on task 9
Test: [3/3]	loss 0.259 (0.238)	Acc@1 92.423 (92.970)
Test model 1 on task 10
Test: [3/3]	loss 0.235 (0.244)	Acc@1 92.533 (92.480)
Test model 1 on task 11
Test: [3/3]	loss 0.256 (0.249)	Acc@1 92.091 (92.260)
Test model 1 on task 12
Test: [3/3]	loss 0.267 (0.251)	Acc@1 91.759 (92.580)
Test model 1 on task 13
Test: [3/3]	loss 0.283 (0.262)	Acc@1 91.316 (92.320)
Test model 1 on task 14
Test: [3/3]	loss 0.281 (0.287)	Acc@1 91.040 (91.170)
Test model 1 on task 15
Test: [3/3]	loss 0.270 (0.286)	Acc@1 92.588 (91.450)
Test model 1 on task 16
Test: [3/3]	loss 0.319 (0.320)	Acc@1 90.265 (90.320)
Test model 1 on task 17
Test: [3/3]	loss 0.285 (0.306)	Acc@1 91.316 (90.770)
Test model 1 on task 18
Test: [3/3]	loss 0.328 (0.321)	Acc@1 90.929 (90.730)
Test model 1 on task 19
Test: [3/3]	loss 0.372 (0.363)	Acc@1 87.942 (88.730)
Test model 1 on task 20
Test: [3/3]	loss 0.367 (0.377)	Acc@1 88.883 (88.890)
Test model 1 on task 21
Test: [3/3]	loss 0.411 (0.398)	Acc@1 87.887 (88.170)
Test model 1 on task 22
Test: [3/3]	loss 0.443 (0.454)	Acc@1 87.168 (86.640)
Test model 1 on task 23
Test: [3/3]	loss 0.453 (0.445)	Acc@1 86.394 (86.940)
Test model 1 on task 24
Test: [3/3]	loss 0.459 (0.485)	Acc@1 86.173 (85.180)
Test model 1 on task 25
Test: [3/3]	loss 0.525 (0.498)	Acc@1 83.684 (85.320)
Test model 1 on task 26
Test: [3/3]	loss 0.538 (0.537)	Acc@1 83.794 (83.730)
Test model 1 on task 27
Test: [3/3]	loss 0.550 (0.537)	Acc@1 82.743 (83.270)
Test model 1 on task 28
Test: [3/3]	loss 0.563 (0.616)	Acc@1 82.633 (80.810)
Test model 1 on task 29
Test: [3/3]	loss 0.617 (0.604)	Acc@1 80.033 (81.120)
Test model 1 on task 30
Test: [3/3]	loss 0.696 (0.692)	Acc@1 77.268 (77.790)
Test model 1 on task 31
Test: [3/3]	loss 0.709 (0.703)	Acc@1 77.323 (78.460)
Test model 1 on task 32
Test: [3/3]	loss 0.775 (0.753)	Acc@1 75.996 (76.110)
Test model 1 on task 33
Test: [3/3]	loss 0.785 (0.805)	Acc@1 75.498 (74.450)
############################################################ Avg acc: 87.94
Task 34 Model 1:
0 ['0.823', '3.012']
100 ['1.155', '1.724']
200 ['1.232', '1.360']
300 ['1.266', '2.030']
400 ['1.289', '1.177']
500 ['1.317', '1.113']
600 ['1.339', '1.199']
700 ['1.341', '0.972']
800 ['1.367', '1.545']
900 ['1.378', '1.359']
1000 ['1.380', '0.902']
1100 ['1.384', '1.122']
1200 ['1.380', '1.021']
1300 ['1.394', '0.650']
1400 ['1.393', '1.121']
1500 ['1.401', '0.507']
1600 ['1.410', '1.638']
1700 ['1.411', '1.941']
1800 ['1.403', '0.943']
1900 ['1.404', '0.981']
2000 ['1.400', '1.263']
2100 ['1.417', '0.577']
2200 ['1.420', '0.809']
2300 ['1.426', '0.950']
2400 ['1.424', '1.072']
2500 ['1.430', '0.869']
2600 ['1.432', '1.460']
2700 ['1.438', '0.951']
2800 ['1.430', '0.817']
2900 ['1.436', '1.356']
3000 ['1.433', '0.515']
3100 ['1.438', '0.693']
3200 ['1.435', '0.928']
3300 ['1.432', '0.788']
3400 ['1.438', '0.625']
3500 ['1.435', '1.068']
3600 ['1.434', '0.612']
3700 ['1.433', '0.792']
Train: [1][3750/3750]	loss 0.065 (0.072)	Acc@1 75.000 (65.563)
0 ['1.433', '0.817']
100 ['1.430', '0.988']
200 ['1.442', '0.646']
300 ['1.443', '0.833']
400 ['1.449', '0.881']
500 ['1.452', '0.980']
600 ['1.444', '1.134']
700 ['1.442', '0.843']
800 ['1.434', '1.072']
900 ['1.437', '0.689']
1000 ['1.428', '0.816']
1100 ['1.444', '1.148']
1200 ['1.440', '0.712']
1300 ['1.437', '0.987']
1400 ['1.441', '0.930']
1500 ['1.441', '0.874']
1600 ['1.442', '1.080']
1700 ['1.447', '0.924']
1800 ['1.444', '0.843']
1900 ['1.442', '1.244']
2000 ['1.449', '0.707']
2100 ['1.449', '0.691']
2200 ['1.430', '0.735']
2300 ['1.441', '1.012']
2400 ['1.437', '1.370']
2500 ['1.447', '0.904']
2600 ['1.456', '0.683']
2700 ['1.445', '1.705']
2800 ['1.451', '0.606']
2900 ['1.453', '0.838']
3000 ['1.447', '0.757']
3100 ['1.452', '1.069']
3200 ['1.439', '0.976']
3300 ['1.456', '0.783']
3400 ['1.449', '1.225']
3500 ['1.446', '0.683']
3600 ['1.444', '0.558']
3700 ['1.457', '0.757']
Train: [2][3750/3750]	loss 0.062 (0.069)	Acc@1 81.250 (70.885)
0 ['1.448', '1.286']
100 ['1.452', '0.977']
200 ['1.447', '1.099']
300 ['1.455', '0.464']
400 ['1.441', '1.257']
500 ['1.454', '0.736']
600 ['1.453', '0.518']
700 ['1.448', '1.095']
800 ['1.452', '0.990']
900 ['1.459', '1.067']
1000 ['1.444', '0.909']
1100 ['1.454', '0.635']
1200 ['1.442', '0.592']
1300 ['1.453', '0.776']
1400 ['1.444', '0.338']
1500 ['1.452', '0.886']
1600 ['1.457', '0.680']
1700 ['1.455', '0.832']
1800 ['1.441', '0.901']
1900 ['1.443', '1.255']
2000 ['1.443', '0.992']
2100 ['1.451', '1.249']
2200 ['1.438', '1.381']
2300 ['1.442', '1.270']
2400 ['1.444', '1.018']
2500 ['1.444', '0.952']
2600 ['1.445', '0.856']
2700 ['1.451', '1.164']
2800 ['1.440', '0.580']
2900 ['1.453', '0.852']
3000 ['1.444', '0.984']
3100 ['1.459', '0.768']
3200 ['1.464', '0.789']
3300 ['1.461', '0.903']
3400 ['1.463', '1.013']
3500 ['1.463', '0.879']
3600 ['1.451', '1.139']
3700 ['1.449', '0.635']
Train: [3][3750/3750]	loss 0.074 (0.069)	Acc@1 75.000 (71.233)
0 ['1.452', '1.001']
100 ['1.450', '1.028']
200 ['1.459', '1.509']
300 ['1.461', '1.186']
400 ['1.457', '0.846']
500 ['1.452', '1.012']
600 ['1.460', '1.126']
700 ['1.459', '1.339']
800 ['1.460', '1.044']
900 ['1.456', '0.667']
1000 ['1.457', '0.744']
1100 ['1.447', '1.139']
1200 ['1.455', '1.232']
1300 ['1.453', '0.953']
1400 ['1.442', '0.969']
1500 ['1.452', '1.154']
1600 ['1.449', '0.996']
1700 ['1.463', '0.790']
1800 ['1.438', '1.054']
1900 ['1.453', '1.359']
2000 ['1.448', '1.031']
2100 ['1.456', '0.879']
2200 ['1.450', '1.562']
2300 ['1.460', '0.652']
2400 ['1.453', '0.974']
2500 ['1.467', '1.152']
2600 ['1.461', '0.536']
2700 ['1.457', '1.180']
2800 ['1.458', '0.691']
2900 ['1.453', '0.600']
3000 ['1.455', '0.951']
3100 ['1.470', '0.923']
3200 ['1.443', '0.964']
3300 ['1.455', '0.638']
3400 ['1.443', '0.746']
3500 ['1.447', '0.533']
3600 ['1.440', '0.620']
3700 ['1.451', '0.932']
Train: [4][3750/3750]	loss 0.085 (0.069)	Acc@1 68.750 (71.375)
0 ['1.460', '0.980']
100 ['1.457', '1.312']
200 ['1.455', '0.647']
300 ['1.459', '1.093']
400 ['1.458', '1.230']
500 ['1.453', '0.616']
600 ['1.460', '0.880']
700 ['1.455', '0.897']
800 ['1.458', '1.311']
900 ['1.448', '0.937']
1000 ['1.457', '0.587']
1100 ['1.463', '0.546']
1200 ['1.469', '0.552']
1300 ['1.449', '0.706']
1400 ['1.466', '0.676']
1500 ['1.454', '1.126']
1600 ['1.446', '1.004']
1700 ['1.455', '0.826']
1800 ['1.449', '0.794']
1900 ['1.454', '0.877']
2000 ['1.448', '1.060']
2100 ['1.447', '1.223']
2200 ['1.454', '0.830']
2300 ['1.448', '1.057']
2400 ['1.458', '1.259']
2500 ['1.448', '0.641']
2600 ['1.446', '1.111']
2700 ['1.454', '0.907']
2800 ['1.460', '0.794']
2900 ['1.458', '0.417']
3000 ['1.462', '1.658']
3100 ['1.454', '0.660']
3200 ['1.464', '0.788']
3300 ['1.458', '1.138']
3400 ['1.463', '1.168']
3500 ['1.462', '0.943']
3600 ['1.461', '0.720']
3700 ['1.459', '0.803']
Train: [5][3750/3750]	loss 0.065 (0.069)	Acc@1 68.750 (71.477)
Test model 1 on task 1
Test: [3/3]	loss 0.293 (0.317)	Acc@1 89.768 (89.530)
Test model 1 on task 2
Test: [3/3]	loss 0.243 (0.240)	Acc@1 92.091 (92.070)
Test model 1 on task 3
Test: [3/3]	loss 0.241 (0.221)	Acc@1 92.035 (92.910)
Test model 1 on task 4
Test: [3/3]	loss 0.240 (0.235)	Acc@1 91.759 (92.210)
Test model 1 on task 5
Test: [3/3]	loss 0.201 (0.223)	Acc@1 93.916 (93.220)
Test model 1 on task 6
Test: [3/3]	loss 0.235 (0.223)	Acc@1 92.588 (92.940)
Test model 1 on task 7
Test: [3/3]	loss 0.213 (0.224)	Acc@1 93.750 (93.240)
Test model 1 on task 8
Test: [3/3]	loss 0.225 (0.234)	Acc@1 92.533 (92.660)
Test model 1 on task 9
Test: [3/3]	loss 0.246 (0.238)	Acc@1 92.257 (92.890)
Test model 1 on task 10
Test: [3/3]	loss 0.252 (0.247)	Acc@1 92.257 (92.370)
Test model 1 on task 11
Test: [3/3]	loss 0.249 (0.252)	Acc@1 92.312 (92.220)
Test model 1 on task 12
Test: [3/3]	loss 0.252 (0.252)	Acc@1 92.367 (92.520)
Test model 1 on task 13
Test: [3/3]	loss 0.284 (0.263)	Acc@1 91.980 (92.220)
Test model 1 on task 14
Test: [3/3]	loss 0.274 (0.290)	Acc@1 91.538 (91.090)
Test model 1 on task 15
Test: [3/3]	loss 0.265 (0.291)	Acc@1 91.925 (91.300)
Test model 1 on task 16
Test: [3/3]	loss 0.304 (0.322)	Acc@1 90.542 (90.330)
Test model 1 on task 17
Test: [3/3]	loss 0.323 (0.305)	Acc@1 89.823 (90.840)
Test model 1 on task 18
Test: [3/3]	loss 0.320 (0.323)	Acc@1 91.538 (90.650)
Test model 1 on task 19
Test: [3/3]	loss 0.351 (0.363)	Acc@1 89.657 (88.850)
Test model 1 on task 20
Test: [3/3]	loss 0.355 (0.380)	Acc@1 89.270 (88.830)
Test model 1 on task 21
Test: [3/3]	loss 0.379 (0.399)	Acc@1 88.440 (88.140)
Test model 1 on task 22
Test: [3/3]	loss 0.460 (0.457)	Acc@1 86.670 (86.450)
Test model 1 on task 23
Test: [3/3]	loss 0.447 (0.446)	Acc@1 87.058 (86.890)
Test model 1 on task 24
Test: [3/3]	loss 0.488 (0.489)	Acc@1 85.398 (85.020)
Test model 1 on task 25
Test: [3/3]	loss 0.505 (0.499)	Acc@1 85.288 (85.350)
Test model 1 on task 26
Test: [3/3]	loss 0.519 (0.539)	Acc@1 85.454 (83.720)
Test model 1 on task 27
Test: [3/3]	loss 0.546 (0.542)	Acc@1 83.407 (83.220)
Test model 1 on task 28
Test: [3/3]	loss 0.638 (0.621)	Acc@1 80.144 (80.530)
Test model 1 on task 29
Test: [3/3]	loss 0.608 (0.603)	Acc@1 81.527 (81.200)
Test model 1 on task 30
Test: [3/3]	loss 0.686 (0.689)	Acc@1 78.650 (78.050)
Test model 1 on task 31
Test: [3/3]	loss 0.728 (0.703)	Acc@1 78.153 (78.250)
Test model 1 on task 32
Test: [3/3]	loss 0.754 (0.754)	Acc@1 75.996 (76.320)
Test model 1 on task 33
Test: [3/3]	loss 0.776 (0.805)	Acc@1 74.723 (74.310)
Test model 1 on task 34
Test: [3/3]	loss 0.839 (0.848)	Acc@1 72.511 (72.760)
############################################################ Avg acc: 87.44
Task 35 Model 1:
0 ['0.872', '3.702']
100 ['1.132', '1.919']
200 ['1.209', '1.912']
300 ['1.267', '1.295']
400 ['1.289', '1.604']
500 ['1.322', '1.086']
600 ['1.333', '1.489']
700 ['1.363', '1.059']
800 ['1.376', '1.285']
900 ['1.391', '1.357']
1000 ['1.401', '1.160']
1100 ['1.397', '1.143']
1200 ['1.415', '1.086']
1300 ['1.412', '1.029']
1400 ['1.423', '1.049']
1500 ['1.419', '1.175']
1600 ['1.422', '1.425']
1700 ['1.428', '0.987']
1800 ['1.447', '1.073']
1900 ['1.437', '1.013']
2000 ['1.441', '1.381']
2100 ['1.443', '1.164']
2200 ['1.437', '1.216']
2300 ['1.454', '1.456']
2400 ['1.454', '0.757']
2500 ['1.449', '0.929']
2600 ['1.448', '1.057']
2700 ['1.442', '0.769']
2800 ['1.451', '0.751']
2900 ['1.452', '1.281']
3000 ['1.455', '0.797']
3100 ['1.455', '1.060']
3200 ['1.471', '0.551']
3300 ['1.464', '0.779']
3400 ['1.454', '1.488']
3500 ['1.453', '0.421']
3600 ['1.454', '0.864']
3700 ['1.459', '0.652']
Train: [1][3750/3750]	loss 0.067 (0.073)	Acc@1 62.500 (62.670)
0 ['1.457', '1.019']
100 ['1.457', '1.393']
200 ['1.457', '1.141']
300 ['1.461', '0.403']
400 ['1.453', '0.623']
500 ['1.472', '0.669']
600 ['1.476', '0.936']
700 ['1.478', '0.965']
800 ['1.465', '0.726']
900 ['1.473', '0.854']
1000 ['1.461', '0.856']
1100 ['1.468', '0.743']
1200 ['1.466', '0.862']
1300 ['1.469', '1.074']
1400 ['1.470', '0.794']
1500 ['1.467', '0.595']
1600 ['1.459', '1.292']
1700 ['1.468', '0.941']
1800 ['1.469', '0.855']
1900 ['1.467', '1.341']
2000 ['1.471', '0.974']
2100 ['1.477', '1.192']
2200 ['1.468', '0.852']
2300 ['1.474', '0.750']
2400 ['1.459', '1.159']
2500 ['1.470', '1.214']
2600 ['1.459', '1.610']
2700 ['1.464', '0.666']
2800 ['1.454', '1.156']
2900 ['1.458', '0.768']
3000 ['1.465', '0.728']
3100 ['1.478', '1.117']
3200 ['1.476', '1.094']
3300 ['1.453', '1.010']
3400 ['1.467', '0.754']
3500 ['1.464', '1.053']
3600 ['1.465', '1.064']
3700 ['1.460', '0.773']
Train: [2][3750/3750]	loss 0.054 (0.070)	Acc@1 93.750 (68.157)
0 ['1.472', '0.755']
100 ['1.457', '1.156']
200 ['1.466', '0.756']
300 ['1.469', '0.954']
400 ['1.469', '0.822']
500 ['1.469', '1.410']
600 ['1.472', '0.477']
700 ['1.469', '0.812']
800 ['1.467', '1.141']
900 ['1.470', '0.992']
1000 ['1.475', '1.333']
1100 ['1.467', '1.080']
1200 ['1.469', '1.789']
1300 ['1.474', '1.097']
1400 ['1.473', '1.404']
1500 ['1.475', '0.788']
1600 ['1.471', '0.864']
1700 ['1.468', '0.914']
1800 ['1.468', '1.047']
1900 ['1.471', '0.786']
2000 ['1.465', '0.670']
2100 ['1.463', '0.991']
2200 ['1.466', '0.784']
2300 ['1.468', '1.481']
2400 ['1.465', '0.961']
2500 ['1.464', '0.982']
2600 ['1.468', '0.819']
2700 ['1.476', '0.847']
2800 ['1.479', '1.025']
2900 ['1.472', '0.974']
3000 ['1.473', '0.849']
3100 ['1.479', '1.091']
3200 ['1.470', '0.606']
3300 ['1.463', '0.676']
3400 ['1.470', '0.775']
3500 ['1.474', '0.877']
3600 ['1.473', '1.336']
3700 ['1.468', '1.080']
Train: [3][3750/3750]	loss 0.069 (0.070)	Acc@1 75.000 (68.505)
0 ['1.468', '0.744']
100 ['1.471', '1.374']
200 ['1.480', '0.600']
300 ['1.481', '0.557']
400 ['1.470', '0.601']
500 ['1.471', '1.389']
600 ['1.475', '1.448']
700 ['1.474', '1.308']
800 ['1.469', '0.672']
900 ['1.477', '1.052']
1000 ['1.473', '0.912']
1100 ['1.467', '0.881']
1200 ['1.476', '0.901']
1300 ['1.477', '0.839']
1400 ['1.468', '0.832']
1500 ['1.482', '1.705']
1600 ['1.477', '1.650']
1700 ['1.470', '1.201']
1800 ['1.470', '0.947']
1900 ['1.484', '1.320']
2000 ['1.480', '0.619']
2100 ['1.474', '0.867']
2200 ['1.479', '0.677']
2300 ['1.482', '1.028']
2400 ['1.478', '1.065']
2500 ['1.484', '0.760']
2600 ['1.470', '0.670']
2700 ['1.483', '1.163']
2800 ['1.477', '1.175']
2900 ['1.470', '1.036']
3000 ['1.467', '1.315']
3100 ['1.473', '0.596']
3200 ['1.472', '0.913']
3300 ['1.476', '1.335']
3400 ['1.467', '0.955']
3500 ['1.477', '0.803']
3600 ['1.477', '0.812']
3700 ['1.476', '1.215']
Train: [4][3750/3750]	loss 0.067 (0.070)	Acc@1 75.000 (68.713)
0 ['1.477', '0.642']
100 ['1.483', '0.759']
200 ['1.484', '1.004']
300 ['1.480', '1.529']
400 ['1.485', '1.178']
500 ['1.476', '0.684']
600 ['1.473', '0.745']
700 ['1.480', '1.239']
800 ['1.479', '0.835']
900 ['1.485', '0.593']
1000 ['1.482', '1.224']
1100 ['1.482', '1.080']
1200 ['1.492', '0.994']
1300 ['1.489', '1.473']
1400 ['1.478', '0.812']
1500 ['1.481', '0.562']
1600 ['1.485', '1.016']
1700 ['1.472', '0.961']
1800 ['1.473', '0.907']
1900 ['1.468', '1.300']
2000 ['1.474', '1.190']
2100 ['1.472', '0.752']
2200 ['1.472', '0.661']
2300 ['1.482', '0.702']
2400 ['1.473', '0.818']
2500 ['1.479', '0.665']
2600 ['1.478', '1.028']
2700 ['1.482', '0.743']
2800 ['1.475', '0.654']
2900 ['1.479', '0.764']
3000 ['1.474', '0.910']
3100 ['1.480', '0.979']
3200 ['1.473', '1.474']
3300 ['1.471', '1.188']
3400 ['1.473', '1.181']
3500 ['1.474', '0.611']
3600 ['1.475', '0.806']
3700 ['1.466', '0.910']
Train: [5][3750/3750]	loss 0.086 (0.070)	Acc@1 50.000 (68.948)
Test model 1 on task 1
Test: [3/3]	loss 0.348 (0.317)	Acc@1 88.551 (89.480)
Test model 1 on task 2
Test: [3/3]	loss 0.253 (0.241)	Acc@1 91.538 (92.030)
Test model 1 on task 3
Test: [3/3]	loss 0.224 (0.221)	Acc@1 92.920 (92.930)
Test model 1 on task 4
Test: [3/3]	loss 0.221 (0.238)	Acc@1 92.644 (92.130)
Test model 1 on task 5
Test: [3/3]	loss 0.225 (0.225)	Acc@1 93.750 (93.130)
Test model 1 on task 6
Test: [3/3]	loss 0.234 (0.224)	Acc@1 92.644 (93.000)
Test model 1 on task 7
Test: [3/3]	loss 0.209 (0.226)	Acc@1 93.695 (93.090)
Test model 1 on task 8
Test: [3/3]	loss 0.226 (0.236)	Acc@1 93.031 (92.510)
Test model 1 on task 9
Test: [3/3]	loss 0.221 (0.240)	Acc@1 93.529 (92.770)
Test model 1 on task 10
Test: [3/3]	loss 0.262 (0.249)	Acc@1 91.040 (92.220)
Test model 1 on task 11
Test: [3/3]	loss 0.264 (0.254)	Acc@1 92.367 (92.190)
Test model 1 on task 12
Test: [3/3]	loss 0.254 (0.254)	Acc@1 93.031 (92.460)
Test model 1 on task 13
Test: [3/3]	loss 0.234 (0.264)	Acc@1 93.473 (92.340)
Test model 1 on task 14
Test: [3/3]	loss 0.291 (0.293)	Acc@1 90.708 (91.040)
Test model 1 on task 15
Test: [3/3]	loss 0.299 (0.293)	Acc@1 90.763 (91.220)
Test model 1 on task 16
Test: [3/3]	loss 0.312 (0.326)	Acc@1 90.597 (90.210)
Test model 1 on task 17
Test: [3/3]	loss 0.310 (0.306)	Acc@1 90.542 (90.910)
Test model 1 on task 18
Test: [3/3]	loss 0.319 (0.326)	Acc@1 90.763 (90.620)
Test model 1 on task 19
Test: [3/3]	loss 0.356 (0.364)	Acc@1 89.657 (88.820)
Test model 1 on task 20
Test: [3/3]	loss 0.380 (0.384)	Acc@1 88.385 (88.740)
Test model 1 on task 21
Test: [3/3]	loss 0.368 (0.400)	Acc@1 89.215 (88.130)
Test model 1 on task 22
Test: [3/3]	loss 0.446 (0.458)	Acc@1 86.062 (86.410)
Test model 1 on task 23
Test: [3/3]	loss 0.454 (0.448)	Acc@1 86.836 (86.910)
Test model 1 on task 24
Test: [3/3]	loss 0.476 (0.491)	Acc@1 85.564 (84.890)
Test model 1 on task 25
Test: [3/3]	loss 0.512 (0.501)	Acc@1 84.679 (85.160)
Test model 1 on task 26
Test: [3/3]	loss 0.548 (0.539)	Acc@1 83.241 (83.540)
Test model 1 on task 27
Test: [3/3]	loss 0.548 (0.541)	Acc@1 83.628 (83.390)
Test model 1 on task 28
Test: [3/3]	loss 0.614 (0.622)	Acc@1 80.586 (80.290)
Test model 1 on task 29
Test: [3/3]	loss 0.637 (0.603)	Acc@1 79.923 (81.290)
Test model 1 on task 30
Test: [3/3]	loss 0.686 (0.690)	Acc@1 77.821 (77.830)
Test model 1 on task 31
Test: [3/3]	loss 0.736 (0.704)	Acc@1 77.378 (78.270)
Test model 1 on task 32
Test: [3/3]	loss 0.766 (0.754)	Acc@1 76.659 (75.990)
Test model 1 on task 33
Test: [3/3]	loss 0.808 (0.807)	Acc@1 75.277 (74.280)
Test model 1 on task 34
Test: [3/3]	loss 0.847 (0.848)	Acc@1 72.566 (72.970)
Test model 1 on task 35
Test: [3/3]	loss 0.927 (0.932)	Acc@1 69.967 (69.730)
############################################################ Avg acc: 86.88
Task 36 Model 1:
0 ['0.964', '3.823']
100 ['1.283', '1.994']
200 ['1.349', '1.422']
300 ['1.392', '1.280']
400 ['1.426', '0.755']
500 ['1.445', '1.040']
600 ['1.475', '0.970']
700 ['1.485', '0.742']
800 ['1.504', '1.033']
900 ['1.519', '1.310']
1000 ['1.521', '1.114']
1100 ['1.528', '1.091']
1200 ['1.536', '0.792']
1300 ['1.544', '1.206']
1400 ['1.544', '1.052']
1500 ['1.550', '1.463']
1600 ['1.560', '1.186']
1700 ['1.550', '1.047']
1800 ['1.551', '1.067']
1900 ['1.562', '0.995']
2000 ['1.571', '1.027']
2100 ['1.558', '0.840']
2200 ['1.553', '1.035']
2300 ['1.556', '1.331']
2400 ['1.561', '0.497']
2500 ['1.571', '1.048']
2600 ['1.565', '1.488']
2700 ['1.562', '0.469']
2800 ['1.561', '1.365']
2900 ['1.573', '0.889']
3000 ['1.579', '1.010']
3100 ['1.574', '0.972']
3200 ['1.564', '1.550']
3300 ['1.572', '0.971']
3400 ['1.576', '1.217']
3500 ['1.574', '1.007']
3600 ['1.591', '0.694']
3700 ['1.585', '0.874']
Train: [1][3750/3750]	loss 0.077 (0.075)	Acc@1 56.250 (61.968)
0 ['1.589', '1.131']
100 ['1.577', '1.439']
200 ['1.578', '0.861']
300 ['1.580', '0.945']
400 ['1.579', '0.850']
500 ['1.584', '0.803']
600 ['1.590', '0.826']
700 ['1.595', '1.291']
800 ['1.595', '0.920']
900 ['1.587', '0.939']
1000 ['1.586', '0.748']
1100 ['1.589', '1.187']
1200 ['1.574', '1.212']
1300 ['1.581', '1.696']
1400 ['1.577', '1.104']
1500 ['1.586', '1.237']
1600 ['1.587', '0.618']
1700 ['1.589', '1.278']
1800 ['1.590', '0.930']
1900 ['1.586', '0.924']
2000 ['1.583', '1.275']
2100 ['1.583', '1.172']
2200 ['1.596', '0.757']
2300 ['1.595', '1.158']
2400 ['1.603', '0.947']
2500 ['1.597', '1.028']
2600 ['1.593', '1.279']
2700 ['1.592', '0.682']
2800 ['1.591', '1.174']
2900 ['1.584', '1.111']
3000 ['1.587', '0.949']
3100 ['1.592', '0.940']
3200 ['1.600', '0.731']
3300 ['1.589', '0.651']
3400 ['1.594', '0.716']
3500 ['1.584', '1.302']
3600 ['1.587', '1.124']
3700 ['1.588', '1.506']
Train: [2][3750/3750]	loss 0.066 (0.072)	Acc@1 75.000 (67.355)
0 ['1.594', '1.428']
100 ['1.590', '0.709']
200 ['1.588', '0.994']
300 ['1.589', '1.207']
400 ['1.594', '1.741']
500 ['1.599', '1.298']
600 ['1.583', '1.011']
700 ['1.603', '1.262']
800 ['1.589', '1.451']
900 ['1.603', '0.643']
1000 ['1.600', '1.210']
1100 ['1.596', '1.033']
1200 ['1.603', '1.156']
1300 ['1.586', '1.071']
1400 ['1.586', '1.214']
1500 ['1.591', '1.040']
1600 ['1.583', '1.137']
1700 ['1.588', '1.197']
1800 ['1.593', '1.608']
1900 ['1.582', '0.979']
2000 ['1.590', '0.712']
2100 ['1.591', '0.719']
2200 ['1.592', '0.928']
2300 ['1.584', '1.287']
2400 ['1.589', '0.839']
2500 ['1.592', '0.898']
2600 ['1.581', '0.708']
2700 ['1.591', '0.649']
2800 ['1.596', '1.013']
2900 ['1.589', '0.718']
3000 ['1.593', '1.264']
3100 ['1.599', '0.823']
3200 ['1.603', '1.507']
3300 ['1.604', '0.876']
3400 ['1.605', '0.780']
3500 ['1.610', '0.741']
3600 ['1.599', '0.718']
3700 ['1.601', '0.889']
Train: [3][3750/3750]	loss 0.083 (0.072)	Acc@1 43.750 (67.747)
0 ['1.598', '1.051']
100 ['1.598', '1.049']
200 ['1.597', '1.033']
300 ['1.597', '1.037']
400 ['1.592', '0.880']
500 ['1.594', '1.512']
600 ['1.595', '1.195']
700 ['1.593', '0.936']
800 ['1.592', '1.011']
900 ['1.588', '1.226']
1000 ['1.605', '0.611']
1100 ['1.594', '0.611']
1200 ['1.599', '1.136']
1300 ['1.599', '1.114']
1400 ['1.595', '0.896']
1500 ['1.597', '1.334']
1600 ['1.588', '1.212']
1700 ['1.591', '1.344']
1800 ['1.595', '1.096']
1900 ['1.590', '0.809']
2000 ['1.586', '0.889']
2100 ['1.587', '1.348']
2200 ['1.593', '0.531']
2300 ['1.590', '0.946']
2400 ['1.595', '0.764']
2500 ['1.594', '0.671']
2600 ['1.601', '0.826']
2700 ['1.598', '1.001']
2800 ['1.602', '0.769']
2900 ['1.590', '1.289']
3000 ['1.599', '1.037']
3100 ['1.604', '0.978']
3200 ['1.587', '0.834']
3300 ['1.592', '0.743']
3400 ['1.593', '0.917']
3500 ['1.586', '1.165']
3600 ['1.591', '0.735']
3700 ['1.596', '0.931']
Train: [4][3750/3750]	loss 0.070 (0.072)	Acc@1 68.750 (67.908)
0 ['1.600', '0.891']
100 ['1.605', '1.205']
200 ['1.597', '1.697']
300 ['1.596', '0.609']
400 ['1.591', '0.545']
500 ['1.602', '0.821']
600 ['1.602', '0.731']
700 ['1.596', '1.355']
800 ['1.595', '0.907']
900 ['1.598', '0.846']
1000 ['1.598', '1.174']
1100 ['1.595', '1.119']
1200 ['1.600', '0.918']
1300 ['1.587', '1.168']
1400 ['1.600', '1.072']
1500 ['1.598', '0.822']
1600 ['1.589', '0.968']
1700 ['1.594', '0.805']
1800 ['1.589', '1.136']
1900 ['1.600', '0.844']
2000 ['1.597', '0.890']
2100 ['1.593', '1.078']
2200 ['1.588', '0.774']
2300 ['1.587', '0.927']
2400 ['1.598', '0.898']
2500 ['1.597', '1.047']
2600 ['1.596', '1.372']
2700 ['1.591', '1.009']
2800 ['1.590', '0.970']
2900 ['1.592', '1.499']
3000 ['1.593', '0.762']
3100 ['1.607', '1.049']
3200 ['1.598', '1.203']
3300 ['1.599', '1.173']
3400 ['1.596', '1.126']
3500 ['1.593', '1.787']
3600 ['1.606', '0.729']
3700 ['1.607', '0.671']
Train: [5][3750/3750]	loss 0.075 (0.072)	Acc@1 62.500 (67.932)
Test model 1 on task 1
Test: [3/3]	loss 0.323 (0.318)	Acc@1 89.768 (89.490)
Test model 1 on task 2
Test: [3/3]	loss 0.255 (0.244)	Acc@1 91.316 (91.930)
Test model 1 on task 3
Test: [3/3]	loss 0.219 (0.222)	Acc@1 93.031 (92.860)
Test model 1 on task 4
Test: [3/3]	loss 0.269 (0.239)	Acc@1 90.708 (92.010)
Test model 1 on task 5
Test: [3/3]	loss 0.195 (0.226)	Acc@1 94.469 (93.080)
Test model 1 on task 6
Test: [3/3]	loss 0.254 (0.225)	Acc@1 91.980 (93.010)
Test model 1 on task 7
Test: [3/3]	loss 0.241 (0.228)	Acc@1 92.478 (93.020)
Test model 1 on task 8
Test: [3/3]	loss 0.256 (0.237)	Acc@1 91.759 (92.540)
Test model 1 on task 9
Test: [3/3]	loss 0.247 (0.243)	Acc@1 92.533 (92.730)
Test model 1 on task 10
Test: [3/3]	loss 0.240 (0.250)	Acc@1 92.257 (92.270)
Test model 1 on task 11
Test: [3/3]	loss 0.244 (0.254)	Acc@1 92.588 (92.240)
Test model 1 on task 12
Test: [3/3]	loss 0.270 (0.256)	Acc@1 92.035 (92.330)
Test model 1 on task 13
Test: [3/3]	loss 0.266 (0.266)	Acc@1 92.035 (92.130)
Test model 1 on task 14
Test: [3/3]	loss 0.289 (0.294)	Acc@1 91.704 (91.150)
Test model 1 on task 15
Test: [3/3]	loss 0.309 (0.295)	Acc@1 90.653 (91.160)
Test model 1 on task 16
Test: [3/3]	loss 0.358 (0.327)	Acc@1 89.159 (90.170)
Test model 1 on task 17
Test: [3/3]	loss 0.300 (0.308)	Acc@1 90.985 (90.740)
Test model 1 on task 18
Test: [3/3]	loss 0.323 (0.328)	Acc@1 90.653 (90.400)
Test model 1 on task 19
Test: [3/3]	loss 0.374 (0.366)	Acc@1 89.381 (88.750)
Test model 1 on task 20
Test: [3/3]	loss 0.387 (0.387)	Acc@1 88.330 (88.640)
Test model 1 on task 21
Test: [3/3]	loss 0.375 (0.402)	Acc@1 89.159 (88.130)
Test model 1 on task 22
Test: [3/3]	loss 0.451 (0.461)	Acc@1 87.223 (86.420)
Test model 1 on task 23
Test: [3/3]	loss 0.448 (0.450)	Acc@1 86.449 (86.730)
Test model 1 on task 24
Test: [3/3]	loss 0.455 (0.491)	Acc@1 85.841 (84.840)
Test model 1 on task 25
Test: [3/3]	loss 0.497 (0.504)	Acc@1 85.122 (85.070)
Test model 1 on task 26
Test: [3/3]	loss 0.553 (0.541)	Acc@1 83.518 (83.510)
Test model 1 on task 27
Test: [3/3]	loss 0.585 (0.541)	Acc@1 81.416 (83.260)
Test model 1 on task 28
Test: [3/3]	loss 0.654 (0.625)	Acc@1 79.148 (80.350)
Test model 1 on task 29
Test: [3/3]	loss 0.587 (0.604)	Acc@1 82.522 (81.260)
Test model 1 on task 30
Test: [3/3]	loss 0.683 (0.686)	Acc@1 78.097 (77.880)
Test model 1 on task 31
Test: [3/3]	loss 0.691 (0.708)	Acc@1 78.816 (78.000)
Test model 1 on task 32
Test: [3/3]	loss 0.746 (0.754)	Acc@1 75.774 (76.140)
Test model 1 on task 33
Test: [3/3]	loss 0.810 (0.809)	Acc@1 74.226 (74.280)
Test model 1 on task 34
Test: [3/3]	loss 0.834 (0.853)	Acc@1 72.677 (72.520)
Test model 1 on task 35
Test: [3/3]	loss 0.969 (0.932)	Acc@1 68.861 (69.870)
Test model 1 on task 36
Test: [3/3]	loss 0.903 (0.944)	Acc@1 70.852 (69.770)
############################################################ Avg acc: 86.35
Task 37 Model 1:
0 ['0.986', '3.528']
100 ['1.271', '1.592']
200 ['1.325', '1.711']
300 ['1.376', '1.371']
400 ['1.409', '1.812']
500 ['1.445', '1.123']
600 ['1.453', '1.634']
700 ['1.467', '0.966']
800 ['1.483', '0.954']
900 ['1.501', '1.061']
1000 ['1.506', '1.013']
1100 ['1.525', '1.206']
1200 ['1.532', '1.029']
1300 ['1.523', '0.772']
1400 ['1.539', '1.175']
1500 ['1.540', '1.563']
1600 ['1.522', '1.270']
1700 ['1.555', '1.504']
1800 ['1.550', '1.274']
1900 ['1.545', '0.913']
2000 ['1.550', '0.909']
2100 ['1.541', '1.179']
2200 ['1.550', '1.241']
2300 ['1.555', '1.322']
2400 ['1.552', '1.751']
2500 ['1.554', '1.436']
2600 ['1.564', '0.802']
2700 ['1.567', '0.743']
2800 ['1.559', '0.885']
2900 ['1.547', '0.896']
3000 ['1.553', '1.122']
3100 ['1.555', '1.040']
3200 ['1.568', '1.084']
3300 ['1.572', '1.185']
3400 ['1.576', '0.814']
3500 ['1.565', '0.744']
3600 ['1.569', '0.731']
3700 ['1.571', '0.582']
Train: [1][3750/3750]	loss 0.074 (0.073)	Acc@1 43.750 (60.068)
0 ['1.563', '1.463']
100 ['1.569', '1.181']
200 ['1.577', '1.518']
300 ['1.578', '0.949']
400 ['1.583', '1.488']
500 ['1.587', '0.860']
600 ['1.573', '1.000']
700 ['1.574', '0.996']
800 ['1.586', '1.369']
900 ['1.582', '0.833']
1000 ['1.570', '0.620']
1100 ['1.566', '1.272']
1200 ['1.590', '0.992']
1300 ['1.580', '1.068']
1400 ['1.577', '1.079']
1500 ['1.586', '1.180']
1600 ['1.567', '1.192']
1700 ['1.576', '1.380']
1800 ['1.563', '0.856']
1900 ['1.577', '1.297']
2000 ['1.587', '0.961']
2100 ['1.578', '1.155']
2200 ['1.585', '1.340']
2300 ['1.570', '0.864']
2400 ['1.569', '0.752']
2500 ['1.568', '1.486']
2600 ['1.570', '0.971']
2700 ['1.577', '1.055']
2800 ['1.579', '0.866']
2900 ['1.569', '0.725']
3000 ['1.573', '1.348']
3100 ['1.585', '0.783']
3200 ['1.578', '0.853']
3300 ['1.592', '0.774']
3400 ['1.582', '0.673']
3500 ['1.572', '0.909']
3600 ['1.578', '1.086']
3700 ['1.577', '1.075']
Train: [2][3750/3750]	loss 0.063 (0.071)	Acc@1 75.000 (64.970)
0 ['1.575', '1.362']
100 ['1.571', '1.055']
200 ['1.571', '0.973']
300 ['1.576', '0.904']
400 ['1.582', '0.801']
500 ['1.576', '0.734']
600 ['1.582', '1.163']
700 ['1.574', '1.075']
800 ['1.581', '0.962']
900 ['1.583', '1.094']
1000 ['1.579', '0.970']
1100 ['1.572', '0.902']
1200 ['1.567', '1.189']
1300 ['1.576', '1.228']
1400 ['1.581', '0.809']
1500 ['1.585', '1.270']
1600 ['1.587', '1.718']
1700 ['1.584', '1.197']
1800 ['1.582', '0.658']
1900 ['1.586', '0.946']
2000 ['1.582', '0.935']
2100 ['1.588', '1.293']
2200 ['1.575', '0.821']
2300 ['1.585', '0.937']
2400 ['1.588', '1.186']
2500 ['1.584', '0.617']
2600 ['1.584', '1.351']
2700 ['1.586', '1.069']
2800 ['1.578', '1.052']
2900 ['1.583', '0.777']
3000 ['1.574', '0.854']
3100 ['1.577', '0.998']
3200 ['1.584', '0.658']
3300 ['1.581', '1.133']
3400 ['1.578', '1.066']
3500 ['1.576', '0.889']
3600 ['1.575', '1.563']
3700 ['1.576', '1.343']
Train: [3][3750/3750]	loss 0.064 (0.071)	Acc@1 68.750 (65.315)
0 ['1.578', '0.921']
100 ['1.579', '0.853']
200 ['1.579', '0.736']
300 ['1.592', '0.801']
400 ['1.589', '1.187']
500 ['1.580', '0.889']
600 ['1.576', '0.839']
700 ['1.584', '1.200']
800 ['1.582', '1.127']
900 ['1.586', '1.376']
1000 ['1.583', '1.092']
1100 ['1.581', '1.337']
1200 ['1.582', '0.782']
1300 ['1.578', '0.861']
1400 ['1.580', '0.988']
1500 ['1.588', '0.904']
1600 ['1.571', '1.348']
1700 ['1.592', '1.099']
1800 ['1.579', '0.824']
1900 ['1.590', '1.030']
2000 ['1.579', '0.919']
2100 ['1.590', '1.257']
2200 ['1.582', '1.307']
2300 ['1.578', '1.357']
2400 ['1.580', '1.333']
2500 ['1.575', '1.033']
2600 ['1.577', '0.655']
2700 ['1.575', '1.309']
2800 ['1.580', '0.848']
2900 ['1.569', '1.061']
3000 ['1.573', '1.011']
3100 ['1.567', '1.169']
3200 ['1.574', '1.057']
3300 ['1.579', '1.491']
3400 ['1.581', '1.557']
3500 ['1.578', '0.913']
3600 ['1.587', '0.806']
3700 ['1.593', '0.938']
Train: [4][3750/3750]	loss 0.065 (0.071)	Acc@1 81.250 (65.392)
0 ['1.583', '1.621']
100 ['1.578', '1.113']
200 ['1.595', '1.333']
300 ['1.581', '1.000']
400 ['1.588', '1.080']
500 ['1.583', '1.450']
600 ['1.575', '0.958']
700 ['1.580', '0.931']
800 ['1.584', '0.640']
900 ['1.587', '0.851']
1000 ['1.586', '1.200']
1100 ['1.576', '0.689']
1200 ['1.578', '1.131']
1300 ['1.590', '0.571']
1400 ['1.590', '1.061']
1500 ['1.579', '0.750']
1600 ['1.575', '1.023']
1700 ['1.582', '0.602']
1800 ['1.573', '1.166']
1900 ['1.582', '1.405']
2000 ['1.587', '1.332']
2100 ['1.575', '1.232']
2200 ['1.588', '1.082']
2300 ['1.583', '0.823']
2400 ['1.570', '0.748']
2500 ['1.585', '0.690']
2600 ['1.583', '1.139']
2700 ['1.588', '1.094']
2800 ['1.586', '0.689']
2900 ['1.580', '0.872']
3000 ['1.577', '0.614']
3100 ['1.580', '0.634']
3200 ['1.576', '1.036']
3300 ['1.577', '0.701']
3400 ['1.582', '1.129']
3500 ['1.582', '1.486']
3600 ['1.582', '0.838']
3700 ['1.574', '0.737']
Train: [5][3750/3750]	loss 0.075 (0.071)	Acc@1 56.250 (65.352)
Test model 1 on task 1
Test: [3/3]	loss 0.298 (0.319)	Acc@1 90.819 (89.480)
Test model 1 on task 2
Test: [3/3]	loss 0.263 (0.246)	Acc@1 91.648 (91.830)
Test model 1 on task 3
Test: [3/3]	loss 0.202 (0.223)	Acc@1 93.584 (92.860)
Test model 1 on task 4
Test: [3/3]	loss 0.227 (0.239)	Acc@1 92.146 (92.100)
Test model 1 on task 5
Test: [3/3]	loss 0.222 (0.227)	Acc@1 93.308 (93.100)
Test model 1 on task 6
Test: [3/3]	loss 0.256 (0.226)	Acc@1 91.704 (92.960)
Test model 1 on task 7
Test: [3/3]	loss 0.233 (0.230)	Acc@1 92.920 (92.900)
Test model 1 on task 8
Test: [3/3]	loss 0.238 (0.237)	Acc@1 92.367 (92.450)
Test model 1 on task 9
Test: [3/3]	loss 0.246 (0.244)	Acc@1 92.588 (92.780)
Test model 1 on task 10
Test: [3/3]	loss 0.251 (0.250)	Acc@1 92.146 (92.160)
Test model 1 on task 11
Test: [3/3]	loss 0.269 (0.255)	Acc@1 91.704 (92.240)
Test model 1 on task 12
Test: [3/3]	loss 0.234 (0.257)	Acc@1 93.473 (92.210)
Test model 1 on task 13
Test: [3/3]	loss 0.257 (0.265)	Acc@1 92.699 (92.100)
Test model 1 on task 14
Test: [3/3]	loss 0.306 (0.295)	Acc@1 90.321 (91.010)
Test model 1 on task 15
Test: [3/3]	loss 0.311 (0.297)	Acc@1 91.040 (91.130)
Test model 1 on task 16
Test: [3/3]	loss 0.329 (0.328)	Acc@1 89.657 (90.130)
Test model 1 on task 17
Test: [3/3]	loss 0.310 (0.309)	Acc@1 90.708 (90.740)
Test model 1 on task 18
Test: [3/3]	loss 0.329 (0.329)	Acc@1 90.100 (90.380)
Test model 1 on task 19
Test: [3/3]	loss 0.365 (0.369)	Acc@1 88.772 (88.560)
Test model 1 on task 20
Test: [3/3]	loss 0.402 (0.387)	Acc@1 87.721 (88.660)
Test model 1 on task 21
Test: [3/3]	loss 0.400 (0.404)	Acc@1 88.385 (88.110)
Test model 1 on task 22
Test: [3/3]	loss 0.453 (0.463)	Acc@1 86.781 (86.300)
Test model 1 on task 23
Test: [3/3]	loss 0.454 (0.452)	Acc@1 86.228 (86.590)
Test model 1 on task 24
Test: [3/3]	loss 0.521 (0.493)	Acc@1 83.407 (84.730)
Test model 1 on task 25
Test: [3/3]	loss 0.531 (0.506)	Acc@1 82.688 (84.900)
Test model 1 on task 26
Test: [3/3]	loss 0.539 (0.541)	Acc@1 83.462 (83.490)
Test model 1 on task 27
Test: [3/3]	loss 0.552 (0.545)	Acc@1 82.965 (83.080)
Test model 1 on task 28
Test: [3/3]	loss 0.589 (0.627)	Acc@1 81.748 (80.260)
Test model 1 on task 29
Test: [3/3]	loss 0.602 (0.608)	Acc@1 82.080 (81.020)
Test model 1 on task 30
Test: [3/3]	loss 0.690 (0.689)	Acc@1 77.489 (77.960)
Test model 1 on task 31
Test: [3/3]	loss 0.719 (0.710)	Acc@1 77.710 (77.890)
Test model 1 on task 32
Test: [3/3]	loss 0.800 (0.756)	Acc@1 73.451 (76.030)
Test model 1 on task 33
Test: [3/3]	loss 0.853 (0.806)	Acc@1 73.064 (74.270)
Test model 1 on task 34
Test: [3/3]	loss 0.827 (0.855)	Acc@1 73.230 (72.660)
Test model 1 on task 35
Test: [3/3]	loss 0.898 (0.935)	Acc@1 70.907 (69.690)
Test model 1 on task 36
Test: [3/3]	loss 0.941 (0.945)	Acc@1 69.248 (69.710)
Test model 1 on task 37
Test: [3/3]	loss 0.982 (0.987)	Acc@1 67.257 (66.880)
############################################################ Avg acc: 85.77
Task 38 Model 1:
0 ['1.036', '3.869']
100 ['1.346', '1.841']
200 ['1.429', '1.681']
300 ['1.453', '2.142']
400 ['1.472', '1.406']
500 ['1.500', '1.227']
600 ['1.513', '1.120']
700 ['1.528', '1.522']
800 ['1.545', '1.050']
900 ['1.554', '1.086']
1000 ['1.562', '0.824']
1100 ['1.570', '0.941']
1200 ['1.576', '1.530']
1300 ['1.591', '0.754']
1400 ['1.591', '0.691']
1500 ['1.592', '1.456']
1600 ['1.597', '1.459']
1700 ['1.601', '1.082']
1800 ['1.590', '1.263']
1900 ['1.604', '1.278']
2000 ['1.592', '1.156']
2100 ['1.619', '1.248']
2200 ['1.622', '0.902']
2300 ['1.614', '1.460']
2400 ['1.612', '1.254']
2500 ['1.613', '1.131']
2600 ['1.620', '0.861']
2700 ['1.614', '1.064']
2800 ['1.617', '2.011']
2900 ['1.622', '1.256']
3000 ['1.622', '1.376']
3100 ['1.624', '1.285']
3200 ['1.633', '1.485']
3300 ['1.631', '0.857']
3400 ['1.625', '0.735']
3500 ['1.639', '0.770']
3600 ['1.624', '1.071']
3700 ['1.631', '1.078']
Train: [1][3750/3750]	loss 0.073 (0.073)	Acc@1 56.250 (59.648)
0 ['1.631', '1.201']
100 ['1.631', '1.072']
200 ['1.629', '0.746']
300 ['1.633', '0.834']
400 ['1.637', '1.186']
500 ['1.635', '0.934']
600 ['1.644', '1.415']
700 ['1.639', '0.971']
800 ['1.631', '1.100']
900 ['1.632', '1.575']
1000 ['1.632', '0.857']
1100 ['1.652', '1.658']
1200 ['1.630', '1.313']
1300 ['1.636', '0.793']
1400 ['1.642', '1.107']
1500 ['1.648', '1.422']
1600 ['1.648', '1.082']
1700 ['1.649', '0.681']
1800 ['1.637', '1.200']
1900 ['1.636', '0.776']
2000 ['1.640', '0.968']
2100 ['1.642', '1.086']
2200 ['1.637', '0.960']
2300 ['1.642', '1.125']
2400 ['1.637', '1.042']
2500 ['1.631', '1.298']
2600 ['1.628', '0.627']
2700 ['1.642', '0.771']
2800 ['1.637', '0.887']
2900 ['1.635', '0.962']
3000 ['1.625', '0.624']
3100 ['1.626', '0.703']
3200 ['1.632', '1.283']
3300 ['1.633', '0.831']
3400 ['1.639', '1.298']
3500 ['1.630', '1.244']
3600 ['1.643', '1.060']
3700 ['1.629', '1.000']
Train: [2][3750/3750]	loss 0.060 (0.071)	Acc@1 87.500 (65.413)
0 ['1.639', '1.121']
100 ['1.634', '0.945']
200 ['1.643', '0.828']
300 ['1.638', '0.809']
400 ['1.633', '0.956']
500 ['1.620', '0.934']
600 ['1.629', '0.802']
700 ['1.631', '1.139']
800 ['1.637', '1.125']
900 ['1.635', '1.840']
1000 ['1.640', '1.457']
1100 ['1.633', '0.895']
1200 ['1.630', '0.965']
1300 ['1.624', '1.338']
1400 ['1.634', '0.604']
1500 ['1.629', '1.069']
1600 ['1.630', '1.190']
1700 ['1.636', '0.927']
1800 ['1.641', '1.456']
1900 ['1.624', '1.191']
2000 ['1.630', '1.150']
2100 ['1.638', '0.589']
2200 ['1.631', '0.807']
2300 ['1.639', '0.573']
2400 ['1.644', '0.556']
2500 ['1.634', '1.247']
2600 ['1.634', '1.387']
2700 ['1.634', '0.939']
2800 ['1.627', '1.650']
2900 ['1.634', '1.364']
3000 ['1.628', '0.745']
3100 ['1.633', '1.419']
3200 ['1.622', '0.826']
3300 ['1.629', '0.931']
3400 ['1.632', '1.285']
3500 ['1.639', '0.859']
3600 ['1.643', '0.916']
3700 ['1.646', '1.485']
Train: [3][3750/3750]	loss 0.068 (0.070)	Acc@1 81.250 (66.340)
0 ['1.634', '0.826']
100 ['1.641', '0.853']
200 ['1.644', '0.986']
300 ['1.634', '1.085']
400 ['1.623', '1.348']
500 ['1.637', '0.896']
600 ['1.623', '1.622']
700 ['1.637', '0.861']
800 ['1.643', '1.204']
900 ['1.646', '1.086']
1000 ['1.648', '0.797']
1100 ['1.662', '0.991']
1200 ['1.648', '0.652']
1300 ['1.650', '0.410']
1400 ['1.637', '1.135']
1500 ['1.632', '0.705']
1600 ['1.636', '0.665']
1700 ['1.641', '0.773']
1800 ['1.649', '0.720']
1900 ['1.633', '1.070']
2000 ['1.639', '1.145']
2100 ['1.645', '1.043']
2200 ['1.641', '1.025']
2300 ['1.623', '0.732']
2400 ['1.633', '1.191']
2500 ['1.636', '1.166']
2600 ['1.636', '0.818']
2700 ['1.638', '0.804']
2800 ['1.638', '1.276']
2900 ['1.630', '0.714']
3000 ['1.634', '0.959']
3100 ['1.636', '1.050']
3200 ['1.633', '0.694']
3300 ['1.641', '0.751']
3400 ['1.634', '0.737']
3500 ['1.633', '0.688']
3600 ['1.631', '1.023']
3700 ['1.631', '0.772']
Train: [4][3750/3750]	loss 0.071 (0.070)	Acc@1 56.250 (66.670)
0 ['1.645', '1.042']
100 ['1.638', '1.225']
200 ['1.637', '1.812']
300 ['1.647', '0.585']
400 ['1.645', '1.009']
500 ['1.635', '1.048']
600 ['1.633', '0.743']
700 ['1.635', '1.271']
800 ['1.643', '0.748']
900 ['1.637', '1.053']
1000 ['1.636', '1.222']
1100 ['1.655', '0.632']
1200 ['1.644', '0.896']
1300 ['1.630', '1.450']
1400 ['1.639', '0.704']
1500 ['1.641', '1.060']
1600 ['1.640', '0.832']
1700 ['1.626', '0.771']
1800 ['1.636', '0.893']
1900 ['1.639', '0.973']
2000 ['1.647', '0.922']
2100 ['1.642', '0.978']
2200 ['1.650', '0.594']
2300 ['1.650', '1.168']
2400 ['1.642', '0.648']
2500 ['1.640', '0.864']
2600 ['1.633', '0.996']
2700 ['1.639', '1.371']
2800 ['1.637', '1.289']
2900 ['1.636', '0.879']
3000 ['1.632', '1.265']
3100 ['1.636', '1.262']
3200 ['1.633', '0.760']
3300 ['1.633', '1.557']
3400 ['1.644', '0.801']
3500 ['1.623', '1.247']
3600 ['1.647', '0.792']
3700 ['1.637', '1.050']
Train: [5][3750/3750]	loss 0.061 (0.070)	Acc@1 81.250 (66.878)
Test model 1 on task 1
Test: [3/3]	loss 0.311 (0.319)	Acc@1 89.602 (89.400)
Test model 1 on task 2
Test: [3/3]	loss 0.230 (0.245)	Acc@1 92.533 (91.890)
Test model 1 on task 3
Test: [3/3]	loss 0.226 (0.224)	Acc@1 93.197 (92.760)
Test model 1 on task 4
Test: [3/3]	loss 0.230 (0.240)	Acc@1 92.367 (92.010)
Test model 1 on task 5
Test: [3/3]	loss 0.240 (0.228)	Acc@1 92.478 (93.070)
Test model 1 on task 6
Test: [3/3]	loss 0.226 (0.227)	Acc@1 92.754 (92.830)
Test model 1 on task 7
Test: [3/3]	loss 0.212 (0.233)	Acc@1 93.252 (92.920)
Test model 1 on task 8
Test: [3/3]	loss 0.241 (0.238)	Acc@1 92.035 (92.430)
Test model 1 on task 9
Test: [3/3]	loss 0.251 (0.245)	Acc@1 92.257 (92.680)
Test model 1 on task 10
Test: [3/3]	loss 0.254 (0.250)	Acc@1 92.035 (92.200)
Test model 1 on task 11
Test: [3/3]	loss 0.229 (0.256)	Acc@1 93.363 (92.150)
Test model 1 on task 12
Test: [3/3]	loss 0.248 (0.258)	Acc@1 92.644 (92.230)
Test model 1 on task 13
Test: [3/3]	loss 0.266 (0.268)	Acc@1 91.814 (91.910)
Test model 1 on task 14
Test: [3/3]	loss 0.290 (0.298)	Acc@1 91.095 (90.870)
Test model 1 on task 15
Test: [3/3]	loss 0.301 (0.298)	Acc@1 91.040 (91.110)
Test model 1 on task 16
Test: [3/3]	loss 0.302 (0.332)	Acc@1 91.261 (89.980)
Test model 1 on task 17
Test: [3/3]	loss 0.342 (0.310)	Acc@1 89.712 (90.660)
Test model 1 on task 18
Test: [3/3]	loss 0.320 (0.330)	Acc@1 90.542 (90.350)
Test model 1 on task 19
Test: [3/3]	loss 0.363 (0.370)	Acc@1 89.159 (88.520)
Test model 1 on task 20
Test: [3/3]	loss 0.427 (0.388)	Acc@1 87.887 (88.630)
Test model 1 on task 21
Test: [3/3]	loss 0.431 (0.404)	Acc@1 86.892 (88.010)
Test model 1 on task 22
Test: [3/3]	loss 0.457 (0.464)	Acc@1 86.338 (86.070)
Test model 1 on task 23
Test: [3/3]	loss 0.480 (0.454)	Acc@1 85.896 (86.640)
Test model 1 on task 24
Test: [3/3]	loss 0.493 (0.496)	Acc@1 84.569 (84.640)
Test model 1 on task 25
Test: [3/3]	loss 0.486 (0.508)	Acc@1 86.228 (84.860)
Test model 1 on task 26
Test: [3/3]	loss 0.557 (0.543)	Acc@1 82.467 (83.520)
Test model 1 on task 27
Test: [3/3]	loss 0.542 (0.546)	Acc@1 83.518 (83.120)
Test model 1 on task 28
Test: [3/3]	loss 0.651 (0.626)	Acc@1 79.314 (80.380)
Test model 1 on task 29
Test: [3/3]	loss 0.626 (0.609)	Acc@1 80.199 (80.950)
Test model 1 on task 30
Test: [3/3]	loss 0.715 (0.691)	Acc@1 76.825 (77.720)
Test model 1 on task 31
Test: [3/3]	loss 0.706 (0.711)	Acc@1 78.153 (78.010)
Test model 1 on task 32
Test: [3/3]	loss 0.767 (0.755)	Acc@1 75.221 (76.000)
Test model 1 on task 33
Test: [3/3]	loss 0.810 (0.806)	Acc@1 74.945 (74.340)
Test model 1 on task 34
Test: [3/3]	loss 0.900 (0.859)	Acc@1 71.350 (72.320)
Test model 1 on task 35
Test: [3/3]	loss 0.965 (0.937)	Acc@1 68.861 (69.590)
Test model 1 on task 36
Test: [3/3]	loss 0.969 (0.948)	Acc@1 69.137 (69.560)
Test model 1 on task 37
Test: [3/3]	loss 0.965 (0.986)	Acc@1 67.146 (66.800)
Test model 1 on task 38
Test: [3/3]	loss 0.949 (0.970)	Acc@1 69.192 (68.220)
############################################################ Avg acc: 85.25
Task 39 Model 1:
0 ['1.012', '3.028']
100 ['1.307', '1.800']
200 ['1.368', '1.470']
300 ['1.411', '1.775']
400 ['1.451', '0.817']
500 ['1.475', '1.015']
600 ['1.471', '1.207']
700 ['1.490', '1.389']
800 ['1.487', '1.517']
900 ['1.494', '0.732']
1000 ['1.506', '1.297']
1100 ['1.508', '1.225']
1200 ['1.529', '1.140']
1300 ['1.515', '0.840']
1400 ['1.523', '1.217']
1500 ['1.530', '1.174']
1600 ['1.525', '1.316']
1700 ['1.535', '1.339']
1800 ['1.542', '1.318']
1900 ['1.535', '1.017']
2000 ['1.528', '1.167']
2100 ['1.542', '1.203']
2200 ['1.545', '1.435']
2300 ['1.542', '1.260']
2400 ['1.552', '0.851']
2500 ['1.555', '1.485']
2600 ['1.558', '0.737']
2700 ['1.551', '0.673']
2800 ['1.558', '0.728']
2900 ['1.560', '0.941']
3000 ['1.561', '1.421']
3100 ['1.566', '1.093']
3200 ['1.554', '1.079']
3300 ['1.563', '0.787']
3400 ['1.564', '0.871']
3500 ['1.558', '1.040']
3600 ['1.559', '1.116']
3700 ['1.567', '0.914']
Train: [1][3750/3750]	loss 0.065 (0.069)	Acc@1 75.000 (60.248)
0 ['1.572', '0.900']
100 ['1.562', '1.216']
200 ['1.565', '1.173']
300 ['1.560', '1.350']
400 ['1.564', '1.235']
500 ['1.571', '0.936']
600 ['1.575', '1.157']
700 ['1.565', '1.137']
800 ['1.559', '0.718']
900 ['1.581', '0.923']
1000 ['1.571', '1.080']
1100 ['1.570', '1.083']
1200 ['1.564', '1.187']
1300 ['1.565', '0.876']
1400 ['1.556', '1.641']
1500 ['1.563', '0.847']
1600 ['1.574', '1.143']
1700 ['1.552', '0.881']
1800 ['1.552', '1.368']
1900 ['1.566', '0.999']
2000 ['1.562', '1.551']
2100 ['1.563', '1.055']
2200 ['1.555', '0.891']
2300 ['1.557', '1.187']
2400 ['1.563', '1.399']
2500 ['1.558', '1.048']
2600 ['1.565', '1.053']
2700 ['1.565', '0.874']
2800 ['1.566', '1.041']
2900 ['1.568', '1.320']
3000 ['1.570', '0.822']
3100 ['1.581', '1.204']
3200 ['1.574', '0.909']
3300 ['1.574', '1.055']
3400 ['1.584', '0.792']
3500 ['1.579', '1.463']
3600 ['1.577', '1.099']
3700 ['1.573', '1.353']
Train: [2][3750/3750]	loss 0.060 (0.068)	Acc@1 75.000 (64.058)
0 ['1.566', '0.807']
100 ['1.563', '0.725']
200 ['1.574', '0.844']
300 ['1.569', '1.320']
400 ['1.563', '0.985']
500 ['1.565', '1.189']
600 ['1.578', '0.711']
700 ['1.579', '0.766']
800 ['1.573', '1.254']
900 ['1.576', '0.911']
1000 ['1.565', '0.607']
1100 ['1.559', '1.106']
1200 ['1.571', '1.033']
1300 ['1.575', '1.042']
1400 ['1.578', '1.055']
1500 ['1.574', '1.209']
1600 ['1.560', '1.309']
1700 ['1.567', '0.984']
1800 ['1.570', '0.757']
1900 ['1.564', '0.872']
2000 ['1.568', '1.293']
2100 ['1.585', '1.258']
2200 ['1.558', '1.108']
2300 ['1.567', '1.081']
2400 ['1.574', '1.157']
2500 ['1.574', '1.368']
2600 ['1.583', '0.642']
2700 ['1.565', '1.233']
2800 ['1.569', '1.278']
2900 ['1.563', '0.968']
3000 ['1.573', '0.721']
3100 ['1.572', '1.069']
3200 ['1.565', '0.686']
3300 ['1.562', '0.524']
3400 ['1.564', '1.011']
3500 ['1.565', '0.630']
3600 ['1.586', '1.026']
3700 ['1.568', '0.563']
Train: [3][3750/3750]	loss 0.064 (0.068)	Acc@1 62.500 (64.305)
0 ['1.567', '1.028']
100 ['1.561', '1.548']
200 ['1.570', '0.738']
300 ['1.565', '1.082']
400 ['1.569', '1.227']
500 ['1.576', '1.533']
600 ['1.573', '1.709']
700 ['1.572', '1.037']
800 ['1.569', '0.879']
900 ['1.586', '1.007']
1000 ['1.561', '1.055']
1100 ['1.560', '0.747']
1200 ['1.564', '1.061']
1300 ['1.568', '0.962']
1400 ['1.566', '0.860']
1500 ['1.586', '1.286']
1600 ['1.557', '1.507']
1700 ['1.567', '0.942']
1800 ['1.569', '1.185']
1900 ['1.577', '0.835']
2000 ['1.570', '0.808']
2100 ['1.562', '1.142']
2200 ['1.561', '0.779']
2300 ['1.572', '1.524']
2400 ['1.561', '0.592']
2500 ['1.562', '1.138']
2600 ['1.572', '0.889']
2700 ['1.574', '0.763']
2800 ['1.567', '0.993']
2900 ['1.564', '0.915']
3000 ['1.576', '1.128']
3100 ['1.582', '1.581']
3200 ['1.573', '1.322']
3300 ['1.568', '1.063']
3400 ['1.572', '0.895']
3500 ['1.570', '1.343']
3600 ['1.565', '0.794']
3700 ['1.569', '0.853']
Train: [4][3750/3750]	loss 0.073 (0.068)	Acc@1 50.000 (64.512)
0 ['1.574', '0.767']
100 ['1.568', '0.813']
200 ['1.568', '0.904']
300 ['1.574', '0.994']
400 ['1.570', '0.831']
500 ['1.568', '0.714']
600 ['1.565', '1.498']
700 ['1.566', '1.313']
800 ['1.571', '1.163']
900 ['1.556', '1.428']
1000 ['1.571', '0.836']
1100 ['1.583', '0.868']
1200 ['1.572', '0.844']
1300 ['1.587', '1.390']
1400 ['1.568', '1.072']
1500 ['1.568', '1.077']
1600 ['1.566', '1.645']
1700 ['1.566', '1.390']
1800 ['1.576', '1.181']
1900 ['1.581', '0.848']
2000 ['1.572', '1.106']
2100 ['1.572', '0.714']
2200 ['1.574', '1.247']
2300 ['1.560', '1.234']
2400 ['1.569', '0.500']
2500 ['1.561', '0.921']
2600 ['1.560', '0.899']
2700 ['1.561', '1.224']
2800 ['1.570', '0.913']
2900 ['1.571', '1.110']
3000 ['1.585', '1.310']
3100 ['1.566', '0.988']
3200 ['1.563', '0.937']
3300 ['1.570', '1.453']
3400 ['1.571', '1.530']
3500 ['1.576', '1.316']
3600 ['1.578', '0.940']
3700 ['1.563', '1.673']
Train: [5][3750/3750]	loss 0.081 (0.068)	Acc@1 31.250 (64.542)
Test model 1 on task 1
Test: [3/3]	loss 0.348 (0.320)	Acc@1 88.164 (89.450)
Test model 1 on task 2
Test: [3/3]	loss 0.260 (0.246)	Acc@1 91.206 (91.800)
Test model 1 on task 3
Test: [3/3]	loss 0.210 (0.225)	Acc@1 93.252 (92.730)
Test model 1 on task 4
Test: [3/3]	loss 0.254 (0.241)	Acc@1 91.704 (92.030)
Test model 1 on task 5
Test: [3/3]	loss 0.205 (0.227)	Acc@1 93.861 (93.140)
Test model 1 on task 6
Test: [3/3]	loss 0.240 (0.228)	Acc@1 91.759 (92.770)
Test model 1 on task 7
Test: [3/3]	loss 0.249 (0.235)	Acc@1 92.920 (92.830)
Test model 1 on task 8
Test: [3/3]	loss 0.242 (0.239)	Acc@1 91.759 (92.360)
Test model 1 on task 9
Test: [3/3]	loss 0.243 (0.246)	Acc@1 92.257 (92.620)
Test model 1 on task 10
Test: [3/3]	loss 0.232 (0.252)	Acc@1 93.197 (92.150)
Test model 1 on task 11
Test: [3/3]	loss 0.251 (0.258)	Acc@1 91.925 (92.120)
Test model 1 on task 12
Test: [3/3]	loss 0.249 (0.259)	Acc@1 92.976 (92.320)
Test model 1 on task 13
Test: [3/3]	loss 0.261 (0.269)	Acc@1 91.593 (91.870)
Test model 1 on task 14
Test: [3/3]	loss 0.308 (0.299)	Acc@1 91.206 (90.830)
Test model 1 on task 15
Test: [3/3]	loss 0.313 (0.299)	Acc@1 90.321 (91.070)
Test model 1 on task 16
Test: [3/3]	loss 0.353 (0.333)	Acc@1 89.989 (89.970)
Test model 1 on task 17
Test: [3/3]	loss 0.306 (0.312)	Acc@1 91.040 (90.610)
Test model 1 on task 18
Test: [3/3]	loss 0.339 (0.333)	Acc@1 89.878 (90.360)
Test model 1 on task 19
Test: [3/3]	loss 0.362 (0.372)	Acc@1 89.159 (88.490)
Test model 1 on task 20
Test: [3/3]	loss 0.368 (0.390)	Acc@1 89.491 (88.500)
Test model 1 on task 21
Test: [3/3]	loss 0.409 (0.405)	Acc@1 88.164 (88.080)
Test model 1 on task 22
Test: [3/3]	loss 0.470 (0.466)	Acc@1 85.951 (86.090)
Test model 1 on task 23
Test: [3/3]	loss 0.449 (0.458)	Acc@1 87.389 (86.550)
Test model 1 on task 24
Test: [3/3]	loss 0.496 (0.498)	Acc@1 85.122 (84.610)
Test model 1 on task 25
Test: [3/3]	loss 0.485 (0.509)	Acc@1 85.177 (84.950)
Test model 1 on task 26
Test: [3/3]	loss 0.535 (0.546)	Acc@1 83.518 (83.280)
Test model 1 on task 27
Test: [3/3]	loss 0.514 (0.547)	Acc@1 84.845 (83.200)
Test model 1 on task 28
Test: [3/3]	loss 0.625 (0.624)	Acc@1 80.365 (80.290)
Test model 1 on task 29
Test: [3/3]	loss 0.608 (0.609)	Acc@1 81.803 (81.020)
Test model 1 on task 30
Test: [3/3]	loss 0.680 (0.693)	Acc@1 77.710 (77.590)
Test model 1 on task 31
Test: [3/3]	loss 0.741 (0.710)	Acc@1 76.438 (77.920)
Test model 1 on task 32
Test: [3/3]	loss 0.758 (0.756)	Acc@1 76.715 (75.980)
Test model 1 on task 33
Test: [3/3]	loss 0.748 (0.806)	Acc@1 77.544 (74.310)
Test model 1 on task 34
Test: [3/3]	loss 0.859 (0.860)	Acc@1 71.737 (72.160)
Test model 1 on task 35
Test: [3/3]	loss 0.937 (0.938)	Acc@1 68.861 (69.450)
Test model 1 on task 36
Test: [3/3]	loss 0.958 (0.949)	Acc@1 69.580 (69.520)
Test model 1 on task 37
Test: [3/3]	loss 1.002 (0.984)	Acc@1 67.423 (66.980)
Test model 1 on task 38
Test: [3/3]	loss 0.991 (0.971)	Acc@1 67.754 (68.100)
Test model 1 on task 39
Test: [3/3]	loss 1.061 (1.053)	Acc@1 65.210 (64.940)
############################################################ Avg acc: 84.69
Task 40 Model 1:
0 ['1.075', '2.670']
100 ['1.393', '1.905']
200 ['1.500', '1.978']
300 ['1.564', '2.052']
400 ['1.603', '2.004']
500 ['1.656', '1.094']
600 ['1.661', '1.275']
700 ['1.679', '1.276']
800 ['1.713', '1.749']
900 ['1.714', '1.566']
1000 ['1.724', '1.176']
1100 ['1.730', '1.525']
1200 ['1.747', '0.861']
1300 ['1.752', '0.911']
1400 ['1.733', '1.790']
1500 ['1.747', '0.854']
1600 ['1.729', '1.293']
1700 ['1.754', '1.554']
1800 ['1.751', '1.093']
1900 ['1.754', '1.581']
2000 ['1.759', '1.197']
2100 ['1.776', '1.094']
2200 ['1.756', '1.336']
2300 ['1.767', '1.249']
2400 ['1.756', '1.555']
2500 ['1.779', '1.253']
2600 ['1.776', '1.108']
2700 ['1.765', '0.778']
2800 ['1.760', '1.060']
2900 ['1.772', '1.501']
3000 ['1.773', '1.625']
3100 ['1.764', '0.981']
3200 ['1.782', '0.879']
3300 ['1.764', '1.093']
3400 ['1.758', '1.290']
3500 ['1.759', '1.310']
3600 ['1.775', '1.506']
3700 ['1.778', '1.278']
Train: [1][3750/3750]	loss 0.072 (0.078)	Acc@1 37.500 (52.220)
0 ['1.788', '1.656']
100 ['1.759', '1.440']
200 ['1.767', '1.503']
300 ['1.762', '1.342']
400 ['1.769', '1.300']
500 ['1.771', '1.211']
600 ['1.767', '1.573']
700 ['1.775', '1.501']
800 ['1.782', '1.263']
900 ['1.753', '1.688']
1000 ['1.771', '0.970']
1100 ['1.769', '1.592']
1200 ['1.769', '1.067']
1300 ['1.783', '1.493']
1400 ['1.784', '1.295']
1500 ['1.768', '1.113']
1600 ['1.757', '1.368']
1700 ['1.765', '1.679']
1800 ['1.767', '1.478']
1900 ['1.773', '1.475']
2000 ['1.770', '1.336']
2100 ['1.788', '0.939']
2200 ['1.778', '1.362']
2300 ['1.764', '1.036']
2400 ['1.780', '1.854']
2500 ['1.770', '0.975']
2600 ['1.782', '0.955']
2700 ['1.761', '1.036']
2800 ['1.765', '1.099']
2900 ['1.770', '1.074']
3000 ['1.769', '1.106']
3100 ['1.777', '0.843']
3200 ['1.780', '1.382']
3300 ['1.791', '0.965']
3400 ['1.784', '1.743']
3500 ['1.787', '1.491']
3600 ['1.776', '1.374']
3700 ['1.784', '0.900']
Train: [2][3750/3750]	loss 0.067 (0.077)	Acc@1 68.750 (56.138)
0 ['1.777', '0.989']
100 ['1.783', '1.068']
200 ['1.779', '1.203']
300 ['1.785', '0.825']
400 ['1.767', '0.763']
500 ['1.788', '1.721']
600 ['1.786', '0.839']
700 ['1.772', '1.755']
800 ['1.777', '1.694']
900 ['1.793', '0.694']
1000 ['1.776', '1.397']
1100 ['1.789', '1.054']
1200 ['1.779', '0.935']
1300 ['1.779', '1.953']
1400 ['1.775', '1.218']
1500 ['1.796', '1.431']
1600 ['1.773', '0.562']
1700 ['1.787', '1.422']
1800 ['1.771', '1.456']
1900 ['1.787', '1.445']
2000 ['1.784', '1.505']
2100 ['1.777', '1.608']
2200 ['1.773', '1.094']
2300 ['1.760', '1.441']
2400 ['1.775', '1.484']
2500 ['1.772', '1.927']
2600 ['1.783', '1.628']
2700 ['1.770', '0.899']
2800 ['1.774', '1.089']
2900 ['1.773', '0.919']
3000 ['1.765', '1.332']
3100 ['1.772', '1.198']
3200 ['1.783', '1.148']
3300 ['1.787', '1.494']
3400 ['1.778', '1.384']
3500 ['1.786', '0.892']
3600 ['1.765', '1.235']
3700 ['1.776', '0.939']
Train: [3][3750/3750]	loss 0.087 (0.076)	Acc@1 50.000 (56.558)
0 ['1.777', '0.952']
100 ['1.769', '1.748']
200 ['1.780', '1.569']
300 ['1.778', '1.117']
400 ['1.778', '1.002']
500 ['1.776', '1.134']
600 ['1.778', '1.402']
700 ['1.772', '1.029']
800 ['1.770', '1.702']
900 ['1.786', '1.109']
1000 ['1.780', '1.124']
1100 ['1.767', '1.213']
1200 ['1.779', '1.161']
1300 ['1.772', '1.591']
1400 ['1.786', '1.158']
1500 ['1.757', '1.291']
1600 ['1.764', '1.128']
1700 ['1.767', '1.230']
1800 ['1.785', '1.874']
1900 ['1.779', '1.779']
2000 ['1.766', '1.241']
2100 ['1.777', '1.150']
2200 ['1.781', '1.196']
2300 ['1.773', '1.444']
2400 ['1.777', '1.743']
2500 ['1.775', '1.494']
2600 ['1.791', '0.910']
2700 ['1.784', '1.203']
2800 ['1.784', '1.192']
2900 ['1.783', '1.088']
3000 ['1.796', '1.187']
3100 ['1.778', '0.909']
3200 ['1.775', '0.959']
3300 ['1.775', '1.767']
3400 ['1.787', '1.030']
3500 ['1.768', '1.499']
3600 ['1.775', '1.230']
3700 ['1.772', '1.518']
Train: [4][3750/3750]	loss 0.070 (0.076)	Acc@1 56.250 (56.647)
0 ['1.778', '1.519']
100 ['1.785', '1.149']
200 ['1.794', '1.437']
300 ['1.784', '0.959']
400 ['1.774', '1.962']
500 ['1.759', '0.968']
600 ['1.782', '1.939']
700 ['1.786', '1.276']
800 ['1.781', '1.293']
900 ['1.780', '0.911']
1000 ['1.782', '1.149']
1100 ['1.787', '1.237']
1200 ['1.783', '1.102']
1300 ['1.795', '1.470']
1400 ['1.795', '1.318']
1500 ['1.771', '1.583']
1600 ['1.778', '1.210']
1700 ['1.773', '1.067']
1800 ['1.778', '1.366']
1900 ['1.767', '1.324']
2000 ['1.781', '1.595']
2100 ['1.775', '1.315']
2200 ['1.777', '1.067']
2300 ['1.774', '1.119']
2400 ['1.771', '0.790']
2500 ['1.787', '1.560']
2600 ['1.778', '1.201']
2700 ['1.781', '1.005']
2800 ['1.771', '1.950']
2900 ['1.774', '1.502']
3000 ['1.771', '1.300']
3100 ['1.769', '1.026']
3200 ['1.763', '1.843']
3300 ['1.772', '1.291']
3400 ['1.777', '1.398']
3500 ['1.769', '1.193']
3600 ['1.767', '1.249']
3700 ['1.790', '1.942']
Train: [5][3750/3750]	loss 0.085 (0.076)	Acc@1 37.500 (56.940)
Test model 1 on task 1
Test: [3/3]	loss 0.363 (0.322)	Acc@1 88.164 (89.400)
Test model 1 on task 2
Test: [3/3]	loss 0.258 (0.246)	Acc@1 91.482 (91.830)
Test model 1 on task 3
Test: [3/3]	loss 0.237 (0.225)	Acc@1 93.197 (92.740)
Test model 1 on task 4
Test: [3/3]	loss 0.221 (0.242)	Acc@1 92.478 (91.940)
Test model 1 on task 5
Test: [3/3]	loss 0.212 (0.228)	Acc@1 93.308 (93.080)
Test model 1 on task 6
Test: [3/3]	loss 0.209 (0.229)	Acc@1 93.639 (92.770)
Test model 1 on task 7
Test: [3/3]	loss 0.225 (0.235)	Acc@1 93.252 (92.740)
Test model 1 on task 8
Test: [3/3]	loss 0.231 (0.239)	Acc@1 92.423 (92.450)
Test model 1 on task 9
Test: [3/3]	loss 0.259 (0.248)	Acc@1 92.423 (92.640)
Test model 1 on task 10
Test: [3/3]	loss 0.287 (0.253)	Acc@1 91.316 (92.120)
Test model 1 on task 11
Test: [3/3]	loss 0.257 (0.259)	Acc@1 91.704 (92.040)
Test model 1 on task 12
Test: [3/3]	loss 0.259 (0.260)	Acc@1 91.925 (92.270)
Test model 1 on task 13
Test: [3/3]	loss 0.269 (0.270)	Acc@1 91.980 (91.900)
Test model 1 on task 14
Test: [3/3]	loss 0.317 (0.299)	Acc@1 90.321 (90.710)
Test model 1 on task 15
Test: [3/3]	loss 0.301 (0.300)	Acc@1 91.040 (91.060)
Test model 1 on task 16
Test: [3/3]	loss 0.318 (0.332)	Acc@1 90.708 (90.050)
Test model 1 on task 17
Test: [3/3]	loss 0.320 (0.313)	Acc@1 90.708 (90.580)
Test model 1 on task 18
Test: [3/3]	loss 0.319 (0.334)	Acc@1 91.316 (90.290)
Test model 1 on task 19
Test: [3/3]	loss 0.348 (0.373)	Acc@1 88.772 (88.390)
Test model 1 on task 20
Test: [3/3]	loss 0.392 (0.391)	Acc@1 88.551 (88.520)
Test model 1 on task 21
Test: [3/3]	loss 0.403 (0.405)	Acc@1 88.385 (87.920)
Test model 1 on task 22
Test: [3/3]	loss 0.470 (0.469)	Acc@1 86.338 (86.060)
Test model 1 on task 23
Test: [3/3]	loss 0.475 (0.460)	Acc@1 86.173 (86.530)
Test model 1 on task 24
Test: [3/3]	loss 0.531 (0.499)	Acc@1 82.909 (84.440)
Test model 1 on task 25
Test: [3/3]	loss 0.489 (0.510)	Acc@1 85.730 (84.840)
Test model 1 on task 26
Test: [3/3]	loss 0.553 (0.543)	Acc@1 83.794 (83.510)
Test model 1 on task 27
Test: [3/3]	loss 0.564 (0.548)	Acc@1 82.190 (83.050)
Test model 1 on task 28
Test: [3/3]	loss 0.617 (0.626)	Acc@1 81.305 (80.240)
Test model 1 on task 29
Test: [3/3]	loss 0.619 (0.611)	Acc@1 80.088 (80.790)
Test model 1 on task 30
Test: [3/3]	loss 0.711 (0.694)	Acc@1 77.489 (77.770)
Test model 1 on task 31
Test: [3/3]	loss 0.708 (0.711)	Acc@1 77.931 (77.830)
Test model 1 on task 32
Test: [3/3]	loss 0.794 (0.759)	Acc@1 74.945 (75.750)
Test model 1 on task 33
Test: [3/3]	loss 0.773 (0.804)	Acc@1 75.774 (74.370)
Test model 1 on task 34
Test: [3/3]	loss 0.900 (0.863)	Acc@1 71.073 (72.070)
Test model 1 on task 35
Test: [3/3]	loss 0.946 (0.946)	Acc@1 68.142 (69.270)
Test model 1 on task 36
Test: [3/3]	loss 0.956 (0.950)	Acc@1 69.248 (69.630)
Test model 1 on task 37
Test: [3/3]	loss 0.961 (0.981)	Acc@1 67.810 (67.200)
Test model 1 on task 38
Test: [3/3]	loss 0.965 (0.970)	Acc@1 68.473 (68.080)
Test model 1 on task 39
Test: [3/3]	loss 1.033 (1.051)	Acc@1 65.100 (64.960)
Test model 1 on task 40
Test: [3/3]	loss 1.237 (1.242)	Acc@1 57.356 (56.810)
############################################################ Avg acc: 83.97
Task 41 Model 1:
0 ['1.263', '4.733']
100 ['1.598', '2.410']
200 ['1.687', '1.487']
300 ['1.732', '1.870']
400 ['1.765', '1.271']
500 ['1.795', '2.027']
600 ['1.833', '1.868']
700 ['1.844', '1.578']
800 ['1.858', '1.865']
900 ['1.882', '1.580']
1000 ['1.914', '1.655']
1100 ['1.900', '1.969']
1200 ['1.901', '1.432']
1300 ['1.924', '1.234']
1400 ['1.931', '0.960']
1500 ['1.924', '1.326']
1600 ['1.921', '1.278']
1700 ['1.924', '1.333']
1800 ['1.946', '1.900']
1900 ['1.945', '1.142']
2000 ['1.944', '1.442']
2100 ['1.945', '1.985']
2200 ['1.951', '1.034']
2300 ['1.957', '1.355']
2400 ['1.945', '1.013']
2500 ['1.951', '1.411']
2600 ['1.953', '2.195']
2700 ['1.941', '1.429']
2800 ['1.936', '1.439']
2900 ['1.949', '1.393']
3000 ['1.947', '1.701']
3100 ['1.947', '1.139']
3200 ['1.962', '1.512']
3300 ['1.955', '1.341']
3400 ['1.951', '1.100']
3500 ['1.941', '1.375']
3600 ['1.953', '1.183']
3700 ['1.960', '1.427']
Train: [1][3750/3750]	loss 0.072 (0.081)	Acc@1 56.250 (52.173)
0 ['1.979', '1.785']
100 ['1.962', '1.037']
200 ['1.958', '1.704']
300 ['1.954', '0.855']
400 ['1.953', '1.796']
500 ['1.957', '1.340']
600 ['1.956', '1.489']
700 ['1.960', '0.954']
800 ['1.960', '1.466']
900 ['1.968', '2.033']
1000 ['1.958', '1.231']
1100 ['1.973', '1.579']
1200 ['1.956', '1.587']
1300 ['1.960', '1.252']
1400 ['1.970', '1.297']
1500 ['1.978', '1.415']
1600 ['1.966', '1.558']
1700 ['1.956', '1.096']
1800 ['1.969', '0.734']
1900 ['1.953', '1.263']
2000 ['1.962', '1.337']
2100 ['1.957', '0.861']
2200 ['1.948', '0.911']
2300 ['1.957', '1.292']
2400 ['1.970', '1.235']
2500 ['1.967', '1.238']
2600 ['1.956', '1.451']
2700 ['1.970', '1.037']
2800 ['1.969', '1.260']
2900 ['1.963', '1.248']
3000 ['1.963', '1.050']
3100 ['1.964', '1.502']
3200 ['1.960', '1.177']
3300 ['1.962', '1.354']
3400 ['1.975', '1.124']
3500 ['1.957', '1.502']
3600 ['1.968', '1.195']
3700 ['1.965', '1.517']
Train: [2][3750/3750]	loss 0.086 (0.079)	Acc@1 37.500 (56.622)
0 ['1.961', '1.714']
100 ['1.973', '1.011']
200 ['1.965', '1.800']
300 ['1.956', '1.072']
400 ['1.972', '1.049']
500 ['1.977', '1.401']
600 ['1.972', '1.449']
700 ['1.963', '1.225']
800 ['1.978', '0.696']
900 ['1.976', '1.375']
1000 ['1.977', '1.391']
1100 ['1.956', '1.523']
1200 ['1.955', '1.064']
1300 ['1.961', '1.685']
1400 ['1.966', '1.153']
1500 ['1.965', '1.027']
1600 ['1.962', '1.439']
1700 ['1.951', '0.919']
1800 ['1.970', '1.382']
1900 ['1.979', '1.272']
2000 ['1.979', '1.188']
2100 ['1.974', '1.472']
2200 ['1.966', '1.840']
2300 ['1.959', '1.028']
2400 ['1.965', '1.519']
2500 ['1.950', '1.042']
2600 ['1.967', '1.181']
2700 ['1.967', '1.343']
2800 ['1.958', '1.014']
2900 ['1.970', '1.536']
3000 ['1.962', '1.350']
3100 ['1.974', '1.186']
3200 ['1.957', '1.303']
3300 ['1.962', '1.340']
3400 ['1.949', '1.764']
3500 ['1.972', '1.416']
3600 ['1.966', '1.238']
3700 ['1.955', '1.344']
Train: [3][3750/3750]	loss 0.066 (0.079)	Acc@1 81.250 (56.712)
0 ['1.958', '1.082']
100 ['1.967', '1.364']
200 ['1.965', '0.877']
300 ['1.964', '1.156']
400 ['1.952', '1.160']
500 ['1.963', '1.278']
600 ['1.954', '1.388']
700 ['1.970', '1.264']
800 ['1.957', '1.488']
900 ['1.963', '1.363']
1000 ['1.965', '1.616']
1100 ['1.970', '1.793']
1200 ['1.975', '1.485']
1300 ['1.963', '1.616']
1400 ['1.957', '1.135']
1500 ['1.956', '0.980']
1600 ['1.968', '1.250']
1700 ['1.962', '1.404']
1800 ['1.954', '0.852']
1900 ['1.963', '1.379']
2000 ['1.972', '1.160']
2100 ['1.977', '1.440']
2200 ['1.970', '1.023']
2300 ['1.964', '1.324']
2400 ['1.963', '1.019']
2500 ['1.956', '1.262']
2600 ['1.959', '1.135']
2700 ['1.961', '1.411']
2800 ['1.972', '1.230']
2900 ['1.983', '1.172']
3000 ['1.961', '1.446']
3100 ['1.972', '1.276']
3200 ['1.968', '1.227']
3300 ['1.975', '1.496']
3400 ['1.966', '1.355']
3500 ['1.959', '0.839']
3600 ['1.973', '1.359']
3700 ['1.967', '1.138']
Train: [4][3750/3750]	loss 0.081 (0.079)	Acc@1 62.500 (56.603)
0 ['1.961', '1.105']
100 ['1.973', '1.208']
200 ['1.958', '1.602']
300 ['1.972', '1.147']
400 ['1.952', '1.917']
500 ['1.959', '1.190']
600 ['1.963', '1.304']
700 ['1.973', '1.531']
800 ['1.957', '1.621']
900 ['1.977', '1.423']
1000 ['1.962', '1.224']
1100 ['1.966', '0.963']
1200 ['1.974', '2.070']
1300 ['1.972', '1.174']
1400 ['1.959', '1.126']
1500 ['1.970', '1.438']
1600 ['1.978', '0.922']
1700 ['1.973', '0.972']
1800 ['1.982', '0.857']
1900 ['1.969', '1.166']
2000 ['1.972', '1.114']
2100 ['1.954', '1.415']
2200 ['1.966', '1.036']
2300 ['1.959', '1.202']
2400 ['1.954', '1.376']
2500 ['1.966', '1.117']
2600 ['1.959', '0.890']
2700 ['1.966', '1.414']
2800 ['1.979', '0.784']
2900 ['1.978', '1.610']
3000 ['1.972', '1.125']
3100 ['1.978', '1.531']
3200 ['1.961', '0.614']
3300 ['1.957', '0.923']
3400 ['1.969', '1.639']
3500 ['1.967', '0.802']
3600 ['1.959', '1.132']
3700 ['1.968', '1.384']
Train: [5][3750/3750]	loss 0.073 (0.079)	Acc@1 62.500 (56.743)
Test model 1 on task 1
Test: [3/3]	loss 0.337 (0.323)	Acc@1 89.381 (89.310)
Test model 1 on task 2
Test: [3/3]	loss 0.224 (0.245)	Acc@1 92.091 (91.810)
Test model 1 on task 3
Test: [3/3]	loss 0.230 (0.226)	Acc@1 92.533 (92.710)
Test model 1 on task 4
Test: [3/3]	loss 0.218 (0.243)	Acc@1 92.754 (91.890)
Test model 1 on task 5
Test: [3/3]	loss 0.252 (0.229)	Acc@1 92.478 (93.090)
Test model 1 on task 6
Test: [3/3]	loss 0.214 (0.230)	Acc@1 92.920 (92.670)
Test model 1 on task 7
Test: [3/3]	loss 0.246 (0.238)	Acc@1 92.644 (92.730)
Test model 1 on task 8
Test: [3/3]	loss 0.250 (0.240)	Acc@1 91.925 (92.390)
Test model 1 on task 9
Test: [3/3]	loss 0.231 (0.250)	Acc@1 92.810 (92.590)
Test model 1 on task 10
Test: [3/3]	loss 0.257 (0.254)	Acc@1 91.759 (92.110)
Test model 1 on task 11
Test: [3/3]	loss 0.253 (0.261)	Acc@1 91.869 (91.990)
Test model 1 on task 12
Test: [3/3]	loss 0.260 (0.263)	Acc@1 92.367 (92.080)
Test model 1 on task 13
Test: [3/3]	loss 0.251 (0.272)	Acc@1 92.367 (91.810)
Test model 1 on task 14
Test: [3/3]	loss 0.301 (0.302)	Acc@1 90.874 (90.650)
Test model 1 on task 15
Test: [3/3]	loss 0.301 (0.302)	Acc@1 90.929 (90.970)
Test model 1 on task 16
Test: [3/3]	loss 0.378 (0.333)	Acc@1 88.496 (89.970)
Test model 1 on task 17
Test: [3/3]	loss 0.298 (0.314)	Acc@1 90.819 (90.590)
Test model 1 on task 18
Test: [3/3]	loss 0.340 (0.335)	Acc@1 90.376 (90.360)
Test model 1 on task 19
Test: [3/3]	loss 0.399 (0.375)	Acc@1 87.113 (88.350)
Test model 1 on task 20
Test: [3/3]	loss 0.374 (0.391)	Acc@1 88.717 (88.400)
Test model 1 on task 21
Test: [3/3]	loss 0.409 (0.406)	Acc@1 87.887 (88.000)
Test model 1 on task 22
Test: [3/3]	loss 0.469 (0.469)	Acc@1 86.007 (86.110)
Test model 1 on task 23
Test: [3/3]	loss 0.483 (0.463)	Acc@1 85.066 (86.470)
Test model 1 on task 24
Test: [3/3]	loss 0.513 (0.501)	Acc@1 83.407 (84.450)
Test model 1 on task 25
Test: [3/3]	loss 0.497 (0.511)	Acc@1 84.458 (84.850)
Test model 1 on task 26
Test: [3/3]	loss 0.517 (0.543)	Acc@1 83.794 (83.590)
Test model 1 on task 27
Test: [3/3]	loss 0.533 (0.549)	Acc@1 83.573 (83.170)
Test model 1 on task 28
Test: [3/3]	loss 0.682 (0.627)	Acc@1 77.987 (80.170)
Test model 1 on task 29
Test: [3/3]	loss 0.645 (0.613)	Acc@1 80.752 (80.750)
Test model 1 on task 30
Test: [3/3]	loss 0.693 (0.696)	Acc@1 78.042 (77.750)
Test model 1 on task 31
Test: [3/3]	loss 0.757 (0.713)	Acc@1 75.719 (77.830)
Test model 1 on task 32
Test: [3/3]	loss 0.759 (0.762)	Acc@1 76.604 (75.780)
Test model 1 on task 33
Test: [3/3]	loss 0.784 (0.806)	Acc@1 75.055 (74.420)
Test model 1 on task 34
Test: [3/3]	loss 0.887 (0.864)	Acc@1 70.631 (71.890)
Test model 1 on task 35
Test: [3/3]	loss 0.950 (0.944)	Acc@1 67.920 (69.180)
Test model 1 on task 36
Test: [3/3]	loss 0.938 (0.953)	Acc@1 71.128 (69.520)
Test model 1 on task 37
Test: [3/3]	loss 1.018 (0.985)	Acc@1 66.040 (66.890)
Test model 1 on task 38
Test: [3/3]	loss 0.975 (0.971)	Acc@1 68.142 (68.070)
Test model 1 on task 39
Test: [3/3]	loss 1.050 (1.055)	Acc@1 64.657 (64.670)
Test model 1 on task 40
Test: [3/3]	loss 1.267 (1.242)	Acc@1 54.978 (56.830)
Test model 1 on task 41
Test: [3/3]	loss 1.248 (1.258)	Acc@1 58.739 (58.170)
############################################################ Avg acc: 83.29
Task 42 Model 1:
0 ['1.285', '3.053']
100 ['1.614', '1.833']
200 ['1.695', '2.095']
300 ['1.764', '1.653']
400 ['1.811', '1.066']
500 ['1.843', '1.555']
600 ['1.872', '1.301']
700 ['1.889', '1.584']
800 ['1.900', '1.352']
900 ['1.919', '1.486']
1000 ['1.915', '1.153']
1100 ['1.935', '1.043']
1200 ['1.933', '1.908']
1300 ['1.962', '1.628']
1400 ['1.937', '1.093']
1500 ['1.934', '0.985']
1600 ['1.933', '1.650']
1700 ['1.947', '1.346']
1800 ['1.952', '1.526']
1900 ['1.944', '1.809']
2000 ['1.951', '1.516']
2100 ['1.954', '1.298']
2200 ['1.940', '1.252']
2300 ['1.936', '1.023']
2400 ['1.947', '1.526']
2500 ['1.950', '1.148']
2600 ['1.945', '1.285']
2700 ['1.963', '1.663']
2800 ['1.962', '1.272']
2900 ['1.957', '1.475']
3000 ['1.962', '1.719']
3100 ['1.963', '1.697']
3200 ['1.960', '1.373']
3300 ['1.956', '1.279']
3400 ['1.954', '1.199']
3500 ['1.961', '1.318']
3600 ['1.974', '1.414']
3700 ['1.963', '0.814']
Train: [1][3750/3750]	loss 0.071 (0.079)	Acc@1 75.000 (54.215)
0 ['1.969', '0.787']
100 ['1.985', '0.776']
200 ['1.959', '1.012']
300 ['1.971', '1.323']
400 ['1.965', '1.596']
500 ['1.955', '1.390']
600 ['1.956', '0.805']
700 ['1.959', '0.956']
800 ['1.979', '1.106']
900 ['1.969', '1.956']
1000 ['1.961', '1.137']
1100 ['1.957', '1.181']
1200 ['1.958', '0.809']
1300 ['1.954', '1.122']
1400 ['1.963', '1.214']
1500 ['1.951', '1.260']
1600 ['1.970', '1.458']
1700 ['1.983', '1.681']
1800 ['1.961', '1.299']
1900 ['1.961', '0.955']
2000 ['1.971', '2.166']
2100 ['1.970', '0.929']
2200 ['1.964', '1.576']
2300 ['1.970', '0.836']
2400 ['1.969', '0.938']
2500 ['1.953', '1.434']
2600 ['1.967', '1.113']
2700 ['1.957', '1.165']
2800 ['1.973', '1.155']
2900 ['1.982', '1.315']
3000 ['1.979', '1.353']
3100 ['1.980', '1.400']
3200 ['1.981', '1.147']
3300 ['1.991', '1.498']
3400 ['1.977', '1.166']
3500 ['1.979', '1.036']
3600 ['1.976', '1.997']
3700 ['1.987', '1.172']
Train: [2][3750/3750]	loss 0.084 (0.077)	Acc@1 50.000 (57.808)
0 ['1.986', '1.539']
100 ['1.955', '1.183']
200 ['1.984', '1.048']
300 ['1.990', '1.093']
400 ['1.973', '1.264']
500 ['1.977', '1.521']
600 ['1.983', '0.997']
700 ['1.972', '2.000']
800 ['1.981', '0.893']
900 ['1.975', '1.340']
1000 ['1.982', '1.015']
1100 ['1.969', '1.202']
1200 ['1.976', '0.688']
1300 ['1.967', '1.539']
1400 ['1.959', '1.170']
1500 ['1.951', '1.081']
1600 ['1.972', '1.471']
1700 ['1.963', '1.282']
1800 ['1.951', '1.457']
1900 ['1.976', '1.206']
2000 ['1.964', '1.456']
2100 ['1.972', '1.263']
2200 ['1.984', '1.116']
2300 ['1.961', '0.951']
2400 ['1.977', '1.167']
2500 ['1.970', '0.987']
2600 ['1.968', '0.883']
2700 ['1.981', '1.029']
2800 ['1.982', '1.853']
2900 ['1.982', '0.943']
3000 ['1.983', '0.890']
3100 ['1.984', '1.432']
3200 ['1.986', '1.066']
3300 ['1.970', '1.799']
3400 ['1.965', '1.127']
3500 ['1.978', '1.626']
3600 ['1.977', '0.964']
3700 ['1.962', '0.991']
Train: [3][3750/3750]	loss 0.069 (0.077)	Acc@1 56.250 (58.005)
0 ['1.968', '0.804']
100 ['1.962', '1.363']
200 ['1.952', '1.232']
300 ['1.962', '1.321']
400 ['1.963', '1.371']
500 ['1.966', '1.158']
600 ['1.976', '1.072']
700 ['1.975', '1.219']
800 ['1.965', '1.682']
900 ['1.977', '1.262']
1000 ['1.981', '1.539']
1100 ['1.961', '1.176']
1200 ['1.976', '1.051']
1300 ['1.965', '1.256']
1400 ['1.949', '1.873']
1500 ['1.972', '1.347']
1600 ['1.964', '1.115']
1700 ['1.970', '1.534']
1800 ['1.962', '1.371']
1900 ['1.972', '1.494']
2000 ['1.982', '1.107']
2100 ['1.979', '1.140']
2200 ['1.975', '1.199']
2300 ['1.983', '1.638']
2400 ['1.975', '1.741']
2500 ['1.971', '1.413']
2600 ['1.958', '1.590']
2700 ['1.970', '1.520']
2800 ['1.982', '0.992']
2900 ['1.986', '1.345']
3000 ['1.960', '1.814']
3100 ['1.973', '1.186']
3200 ['1.981', '1.559']
3300 ['1.972', '1.081']
3400 ['1.969', '1.477']
3500 ['1.975', '1.338']
3600 ['1.974', '1.567']
3700 ['1.981', '1.385']
Train: [4][3750/3750]	loss 0.079 (0.077)	Acc@1 43.750 (57.982)
0 ['1.979', '1.523']
100 ['1.979', '1.772']
200 ['1.958', '1.110']
300 ['1.971', '0.971']
400 ['1.976', '1.305']
500 ['1.993', '1.800']
600 ['1.980', '1.410']
700 ['1.988', '1.016']
800 ['1.977', '0.921']
900 ['1.976', '1.472']
1000 ['1.971', '1.657']
1100 ['1.973', '0.967']
1200 ['1.972', '1.375']
1300 ['1.971', '1.586']
1400 ['1.958', '1.066']
1500 ['1.967', '0.950']
1600 ['1.961', '0.904']
1700 ['1.953', '1.632']
1800 ['1.957', '1.675']
1900 ['1.972', '1.364']
2000 ['1.961', '0.868']
2100 ['1.952', '1.629']
2200 ['1.970', '1.249']
2300 ['1.964', '1.452']
2400 ['1.973', '1.444']
2500 ['1.972', '1.223']
2600 ['1.972', '1.246']
2700 ['1.979', '1.301']
2800 ['1.980', '0.992']
2900 ['1.972', '0.913']
3000 ['1.989', '1.448']
3100 ['1.971', '0.959']
3200 ['1.960', '0.775']
3300 ['1.971', '1.497']
3400 ['1.959', '0.726']
3500 ['1.965', '1.477']
3600 ['1.969', '1.560']
3700 ['1.987', '1.049']
Train: [5][3750/3750]	loss 0.076 (0.077)	Acc@1 62.500 (57.940)
Test model 1 on task 1
Test: [3/3]	loss 0.322 (0.324)	Acc@1 88.938 (89.290)
Test model 1 on task 2
Test: [3/3]	loss 0.256 (0.246)	Acc@1 91.316 (91.740)
Test model 1 on task 3
Test: [3/3]	loss 0.239 (0.225)	Acc@1 92.976 (92.700)
Test model 1 on task 4
Test: [3/3]	loss 0.232 (0.243)	Acc@1 92.423 (91.860)
Test model 1 on task 5
Test: [3/3]	loss 0.241 (0.231)	Acc@1 92.644 (93.100)
Test model 1 on task 6
Test: [3/3]	loss 0.255 (0.231)	Acc@1 92.257 (92.720)
Test model 1 on task 7
Test: [3/3]	loss 0.233 (0.239)	Acc@1 92.754 (92.630)
Test model 1 on task 8
Test: [3/3]	loss 0.250 (0.240)	Acc@1 92.478 (92.360)
Test model 1 on task 9
Test: [3/3]	loss 0.250 (0.251)	Acc@1 92.920 (92.520)
Test model 1 on task 10
Test: [3/3]	loss 0.237 (0.255)	Acc@1 92.754 (92.080)
Test model 1 on task 11
Test: [3/3]	loss 0.265 (0.262)	Acc@1 91.980 (91.880)
Test model 1 on task 12
Test: [3/3]	loss 0.267 (0.264)	Acc@1 91.316 (92.060)
Test model 1 on task 13
Test: [3/3]	loss 0.274 (0.274)	Acc@1 91.869 (91.590)
Test model 1 on task 14
Test: [3/3]	loss 0.295 (0.304)	Acc@1 90.265 (90.530)
Test model 1 on task 15
Test: [3/3]	loss 0.297 (0.303)	Acc@1 91.593 (90.900)
Test model 1 on task 16
Test: [3/3]	loss 0.328 (0.335)	Acc@1 90.321 (89.910)
Test model 1 on task 17
Test: [3/3]	loss 0.318 (0.315)	Acc@1 90.542 (90.450)
Test model 1 on task 18
Test: [3/3]	loss 0.348 (0.336)	Acc@1 89.712 (90.300)
Test model 1 on task 19
Test: [3/3]	loss 0.380 (0.377)	Acc@1 87.279 (88.400)
Test model 1 on task 20
Test: [3/3]	loss 0.364 (0.391)	Acc@1 88.551 (88.490)
Test model 1 on task 21
Test: [3/3]	loss 0.421 (0.407)	Acc@1 87.555 (87.970)
Test model 1 on task 22
Test: [3/3]	loss 0.474 (0.471)	Acc@1 85.288 (86.020)
Test model 1 on task 23
Test: [3/3]	loss 0.476 (0.464)	Acc@1 86.394 (86.360)
Test model 1 on task 24
Test: [3/3]	loss 0.512 (0.500)	Acc@1 85.177 (84.360)
Test model 1 on task 25
Test: [3/3]	loss 0.482 (0.513)	Acc@1 85.232 (84.790)
Test model 1 on task 26
Test: [3/3]	loss 0.554 (0.545)	Acc@1 82.965 (83.300)
Test model 1 on task 27
Test: [3/3]	loss 0.538 (0.549)	Acc@1 83.352 (83.070)
Test model 1 on task 28
Test: [3/3]	loss 0.647 (0.628)	Acc@1 78.982 (80.230)
Test model 1 on task 29
Test: [3/3]	loss 0.610 (0.614)	Acc@1 80.199 (80.740)
Test model 1 on task 30
Test: [3/3]	loss 0.668 (0.698)	Acc@1 78.872 (77.560)
Test model 1 on task 31
Test: [3/3]	loss 0.703 (0.717)	Acc@1 77.434 (77.600)
Test model 1 on task 32
Test: [3/3]	loss 0.753 (0.758)	Acc@1 76.383 (75.960)
Test model 1 on task 33
Test: [3/3]	loss 0.797 (0.808)	Acc@1 74.336 (74.310)
Test model 1 on task 34
Test: [3/3]	loss 0.849 (0.866)	Acc@1 72.732 (71.920)
Test model 1 on task 35
Test: [3/3]	loss 0.970 (0.942)	Acc@1 68.363 (69.130)
Test model 1 on task 36
Test: [3/3]	loss 0.955 (0.955)	Acc@1 69.082 (69.470)
Test model 1 on task 37
Test: [3/3]	loss 0.992 (0.981)	Acc@1 67.091 (67.040)
Test model 1 on task 38
Test: [3/3]	loss 0.935 (0.968)	Acc@1 68.473 (68.110)
Test model 1 on task 39
Test: [3/3]	loss 1.045 (1.054)	Acc@1 65.985 (64.800)
Test model 1 on task 40
Test: [3/3]	loss 1.202 (1.239)	Acc@1 58.131 (56.990)
Test model 1 on task 41
Test: [3/3]	loss 1.227 (1.261)	Acc@1 59.900 (57.900)
Test model 1 on task 42
Test: [3/3]	loss 1.190 (1.216)	Acc@1 61.338 (59.930)
############################################################ Avg acc: 82.69
Task 43 Model 1:
0 ['1.270', '3.693']
100 ['1.598', '2.097']
200 ['1.714', '1.989']
300 ['1.771', '2.074']
400 ['1.806', '1.738']
500 ['1.832', '1.613']
600 ['1.840', '2.228']
700 ['1.868', '1.818']
800 ['1.873', '1.360']
900 ['1.887', '1.648']
1000 ['1.892', '1.483']
1100 ['1.892', '1.657']
1200 ['1.917', '2.119']
1300 ['1.899', '1.834']
1400 ['1.898', '1.245']
1500 ['1.905', '1.014']
1600 ['1.920', '1.673']
1700 ['1.913', '0.814']
1800 ['1.916', '1.841']
1900 ['1.922', '2.073']
2000 ['1.921', '1.243']
2100 ['1.927', '1.357']
2200 ['1.918', '1.025']
2300 ['1.939', '0.994']
2400 ['1.923', '1.464']
2500 ['1.914', '1.602']
2600 ['1.922', '1.875']
2700 ['1.925', '1.001']
2800 ['1.925', '1.074']
2900 ['1.939', '1.244']
3000 ['1.945', '1.414']
3100 ['1.936', '1.607']
3200 ['1.935', '1.080']
3300 ['1.941', '1.649']
3400 ['1.936', '0.976']
3500 ['1.957', '1.506']
3600 ['1.944', '1.213']
3700 ['1.950', '1.712']
Train: [1][3750/3750]	loss 0.083 (0.080)	Acc@1 25.000 (48.293)
0 ['1.930', '1.248']
100 ['1.957', '1.500']
200 ['1.933', '1.190']
300 ['1.941', '1.318']
400 ['1.936', '1.430']
500 ['1.948', '1.375']
600 ['1.950', '1.123']
700 ['1.947', '1.277']
800 ['1.948', '1.617']
900 ['1.955', '1.370']
1000 ['1.954', '1.687']
1100 ['1.948', '1.704']
1200 ['1.942', '1.665']
1300 ['1.945', '1.425']
1400 ['1.944', '1.503']
1500 ['1.951', '0.804']
1600 ['1.970', '1.090']
1700 ['1.953', '1.791']
1800 ['1.971', '0.954']
1900 ['1.958', '1.368']
2000 ['1.965', '1.094']
2100 ['1.960', '1.080']
2200 ['1.966', '1.528']
2300 ['1.951', '1.644']
2400 ['1.964', '1.742']
2500 ['1.958', '1.226']
2600 ['1.951', '0.876']
2700 ['1.965', '1.583']
2800 ['1.944', '2.112']
2900 ['1.963', '0.796']
3000 ['1.944', '1.240']
3100 ['1.966', '1.893']
3200 ['1.972', '1.044']
3300 ['1.941', '1.374']
3400 ['1.933', '1.612']
3500 ['1.945', '1.360']
3600 ['1.946', '1.334']
3700 ['1.963', '1.794']
Train: [2][3750/3750]	loss 0.079 (0.079)	Acc@1 50.000 (51.907)
0 ['1.955', '1.840']
100 ['1.951', '1.417']
200 ['1.941', '0.870']
300 ['1.949', '1.198']
400 ['1.963', '1.867']
500 ['1.956', '1.924']
600 ['1.968', '1.600']
700 ['1.956', '1.458']
800 ['1.957', '1.274']
900 ['1.963', '1.411']
1000 ['1.962', '1.219']
1100 ['1.976', '1.613']
1200 ['1.957', '1.559']
1300 ['1.953', '0.782']
1400 ['1.971', '1.021']
1500 ['1.961', '1.873']
1600 ['1.956', '1.426']
1700 ['1.965', '1.028']
1800 ['1.973', '1.420']
1900 ['1.958', '1.471']
2000 ['1.978', '1.156']
2100 ['1.952', '1.375']
2200 ['1.963', '1.446']
2300 ['1.955', '1.661']
2400 ['1.966', '1.415']
2500 ['1.952', '1.626']
2600 ['1.959', '1.601']
2700 ['1.984', '1.010']
2800 ['1.953', '1.350']
2900 ['1.944', '1.352']
3000 ['1.980', '1.269']
3100 ['1.976', '1.164']
3200 ['1.971', '1.334']
3300 ['1.972', '1.604']
3400 ['1.954', '1.935']
3500 ['1.983', '1.308']
3600 ['1.958', '1.313']
3700 ['1.980', '1.940']
Train: [3][3750/3750]	loss 0.073 (0.079)	Acc@1 62.500 (52.432)
0 ['1.962', '1.203']
100 ['1.967', '1.286']
200 ['1.973', '1.528']
300 ['1.967', '1.570']
400 ['1.978', '1.036']
500 ['1.964', '1.794']
600 ['1.984', '1.319']
700 ['1.961', '1.889']
800 ['1.961', '1.477']
900 ['1.983', '1.948']
1000 ['1.972', '2.020']
1100 ['1.975', '0.795']
1200 ['1.966', '1.322']
1300 ['1.970', '1.365']
1400 ['1.973', '1.267']
1500 ['1.965', '1.452']
1600 ['1.968', '1.731']
1700 ['1.950', '1.429']
1800 ['1.956', '1.227']
1900 ['1.960', '1.575']
2000 ['1.968', '1.282']
2100 ['1.977', '1.784']
2200 ['1.972', '1.373']
2300 ['1.966', '1.066']
2400 ['1.973', '1.531']
2500 ['1.970', '1.765']
2600 ['1.975', '1.635']
2700 ['1.969', '1.947']
2800 ['1.959', '1.111']
2900 ['1.959', '1.490']
3000 ['1.965', '1.605']
3100 ['1.947', '1.350']
3200 ['1.984', '1.594']
3300 ['1.967', '1.287']
3400 ['1.980', '1.792']
3500 ['1.971', '1.489']
3600 ['1.979', '1.395']
3700 ['1.955', '1.284']
Train: [4][3750/3750]	loss 0.083 (0.079)	Acc@1 50.000 (52.612)
0 ['1.957', '1.163']
100 ['1.962', '1.219']
200 ['1.946', '1.836']
300 ['1.960', '2.242']
400 ['1.966', '1.352']
500 ['1.987', '1.899']
600 ['1.967', '1.464']
700 ['1.956', '1.224']
800 ['1.967', '1.367']
900 ['1.971', '1.257']
1000 ['1.980', '1.421']
1100 ['1.973', '1.346']
1200 ['1.970', '1.487']
1300 ['1.961', '1.242']
1400 ['1.988', '1.297']
1500 ['1.982', '1.522']
1600 ['1.983', '1.687']
1700 ['1.968', '1.084']
1800 ['1.962', '1.289']
1900 ['1.972', '1.028']
2000 ['1.965', '1.925']
2100 ['1.966', '1.325']
2200 ['1.975', '1.728']
2300 ['1.967', '1.174']
2400 ['1.960', '1.223']
2500 ['1.972', '1.299']
2600 ['1.973', '1.006']
2700 ['1.976', '1.750']
2800 ['1.968', '1.488']
2900 ['1.971', '1.505']
3000 ['1.965', '1.582']
3100 ['1.978', '1.507']
3200 ['1.964', '1.267']
3300 ['1.967', '1.544']
3400 ['1.978', '2.263']
3500 ['1.979', '0.981']
3600 ['1.971', '0.878']
3700 ['1.966', '0.836']
Train: [5][3750/3750]	loss 0.076 (0.079)	Acc@1 50.000 (52.750)
Test model 1 on task 1
Test: [3/3]	loss 0.290 (0.326)	Acc@1 89.989 (89.300)
Test model 1 on task 2
Test: [3/3]	loss 0.212 (0.248)	Acc@1 92.644 (91.660)
Test model 1 on task 3
Test: [3/3]	loss 0.219 (0.226)	Acc@1 92.920 (92.690)
Test model 1 on task 4
Test: [3/3]	loss 0.253 (0.243)	Acc@1 91.980 (91.780)
Test model 1 on task 5
Test: [3/3]	loss 0.216 (0.231)	Acc@1 93.750 (93.090)
Test model 1 on task 6
Test: [3/3]	loss 0.235 (0.232)	Acc@1 92.810 (92.640)
Test model 1 on task 7
Test: [3/3]	loss 0.223 (0.241)	Acc@1 93.473 (92.570)
Test model 1 on task 8
Test: [3/3]	loss 0.238 (0.241)	Acc@1 92.920 (92.270)
Test model 1 on task 9
Test: [3/3]	loss 0.254 (0.251)	Acc@1 92.367 (92.600)
Test model 1 on task 10
Test: [3/3]	loss 0.248 (0.256)	Acc@1 91.980 (92.060)
Test model 1 on task 11
Test: [3/3]	loss 0.255 (0.262)	Acc@1 92.146 (91.960)
Test model 1 on task 12
Test: [3/3]	loss 0.308 (0.265)	Acc@1 90.321 (92.000)
Test model 1 on task 13
Test: [3/3]	loss 0.260 (0.274)	Acc@1 91.814 (91.620)
Test model 1 on task 14
Test: [3/3]	loss 0.289 (0.305)	Acc@1 90.487 (90.490)
Test model 1 on task 15
Test: [3/3]	loss 0.308 (0.304)	Acc@1 90.210 (90.850)
Test model 1 on task 16
Test: [3/3]	loss 0.355 (0.336)	Acc@1 89.325 (89.960)
Test model 1 on task 17
Test: [3/3]	loss 0.336 (0.317)	Acc@1 89.325 (90.350)
Test model 1 on task 18
Test: [3/3]	loss 0.319 (0.337)	Acc@1 90.874 (90.390)
Test model 1 on task 19
Test: [3/3]	loss 0.391 (0.378)	Acc@1 87.777 (88.330)
Test model 1 on task 20
Test: [3/3]	loss 0.374 (0.392)	Acc@1 89.049 (88.330)
Test model 1 on task 21
Test: [3/3]	loss 0.429 (0.407)	Acc@1 87.445 (87.930)
Test model 1 on task 22
Test: [3/3]	loss 0.492 (0.473)	Acc@1 85.288 (85.890)
Test model 1 on task 23
Test: [3/3]	loss 0.473 (0.466)	Acc@1 86.117 (86.310)
Test model 1 on task 24
Test: [3/3]	loss 0.501 (0.503)	Acc@1 84.900 (84.290)
Test model 1 on task 25
Test: [3/3]	loss 0.502 (0.515)	Acc@1 85.619 (84.630)
Test model 1 on task 26
Test: [3/3]	loss 0.571 (0.546)	Acc@1 83.131 (83.290)
Test model 1 on task 27
Test: [3/3]	loss 0.521 (0.549)	Acc@1 83.573 (83.060)
Test model 1 on task 28
Test: [3/3]	loss 0.639 (0.630)	Acc@1 79.867 (80.040)
Test model 1 on task 29
Test: [3/3]	loss 0.622 (0.615)	Acc@1 80.752 (80.860)
Test model 1 on task 30
Test: [3/3]	loss 0.683 (0.696)	Acc@1 77.544 (77.600)
Test model 1 on task 31
Test: [3/3]	loss 0.709 (0.719)	Acc@1 77.212 (77.580)
Test model 1 on task 32
Test: [3/3]	loss 0.755 (0.759)	Acc@1 76.106 (75.810)
Test model 1 on task 33
Test: [3/3]	loss 0.789 (0.810)	Acc@1 74.115 (74.170)
Test model 1 on task 34
Test: [3/3]	loss 0.865 (0.866)	Acc@1 71.847 (71.940)
Test model 1 on task 35
Test: [3/3]	loss 0.951 (0.942)	Acc@1 69.746 (69.300)
Test model 1 on task 36
Test: [3/3]	loss 0.993 (0.954)	Acc@1 67.201 (69.670)
Test model 1 on task 37
Test: [3/3]	loss 0.972 (0.979)	Acc@1 66.925 (67.230)
Test model 1 on task 38
Test: [3/3]	loss 0.954 (0.969)	Acc@1 68.529 (67.860)
Test model 1 on task 39
Test: [3/3]	loss 1.068 (1.053)	Acc@1 64.491 (64.820)
Test model 1 on task 40
Test: [3/3]	loss 1.226 (1.230)	Acc@1 57.743 (57.310)
Test model 1 on task 41
Test: [3/3]	loss 1.246 (1.263)	Acc@1 58.684 (57.910)
Test model 1 on task 42
Test: [3/3]	loss 1.207 (1.216)	Acc@1 59.347 (59.780)
Test model 1 on task 43
Test: [3/3]	loss 1.406 (1.370)	Acc@1 53.872 (54.070)
############################################################ Avg acc: 82.01
Task 44 Model 1:
0 ['1.400', '2.927']
100 ['1.651', '1.836']
200 ['1.735', '1.996']
300 ['1.804', '1.501']
400 ['1.845', '1.206']
500 ['1.869', '1.020']
600 ['1.885', '1.403']
700 ['1.901', '1.639']
800 ['1.915', '1.567']
900 ['1.947', '1.649']
1000 ['1.947', '1.574']
1100 ['1.932', '1.151']
1200 ['1.959', '1.416']
1300 ['1.957', '1.583']
1400 ['1.980', '1.325']
1500 ['1.953', '1.557']
1600 ['1.962', '1.743']
1700 ['1.958', '1.266']
1800 ['1.969', '1.568']
1900 ['1.974', '1.646']
2000 ['1.974', '1.365']
2100 ['1.982', '1.480']
2200 ['1.985', '1.331']
2300 ['1.983', '1.952']
2400 ['1.977', '1.084']
2500 ['1.973', '1.154']
2600 ['1.973', '1.735']
2700 ['2.001', '1.293']
2800 ['1.983', '1.267']
2900 ['1.981', '1.190']
3000 ['1.982', '1.428']
3100 ['1.993', '1.843']
3200 ['1.993', '1.313']
3300 ['1.978', '1.965']
3400 ['1.989', '1.276']
3500 ['1.991', '1.699']
3600 ['1.975', '1.801']
3700 ['1.985', '1.476']
Train: [1][3750/3750]	loss 0.100 (0.079)	Acc@1 37.500 (47.468)
0 ['1.991', '1.764']
100 ['1.999', '1.438']
200 ['1.982', '1.354']
300 ['2.006', '1.576']
400 ['1.983', '1.282']
500 ['1.997', '1.713']
600 ['1.984', '1.421']
700 ['1.992', '1.330']
800 ['1.988', '1.743']
900 ['1.988', '1.453']
1000 ['1.997', '1.262']
1100 ['1.993', '1.269']
1200 ['1.984', '2.053']
1300 ['1.987', '1.326']
1400 ['1.994', '1.663']
1500 ['1.984', '1.366']
1600 ['1.991', '1.509']
1700 ['2.000', '1.724']
1800 ['1.995', '1.317']
1900 ['1.993', '1.599']
2000 ['1.986', '1.496']
2100 ['1.974', '1.517']
2200 ['1.981', '1.489']
2300 ['1.983', '1.573']
2400 ['1.989', '1.561']
2500 ['1.994', '1.476']
2600 ['1.997', '1.769']
2700 ['1.979', '1.367']
2800 ['1.994', '1.427']
2900 ['1.992', '1.748']
3000 ['1.994', '1.486']
3100 ['2.002', '1.160']
3200 ['1.998', '1.476']
3300 ['1.989', '1.509']
3400 ['2.002', '1.158']
3500 ['1.995', '1.314']
3600 ['1.989', '1.543']
3700 ['1.996', '1.632']
Train: [2][3750/3750]	loss 0.082 (0.078)	Acc@1 56.250 (50.513)
0 ['1.991', '1.686']
100 ['1.990', '1.637']
200 ['1.983', '1.401']
300 ['1.975', '1.338']
400 ['1.992', '0.871']
500 ['1.992', '1.348']
600 ['1.997', '1.275']
700 ['1.987', '1.286']
800 ['1.988', '2.190']
900 ['1.992', '1.296']
1000 ['1.999', '1.575']
1100 ['1.989', '1.319']
1200 ['1.982', '1.560']
1300 ['1.989', '1.972']
1400 ['1.985', '1.474']
1500 ['1.982', '1.191']
1600 ['1.987', '1.647']
1700 ['1.990', '1.430']
1800 ['1.992', '1.181']
1900 ['1.997', '1.995']
2000 ['1.988', '1.611']
2100 ['1.980', '1.738']
2200 ['1.985', '1.915']
2300 ['1.989', '1.318']
2400 ['1.993', '1.339']
2500 ['1.999', '1.449']
2600 ['2.005', '1.742']
2700 ['1.994', '1.435']
2800 ['1.992', '1.009']
2900 ['1.988', '1.402']
3000 ['1.999', '1.128']
3100 ['1.991', '1.270']
3200 ['2.010', '1.350']
3300 ['1.997', '1.208']
3400 ['1.993', '1.453']
3500 ['1.978', '1.239']
3600 ['1.992', '1.477']
3700 ['1.987', '1.261']
Train: [3][3750/3750]	loss 0.069 (0.078)	Acc@1 75.000 (50.623)
0 ['1.994', '1.654']
100 ['1.990', '1.687']
200 ['1.996', '1.667']
300 ['2.003', '1.377']
400 ['2.008', '1.678']
500 ['2.004', '1.669']
600 ['1.995', '1.994']
700 ['1.992', '1.169']
800 ['1.978', '1.297']
900 ['1.973', '1.673']
1000 ['1.984', '1.179']
1100 ['1.991', '1.065']
1200 ['1.986', '1.404']
1300 ['1.979', '1.837']
1400 ['1.985', '1.560']
1500 ['1.984', '1.242']
1600 ['1.996', '1.432']
1700 ['1.994', '1.278']
1800 ['1.987', '1.624']
1900 ['2.003', '1.362']
2000 ['2.001', '1.725']
2100 ['1.995', '1.272']
2200 ['2.003', '1.698']
2300 ['2.005', '1.208']
2400 ['1.991', '1.334']
2500 ['1.992', '0.984']
2600 ['1.986', '1.572']
2700 ['1.993', '1.346']
2800 ['1.996', '0.968']
2900 ['1.999', '1.707']
3000 ['1.984', '1.603']
3100 ['1.981', '1.554']
3200 ['1.988', '1.353']
3300 ['1.996', '1.752']
3400 ['1.989', '1.124']
3500 ['1.998', '1.230']
3600 ['1.996', '1.483']
3700 ['1.989', '1.495']
Train: [4][3750/3750]	loss 0.078 (0.078)	Acc@1 43.750 (50.582)
0 ['1.982', '1.728']
100 ['1.993', '1.949']
200 ['1.992', '1.592']
300 ['1.997', '1.412']
400 ['1.992', '1.439']
500 ['1.991', '0.780']
600 ['1.996', '1.318']
700 ['1.996', '1.670']
800 ['2.013', '1.859']
900 ['2.003', '1.361']
1000 ['2.003', '1.543']
1100 ['1.999', '1.529']
1200 ['1.998', '1.081']
1300 ['1.995', '1.153']
1400 ['1.999', '1.031']
1500 ['1.990', '1.088']
1600 ['1.974', '2.132']
1700 ['1.984', '1.534']
1800 ['1.987', '1.461']
1900 ['1.989', '1.479']
2000 ['1.986', '1.607']
2100 ['1.983', '1.002']
2200 ['1.986', '1.652']
2300 ['1.977', '1.484']
2400 ['1.981', '2.153']
2500 ['1.992', '1.449']
2600 ['1.996', '2.086']
2700 ['1.990', '1.456']
2800 ['1.994', '1.240']
2900 ['1.987', '1.644']
3000 ['2.001', '1.858']
3100 ['1.995', '1.319']
3200 ['1.984', '1.467']
3300 ['1.981', '1.147']
3400 ['1.984', '1.538']
3500 ['1.984', '1.261']
3600 ['1.997', '1.650']
3700 ['1.999', '1.252']
Train: [5][3750/3750]	loss 0.081 (0.078)	Acc@1 62.500 (50.533)
Test model 1 on task 1
Test: [3/3]	loss 0.311 (0.326)	Acc@1 89.381 (89.330)
Test model 1 on task 2
Test: [3/3]	loss 0.253 (0.249)	Acc@1 91.869 (91.660)
Test model 1 on task 3
Test: [3/3]	loss 0.238 (0.227)	Acc@1 92.257 (92.670)
Test model 1 on task 4
Test: [3/3]	loss 0.246 (0.244)	Acc@1 91.759 (91.830)
Test model 1 on task 5
Test: [3/3]	loss 0.228 (0.232)	Acc@1 92.644 (93.060)
Test model 1 on task 6
Test: [3/3]	loss 0.244 (0.233)	Acc@1 92.423 (92.650)
Test model 1 on task 7
Test: [3/3]	loss 0.238 (0.242)	Acc@1 92.865 (92.530)
Test model 1 on task 8
Test: [3/3]	loss 0.234 (0.243)	Acc@1 92.035 (92.240)
Test model 1 on task 9
Test: [3/3]	loss 0.259 (0.251)	Acc@1 92.478 (92.600)
Test model 1 on task 10
Test: [3/3]	loss 0.263 (0.258)	Acc@1 92.091 (91.980)
Test model 1 on task 11
Test: [3/3]	loss 0.275 (0.262)	Acc@1 91.925 (92.090)
Test model 1 on task 12
Test: [3/3]	loss 0.248 (0.267)	Acc@1 92.423 (92.020)
Test model 1 on task 13
Test: [3/3]	loss 0.288 (0.276)	Acc@1 90.874 (91.490)
Test model 1 on task 14
Test: [3/3]	loss 0.309 (0.307)	Acc@1 90.985 (90.440)
Test model 1 on task 15
Test: [3/3]	loss 0.337 (0.305)	Acc@1 89.491 (90.760)
Test model 1 on task 16
Test: [3/3]	loss 0.338 (0.337)	Acc@1 89.712 (89.950)
Test model 1 on task 17
Test: [3/3]	loss 0.335 (0.319)	Acc@1 89.602 (90.280)
Test model 1 on task 18
Test: [3/3]	loss 0.330 (0.338)	Acc@1 90.653 (90.350)
Test model 1 on task 19
Test: [3/3]	loss 0.382 (0.379)	Acc@1 88.496 (88.210)
Test model 1 on task 20
Test: [3/3]	loss 0.399 (0.393)	Acc@1 88.330 (88.420)
Test model 1 on task 21
Test: [3/3]	loss 0.402 (0.408)	Acc@1 88.606 (87.800)
Test model 1 on task 22
Test: [3/3]	loss 0.483 (0.474)	Acc@1 85.398 (85.770)
Test model 1 on task 23
Test: [3/3]	loss 0.494 (0.466)	Acc@1 84.900 (86.280)
Test model 1 on task 24
Test: [3/3]	loss 0.505 (0.504)	Acc@1 84.956 (84.270)
Test model 1 on task 25
Test: [3/3]	loss 0.521 (0.516)	Acc@1 83.850 (84.710)
Test model 1 on task 26
Test: [3/3]	loss 0.555 (0.546)	Acc@1 82.909 (83.260)
Test model 1 on task 27
Test: [3/3]	loss 0.527 (0.549)	Acc@1 84.071 (83.000)
Test model 1 on task 28
Test: [3/3]	loss 0.631 (0.631)	Acc@1 80.642 (80.100)
Test model 1 on task 29
Test: [3/3]	loss 0.610 (0.616)	Acc@1 81.582 (80.730)
Test model 1 on task 30
Test: [3/3]	loss 0.696 (0.696)	Acc@1 77.544 (77.600)
Test model 1 on task 31
Test: [3/3]	loss 0.715 (0.721)	Acc@1 78.319 (77.530)
Test model 1 on task 32
Test: [3/3]	loss 0.792 (0.760)	Acc@1 74.558 (75.760)
Test model 1 on task 33
Test: [3/3]	loss 0.806 (0.809)	Acc@1 73.341 (74.080)
Test model 1 on task 34
Test: [3/3]	loss 0.843 (0.868)	Acc@1 73.009 (71.870)
Test model 1 on task 35
Test: [3/3]	loss 0.920 (0.941)	Acc@1 71.239 (69.290)
Test model 1 on task 36
Test: [3/3]	loss 0.941 (0.952)	Acc@1 69.635 (69.570)
Test model 1 on task 37
Test: [3/3]	loss 0.977 (0.979)	Acc@1 66.814 (67.040)
Test model 1 on task 38
Test: [3/3]	loss 0.998 (0.973)	Acc@1 66.814 (67.740)
Test model 1 on task 39
Test: [3/3]	loss 1.050 (1.053)	Acc@1 64.768 (64.870)
Test model 1 on task 40
Test: [3/3]	loss 1.202 (1.224)	Acc@1 57.965 (57.580)
Test model 1 on task 41
Test: [3/3]	loss 1.264 (1.264)	Acc@1 57.854 (57.830)
Test model 1 on task 42
Test: [3/3]	loss 1.178 (1.212)	Acc@1 61.781 (59.940)
Test model 1 on task 43
Test: [3/3]	loss 1.373 (1.366)	Acc@1 53.982 (54.300)
Test model 1 on task 44
Test: [3/3]	loss 1.430 (1.405)	Acc@1 51.715 (52.400)
############################################################ Avg acc: 81.32
Task 45 Model 1:
0 ['1.437', '3.551']
100 ['1.732', '1.768']
200 ['1.812', '2.043']
300 ['1.896', '2.095']
400 ['1.933', '2.337']
500 ['1.969', '1.633']
600 ['2.006', '1.610']
700 ['2.031', '1.543']
800 ['2.019', '1.627']
900 ['2.046', '1.986']
1000 ['2.049', '2.203']
1100 ['2.060', '1.837']
1200 ['2.059', '1.830']
1300 ['2.075', '1.770']
1400 ['2.062', '1.456']
1500 ['2.065', '1.831']
1600 ['2.067', '1.719']
1700 ['2.081', '1.040']
1800 ['2.079', '1.951']
1900 ['2.083', '1.608']
2000 ['2.080', '1.431']
2100 ['2.081', '1.696']
2200 ['2.090', '1.524']
2300 ['2.104', '1.882']
2400 ['2.078', '1.865']
2500 ['2.068', '1.503']
2600 ['2.056', '1.768']
2700 ['2.074', '1.729']
2800 ['2.081', '1.683']
2900 ['2.094', '1.671']
3000 ['2.086', '1.270']
3100 ['2.102', '2.014']
3200 ['2.088', '1.545']
3300 ['2.104', '1.457']
3400 ['2.068', '1.054']
3500 ['2.064', '1.146']
3600 ['2.089', '1.761']
3700 ['2.084', '2.076']
Train: [1][3750/3750]	loss 0.075 (0.083)	Acc@1 43.750 (41.942)
0 ['2.085', '1.709']
100 ['2.104', '1.467']
200 ['2.087', '1.371']
300 ['2.052', '1.940']
400 ['2.065', '1.428']
500 ['2.092', '1.658']
600 ['2.074', '1.910']
700 ['2.079', '1.672']
800 ['2.094', '1.522']
900 ['2.099', '1.912']
1000 ['2.091', '1.667']
1100 ['2.088', '0.877']
1200 ['2.086', '1.327']
1300 ['2.086', '1.656']
1400 ['2.105', '1.465']
1500 ['2.090', '1.834']
1600 ['2.094', '1.142']
1700 ['2.109', '1.375']
1800 ['2.075', '1.282']
1900 ['2.100', '1.627']
2000 ['2.087', '1.997']
2100 ['2.102', '1.526']
2200 ['2.099', '2.316']
2300 ['2.098', '1.637']
2400 ['2.119', '1.406']
2500 ['2.093', '1.659']
2600 ['2.115', '0.990']
2700 ['2.097', '2.126']
2800 ['2.090', '1.554']
2900 ['2.086', '1.480']
3000 ['2.098', '1.844']
3100 ['2.082', '1.780']
3200 ['2.110', '1.504']
3300 ['2.101', '1.582']
3400 ['2.120', '1.645']
3500 ['2.093', '1.661']
3600 ['2.116', '1.734']
3700 ['2.096', '1.539']
Train: [2][3750/3750]	loss 0.075 (0.082)	Acc@1 43.750 (44.967)
0 ['2.126', '1.544']
100 ['2.137', '1.472']
200 ['2.105', '1.490']
300 ['2.084', '1.291']
400 ['2.098', '1.553']
500 ['2.090', '1.532']
600 ['2.101', '1.880']
700 ['2.109', '1.429']
800 ['2.119', '1.717']
900 ['2.087', '1.932']
1000 ['2.092', '1.688']
1100 ['2.098', '1.665']
1200 ['2.095', '1.299']
1300 ['2.100', '1.414']
1400 ['2.102', '2.280']
1500 ['2.114', '2.090']
1600 ['2.116', '1.396']
1700 ['2.123', '1.673']
1800 ['2.114', '1.983']
1900 ['2.121', '1.424']
2000 ['2.122', '1.743']
2100 ['2.117', '1.000']
2200 ['2.115', '1.358']
2300 ['2.109', '1.433']
2400 ['2.105', '1.208']
2500 ['2.108', '1.483']
2600 ['2.108', '1.280']
2700 ['2.127', '1.563']
2800 ['2.106', '1.419']
2900 ['2.100', '1.138']
3000 ['2.123', '1.761']
3100 ['2.100', '1.389']
3200 ['2.131', '1.972']
3300 ['2.127', '1.474']
3400 ['2.132', '1.720']
3500 ['2.131', '1.469']
3600 ['2.111', '1.503']
3700 ['2.125', '1.612']
Train: [3][3750/3750]	loss 0.074 (0.082)	Acc@1 50.000 (45.485)
0 ['2.122', '1.486']
100 ['2.129', '1.531']
200 ['2.108', '1.641']
300 ['2.126', '1.452']
400 ['2.096', '1.413']
500 ['2.090', '1.738']
600 ['2.110', '1.913']
700 ['2.108', '1.310']
800 ['2.111', '1.956']
900 ['2.144', '1.685']
1000 ['2.107', '1.488']
1100 ['2.104', '2.088']
1200 ['2.112', '1.694']
1300 ['2.112', '1.363']
1400 ['2.117', '1.375']
1500 ['2.097', '2.142']
1600 ['2.105', '1.800']
1700 ['2.113', '1.778']
1800 ['2.109', '1.727']
1900 ['2.138', '1.263']
2000 ['2.117', '1.605']
2100 ['2.118', '1.380']
2200 ['2.120', '2.261']
2300 ['2.109', '1.405']
2400 ['2.107', '2.363']
2500 ['2.118', '1.634']
2600 ['2.114', '1.502']
2700 ['2.107', '0.932']
2800 ['2.126', '1.441']
2900 ['2.123', '1.805']
3000 ['2.126', '1.577']
3100 ['2.116', '1.636']
3200 ['2.114', '1.394']
3300 ['2.103', '1.058']
3400 ['2.126', '1.486']
3500 ['2.123', '1.446']
3600 ['2.120', '1.832']
3700 ['2.108', '1.409']
Train: [4][3750/3750]	loss 0.084 (0.082)	Acc@1 31.250 (45.710)
0 ['2.107', '1.002']
100 ['2.131', '1.508']
200 ['2.095', '1.583']
300 ['2.117', '1.547']
400 ['2.119', '1.727']
500 ['2.113', '1.584']
600 ['2.121', '1.772']
700 ['2.112', '1.791']
800 ['2.113', '1.338']
900 ['2.110', '1.641']
1000 ['2.112', '1.737']
1100 ['2.112', '1.384']
1200 ['2.121', '1.647']
1300 ['2.109', '1.398']
1400 ['2.126', '1.819']
1500 ['2.122', '1.650']
1600 ['2.140', '1.466']
1700 ['2.121', '1.098']
1800 ['2.111', '1.549']
1900 ['2.107', '1.359']
2000 ['2.096', '1.500']
2100 ['2.122', '1.383']
2200 ['2.108', '0.972']
2300 ['2.121', '1.475']
2400 ['2.109', '1.793']
2500 ['2.099', '1.625']
2600 ['2.100', '1.430']
2700 ['2.142', '1.289']
2800 ['2.115', '2.037']
2900 ['2.134', '1.965']
3000 ['2.116', '0.970']
3100 ['2.110', '1.351']
3200 ['2.108', '1.304']
3300 ['2.122', '2.005']
3400 ['2.106', '2.204']
3500 ['2.130', '1.350']
3600 ['2.109', '1.783']
3700 ['2.116', '2.048']
Train: [5][3750/3750]	loss 0.080 (0.082)	Acc@1 50.000 (45.665)
Test model 1 on task 1
Test: [3/3]	loss 0.334 (0.326)	Acc@1 89.270 (89.440)
Test model 1 on task 2
Test: [3/3]	loss 0.246 (0.252)	Acc@1 92.091 (91.540)
Test model 1 on task 3
Test: [3/3]	loss 0.200 (0.228)	Acc@1 94.248 (92.740)
Test model 1 on task 4
Test: [3/3]	loss 0.237 (0.245)	Acc@1 92.091 (91.910)
Test model 1 on task 5
Test: [3/3]	loss 0.222 (0.232)	Acc@1 93.971 (93.040)
Test model 1 on task 6
Test: [3/3]	loss 0.256 (0.234)	Acc@1 92.146 (92.660)
Test model 1 on task 7
Test: [3/3]	loss 0.255 (0.242)	Acc@1 91.980 (92.560)
Test model 1 on task 8
Test: [3/3]	loss 0.249 (0.243)	Acc@1 92.035 (92.310)
Test model 1 on task 9
Test: [3/3]	loss 0.236 (0.252)	Acc@1 92.644 (92.650)
Test model 1 on task 10
Test: [3/3]	loss 0.250 (0.259)	Acc@1 91.980 (91.920)
Test model 1 on task 11
Test: [3/3]	loss 0.242 (0.262)	Acc@1 92.367 (92.060)
Test model 1 on task 12
Test: [3/3]	loss 0.292 (0.269)	Acc@1 90.985 (91.910)
Test model 1 on task 13
Test: [3/3]	loss 0.284 (0.277)	Acc@1 91.206 (91.530)
Test model 1 on task 14
Test: [3/3]	loss 0.297 (0.307)	Acc@1 90.763 (90.390)
Test model 1 on task 15
Test: [3/3]	loss 0.260 (0.305)	Acc@1 92.423 (90.780)
Test model 1 on task 16
Test: [3/3]	loss 0.348 (0.339)	Acc@1 89.491 (89.810)
Test model 1 on task 17
Test: [3/3]	loss 0.279 (0.320)	Acc@1 91.482 (90.310)
Test model 1 on task 18
Test: [3/3]	loss 0.328 (0.340)	Acc@1 90.044 (90.120)
Test model 1 on task 19
Test: [3/3]	loss 0.396 (0.381)	Acc@1 87.777 (88.090)
Test model 1 on task 20
Test: [3/3]	loss 0.377 (0.394)	Acc@1 88.662 (88.230)
Test model 1 on task 21
Test: [3/3]	loss 0.429 (0.409)	Acc@1 86.394 (87.780)
Test model 1 on task 22
Test: [3/3]	loss 0.494 (0.474)	Acc@1 85.509 (85.910)
Test model 1 on task 23
Test: [3/3]	loss 0.484 (0.468)	Acc@1 85.343 (86.090)
Test model 1 on task 24
Test: [3/3]	loss 0.515 (0.507)	Acc@1 83.684 (84.130)
Test model 1 on task 25
Test: [3/3]	loss 0.523 (0.518)	Acc@1 84.292 (84.660)
Test model 1 on task 26
Test: [3/3]	loss 0.531 (0.547)	Acc@1 83.960 (83.190)
Test model 1 on task 27
Test: [3/3]	loss 0.582 (0.551)	Acc@1 81.195 (82.850)
Test model 1 on task 28
Test: [3/3]	loss 0.622 (0.630)	Acc@1 80.752 (80.220)
Test model 1 on task 29
Test: [3/3]	loss 0.586 (0.616)	Acc@1 81.527 (80.720)
Test model 1 on task 30
Test: [3/3]	loss 0.680 (0.696)	Acc@1 79.923 (77.460)
Test model 1 on task 31
Test: [3/3]	loss 0.725 (0.724)	Acc@1 77.102 (77.270)
Test model 1 on task 32
Test: [3/3]	loss 0.773 (0.760)	Acc@1 75.442 (75.640)
Test model 1 on task 33
Test: [3/3]	loss 0.822 (0.812)	Acc@1 73.009 (73.920)
Test model 1 on task 34
Test: [3/3]	loss 0.897 (0.869)	Acc@1 71.681 (71.830)
Test model 1 on task 35
Test: [3/3]	loss 0.958 (0.941)	Acc@1 68.584 (69.280)
Test model 1 on task 36
Test: [3/3]	loss 0.946 (0.948)	Acc@1 69.027 (69.500)
Test model 1 on task 37
Test: [3/3]	loss 1.026 (0.980)	Acc@1 64.712 (67.110)
Test model 1 on task 38
Test: [3/3]	loss 0.963 (0.975)	Acc@1 68.418 (67.740)
Test model 1 on task 39
Test: [3/3]	loss 1.034 (1.051)	Acc@1 65.487 (64.930)
Test model 1 on task 40
Test: [3/3]	loss 1.233 (1.220)	Acc@1 56.803 (57.600)
Test model 1 on task 41
Test: [3/3]	loss 1.266 (1.263)	Acc@1 56.914 (57.820)
Test model 1 on task 42
Test: [3/3]	loss 1.250 (1.207)	Acc@1 58.794 (60.160)
Test model 1 on task 43
Test: [3/3]	loss 1.377 (1.366)	Acc@1 54.480 (54.190)
Test model 1 on task 44
Test: [3/3]	loss 1.392 (1.401)	Acc@1 51.936 (52.580)
Test model 1 on task 45
Test: [3/3]	loss 1.501 (1.528)	Acc@1 48.341 (47.860)
############################################################ Avg acc: 80.54
Task 46 Model 1:
0 ['1.567', '3.573']
100 ['1.836', '2.631']
200 ['1.935', '2.212']
300 ['1.977', '2.246']
400 ['2.007', '1.964']
500 ['2.052', '2.014']
600 ['2.069', '1.688']
700 ['2.074', '1.752']
800 ['2.097', '1.308']
900 ['2.094', '1.331']
1000 ['2.106', '1.565']
1100 ['2.104', '2.052']
1200 ['2.122', '1.795']
1300 ['2.133', '1.260']
1400 ['2.118', '1.463']
1500 ['2.113', '1.660']
1600 ['2.121', '1.555']
1700 ['2.121', '1.741']
1800 ['2.112', '2.162']
1900 ['2.125', '1.750']
2000 ['2.131', '1.445']
2100 ['2.136', '1.759']
2200 ['2.152', '1.708']
2300 ['2.142', '1.437']
2400 ['2.140', '1.610']
2500 ['2.144', '1.581']
2600 ['2.123', '2.140']
2700 ['2.143', '1.621']
2800 ['2.150', '1.627']
2900 ['2.135', '1.980']
3000 ['2.145', '1.621']
3100 ['2.135', '1.509']
3200 ['2.134', '1.268']
3300 ['2.123', '1.948']
3400 ['2.150', '1.525']
3500 ['2.153', '1.650']
3600 ['2.152', '1.827']
3700 ['2.145', '1.717']
Train: [1][3750/3750]	loss 0.084 (0.084)	Acc@1 37.500 (39.667)
0 ['2.159', '1.664']
100 ['2.157', '1.678']
200 ['2.145', '1.261']
300 ['2.152', '1.656']
400 ['2.157', '1.876']
500 ['2.169', '1.410']
600 ['2.152', '1.457']
700 ['2.161', '1.305']
800 ['2.146', '1.921']
900 ['2.154', '1.854']
1000 ['2.128', '1.666']
1100 ['2.151', '1.784']
1200 ['2.143', '1.904']
1300 ['2.135', '1.387']
1400 ['2.152', '1.810']
1500 ['2.144', '1.277']
1600 ['2.154', '1.685']
1700 ['2.140', '1.806']
1800 ['2.143', '2.007']
1900 ['2.161', '1.418']
2000 ['2.162', '1.393']
2100 ['2.157', '1.830']
2200 ['2.144', '1.669']
2300 ['2.150', '1.823']
2400 ['2.146', '2.371']
2500 ['2.146', '1.886']
2600 ['2.143', '1.851']
2700 ['2.158', '1.858']
2800 ['2.161', '1.377']
2900 ['2.136', '1.397']
3000 ['2.159', '1.629']
3100 ['2.156', '1.915']
3200 ['2.177', '2.197']
3300 ['2.180', '1.585']
3400 ['2.160', '1.419']
3500 ['2.141', '1.113']
3600 ['2.168', '1.596']
3700 ['2.161', '1.751']
Train: [2][3750/3750]	loss 0.084 (0.083)	Acc@1 43.750 (42.467)
0 ['2.165', '1.374']
100 ['2.161', '1.525']
200 ['2.179', '1.575']
300 ['2.159', '1.361']
400 ['2.155', '1.435']
500 ['2.154', '1.946']
600 ['2.170', '1.471']
700 ['2.162', '1.381']
800 ['2.156', '1.888']
900 ['2.165', '1.707']
1000 ['2.168', '1.453']
1100 ['2.171', '1.488']
1200 ['2.183', '1.250']
1300 ['2.173', '1.966']
1400 ['2.182', '1.374']
1500 ['2.172', '1.635']
1600 ['2.163', '1.451']
1700 ['2.183', '1.937']
1800 ['2.183', '1.491']
1900 ['2.174', '1.462']
2000 ['2.180', '1.806']
2100 ['2.150', '1.038']
2200 ['2.165', '1.872']
2300 ['2.149', '1.747']
2400 ['2.157', '1.463']
2500 ['2.169', '1.291']
2600 ['2.157', '1.408']
2700 ['2.154', '1.683']
2800 ['2.149', '1.850']
2900 ['2.178', '1.373']
3000 ['2.167', '2.519']
3100 ['2.172', '1.653']
3200 ['2.179', '1.415']
3300 ['2.152', '2.047']
3400 ['2.182', '1.447']
3500 ['2.174', '1.493']
3600 ['2.179', '1.426']
3700 ['2.175', '1.499']
Train: [3][3750/3750]	loss 0.085 (0.083)	Acc@1 31.250 (43.777)
0 ['2.174', '1.955']
100 ['2.196', '1.226']
200 ['2.201', '1.581']
300 ['2.177', '1.626']
400 ['2.171', '2.067']
500 ['2.166', '2.272']
600 ['2.186', '1.633']
700 ['2.175', '1.947']
800 ['2.165', '1.934']
900 ['2.166', '1.415']
1000 ['2.170', '1.476']
1100 ['2.169', '1.397']
1200 ['2.162', '1.525']
1300 ['2.177', '1.780']
1400 ['2.180', '2.014']
1500 ['2.190', '1.648']
1600 ['2.180', '1.594']
1700 ['2.158', '1.319']
1800 ['2.169', '1.548']
1900 ['2.163', '1.858']
2000 ['2.156', '1.465']
2100 ['2.167', '1.940']
2200 ['2.159', '1.543']
2300 ['2.148', '1.568']
2400 ['2.168', '2.191']
2500 ['2.179', '1.544']
2600 ['2.176', '1.701']
2700 ['2.159', '1.489']
2800 ['2.168', '1.511']
2900 ['2.176', '1.360']
3000 ['2.173', '1.730']
3100 ['2.185', '1.874']
3200 ['2.175', '1.390']
3300 ['2.168', '1.880']
3400 ['2.189', '2.266']
3500 ['2.170', '1.973']
3600 ['2.181', '1.599']
3700 ['2.166', '1.467']
Train: [4][3750/3750]	loss 0.080 (0.083)	Acc@1 43.750 (43.958)
0 ['2.174', '1.720']
100 ['2.187', '1.571']
200 ['2.172', '1.675']
300 ['2.184', '1.420']
400 ['2.165', '1.728']
500 ['2.171', '1.582']
600 ['2.174', '1.331']
700 ['2.191', '1.591']
800 ['2.179', '1.562']
900 ['2.176', '1.665']
1000 ['2.173', '1.396']
1100 ['2.152', '1.630']
1200 ['2.159', '1.631']
1300 ['2.164', '1.629']
1400 ['2.155', '1.278']
1500 ['2.179', '1.869']
1600 ['2.183', '1.682']
1700 ['2.163', '1.554']
1800 ['2.154', '1.876']
1900 ['2.168', '1.826']
2000 ['2.178', '1.763']
2100 ['2.166', '1.440']
2200 ['2.180', '1.770']
2300 ['2.171', '1.643']
2400 ['2.171', '1.402']
2500 ['2.173', '1.573']
2600 ['2.180', '1.359']
2700 ['2.175', '1.822']
2800 ['2.168', '1.732']
2900 ['2.166', '1.406']
3000 ['2.175', '1.747']
3100 ['2.166', '1.757']
3200 ['2.159', '1.315']
3300 ['2.181', '1.327']
3400 ['2.157', '1.957']
3500 ['2.174', '1.201']
3600 ['2.156', '1.764']
3700 ['2.177', '1.637']
Train: [5][3750/3750]	loss 0.086 (0.083)	Acc@1 50.000 (43.932)
Test model 1 on task 1
Test: [3/3]	loss 0.322 (0.328)	Acc@1 89.049 (89.270)
Test model 1 on task 2
Test: [3/3]	loss 0.252 (0.252)	Acc@1 91.040 (91.550)
Test model 1 on task 3
Test: [3/3]	loss 0.244 (0.229)	Acc@1 91.980 (92.740)
Test model 1 on task 4
Test: [3/3]	loss 0.245 (0.246)	Acc@1 92.146 (91.890)
Test model 1 on task 5
Test: [3/3]	loss 0.237 (0.233)	Acc@1 93.142 (93.040)
Test model 1 on task 6
Test: [3/3]	loss 0.259 (0.237)	Acc@1 91.704 (92.610)
Test model 1 on task 7
Test: [3/3]	loss 0.238 (0.243)	Acc@1 92.810 (92.520)
Test model 1 on task 8
Test: [3/3]	loss 0.256 (0.245)	Acc@1 91.869 (92.210)
Test model 1 on task 9
Test: [3/3]	loss 0.274 (0.253)	Acc@1 92.257 (92.600)
Test model 1 on task 10
Test: [3/3]	loss 0.274 (0.260)	Acc@1 91.593 (91.840)
Test model 1 on task 11
Test: [3/3]	loss 0.269 (0.263)	Acc@1 91.759 (92.070)
Test model 1 on task 12
Test: [3/3]	loss 0.242 (0.270)	Acc@1 92.976 (91.880)
Test model 1 on task 13
Test: [3/3]	loss 0.272 (0.278)	Acc@1 91.593 (91.470)
Test model 1 on task 14
Test: [3/3]	loss 0.319 (0.308)	Acc@1 90.321 (90.430)
Test model 1 on task 15
Test: [3/3]	loss 0.286 (0.307)	Acc@1 91.482 (90.720)
Test model 1 on task 16
Test: [3/3]	loss 0.337 (0.338)	Acc@1 89.602 (89.800)
Test model 1 on task 17
Test: [3/3]	loss 0.334 (0.320)	Acc@1 89.878 (90.350)
Test model 1 on task 18
Test: [3/3]	loss 0.347 (0.340)	Acc@1 90.210 (90.170)
Test model 1 on task 19
Test: [3/3]	loss 0.359 (0.383)	Acc@1 88.551 (88.000)
Test model 1 on task 20
Test: [3/3]	loss 0.407 (0.396)	Acc@1 87.998 (88.220)
Test model 1 on task 21
Test: [3/3]	loss 0.415 (0.409)	Acc@1 87.832 (87.770)
Test model 1 on task 22
Test: [3/3]	loss 0.470 (0.475)	Acc@1 85.785 (85.780)
Test model 1 on task 23
Test: [3/3]	loss 0.490 (0.470)	Acc@1 86.062 (86.000)
Test model 1 on task 24
Test: [3/3]	loss 0.525 (0.509)	Acc@1 83.462 (84.100)
Test model 1 on task 25
Test: [3/3]	loss 0.553 (0.520)	Acc@1 83.518 (84.610)
Test model 1 on task 26
Test: [3/3]	loss 0.564 (0.550)	Acc@1 82.799 (83.000)
Test model 1 on task 27
Test: [3/3]	loss 0.578 (0.552)	Acc@1 81.914 (82.840)
Test model 1 on task 28
Test: [3/3]	loss 0.638 (0.632)	Acc@1 80.531 (80.070)
Test model 1 on task 29
Test: [3/3]	loss 0.608 (0.616)	Acc@1 80.918 (80.700)
Test model 1 on task 30
Test: [3/3]	loss 0.681 (0.696)	Acc@1 79.093 (77.610)
Test model 1 on task 31
Test: [3/3]	loss 0.735 (0.727)	Acc@1 76.825 (77.060)
Test model 1 on task 32
Test: [3/3]	loss 0.773 (0.761)	Acc@1 75.387 (75.630)
Test model 1 on task 33
Test: [3/3]	loss 0.803 (0.813)	Acc@1 75.664 (73.880)
Test model 1 on task 34
Test: [3/3]	loss 0.875 (0.870)	Acc@1 70.852 (71.920)
Test model 1 on task 35
Test: [3/3]	loss 0.952 (0.943)	Acc@1 69.248 (69.060)
Test model 1 on task 36
Test: [3/3]	loss 0.976 (0.948)	Acc@1 67.865 (69.430)
Test model 1 on task 37
Test: [3/3]	loss 0.967 (0.980)	Acc@1 68.197 (67.170)
Test model 1 on task 38
Test: [3/3]	loss 0.971 (0.974)	Acc@1 67.976 (67.740)
Test model 1 on task 39
Test: [3/3]	loss 1.006 (1.049)	Acc@1 67.035 (64.810)
Test model 1 on task 40
Test: [3/3]	loss 1.199 (1.220)	Acc@1 59.347 (57.550)
Test model 1 on task 41
Test: [3/3]	loss 1.274 (1.258)	Acc@1 58.407 (58.080)
Test model 1 on task 42
Test: [3/3]	loss 1.210 (1.205)	Acc@1 60.232 (60.370)
Test model 1 on task 43
Test: [3/3]	loss 1.347 (1.366)	Acc@1 54.591 (54.440)
Test model 1 on task 44
Test: [3/3]	loss 1.420 (1.402)	Acc@1 51.659 (52.440)
Test model 1 on task 45
Test: [3/3]	loss 1.543 (1.527)	Acc@1 47.179 (47.790)
Test model 1 on task 46
Test: [3/3]	loss 1.630 (1.617)	Acc@1 45.022 (44.960)
############################################################ Avg acc: 79.74
Task 47 Model 1:
0 ['1.641', '3.073']
100 ['1.900', '2.422']
200 ['1.983', '2.146']
300 ['2.047', '1.589']
400 ['2.071', '1.583']
500 ['2.106', '1.840']
600 ['2.123', '1.574']
700 ['2.149', '2.158']
800 ['2.168', '1.275']
900 ['2.168', '2.228']
1000 ['2.190', '1.853']
1100 ['2.197', '2.525']
1200 ['2.187', '1.800']
1300 ['2.201', '1.701']
1400 ['2.216', '1.715']
1500 ['2.204', '2.249']
1600 ['2.199', '2.183']
1700 ['2.229', '1.935']
1800 ['2.227', '1.218']
1900 ['2.226', '1.509']
2000 ['2.220', '1.548']
2100 ['2.237', '1.740']
2200 ['2.221', '1.431']
2300 ['2.243', '1.965']
2400 ['2.244', '2.023']
2500 ['2.235', '1.945']
2600 ['2.241', '1.634']
2700 ['2.238', '1.665']
2800 ['2.252', '1.393']
2900 ['2.250', '1.875']
3000 ['2.242', '1.404']
3100 ['2.240', '1.086']
3200 ['2.244', '1.512']
3300 ['2.250', '1.742']
3400 ['2.245', '1.254']
3500 ['2.269', '1.571']
3600 ['2.254', '1.680']
3700 ['2.245', '1.713']
Train: [1][3750/3750]	loss 0.087 (0.085)	Acc@1 43.750 (39.080)
0 ['2.249', '1.977']
100 ['2.249', '2.039']
200 ['2.255', '2.007']
300 ['2.252', '1.661']
400 ['2.259', '1.101']
500 ['2.265', '1.684']
600 ['2.244', '1.832']
700 ['2.251', '1.651']
800 ['2.242', '1.698']
900 ['2.245', '1.349']
1000 ['2.256', '1.448']
1100 ['2.246', '1.502']
1200 ['2.261', '1.475']
1300 ['2.261', '2.186']
1400 ['2.253', '1.730']
1500 ['2.247', '1.967']
1600 ['2.240', '1.588']
1700 ['2.258', '1.639']
1800 ['2.253', '1.749']
1900 ['2.261', '1.632']
2000 ['2.255', '1.221']
2100 ['2.266', '1.464']
2200 ['2.243', '1.927']
2300 ['2.254', '1.642']
2400 ['2.277', '1.774']
2500 ['2.277', '1.606']
2600 ['2.266', '1.685']
2700 ['2.242', '1.981']
2800 ['2.264', '1.677']
2900 ['2.259', '1.504']
3000 ['2.259', '1.510']
3100 ['2.249', '1.732']
3200 ['2.276', '1.947']
3300 ['2.275', '1.426']
3400 ['2.258', '1.238']
3500 ['2.266', '1.571']
3600 ['2.278', '1.159']
3700 ['2.273', '1.448']
Train: [2][3750/3750]	loss 0.094 (0.084)	Acc@1 18.750 (42.630)
0 ['2.271', '1.331']
100 ['2.246', '1.712']
200 ['2.288', '1.295']
300 ['2.268', '1.769']
400 ['2.260', '1.931']
500 ['2.246', '2.019']
600 ['2.245', '1.547']
700 ['2.263', '1.817']
800 ['2.261', '1.689']
900 ['2.255', '1.359']
1000 ['2.245', '1.817']
1100 ['2.257', '1.661']
1200 ['2.275', '2.455']
1300 ['2.245', '1.959']
1400 ['2.253', '2.038']
1500 ['2.272', '1.944']
1600 ['2.261', '1.808']
1700 ['2.277', '2.077']
1800 ['2.251', '2.390']
1900 ['2.265', '1.251']
2000 ['2.253', '1.189']
2100 ['2.260', '1.341']
2200 ['2.262', '1.375']
2300 ['2.266', '1.837']
2400 ['2.264', '1.767']
2500 ['2.258', '1.758']
2600 ['2.244', '2.266']
2700 ['2.267', '1.835']
2800 ['2.263', '2.129']
2900 ['2.269', '1.382']
3000 ['2.268', '2.049']
3100 ['2.267', '1.502']
3200 ['2.269', '2.455']
3300 ['2.258', '1.414']
3400 ['2.264', '1.332']
3500 ['2.278', '2.017']
3600 ['2.271', '1.893']
3700 ['2.255', '1.440']
Train: [3][3750/3750]	loss 0.087 (0.084)	Acc@1 43.750 (42.772)
0 ['2.270', '1.548']
100 ['2.270', '1.828']
200 ['2.260', '1.383']
300 ['2.264', '1.312']
400 ['2.274', '1.777']
500 ['2.275', '1.323']
600 ['2.270', '2.148']
700 ['2.255', '1.821']
800 ['2.267', '2.144']
900 ['2.271', '1.745']
1000 ['2.249', '1.635']
1100 ['2.278', '1.967']
1200 ['2.263', '1.483']
1300 ['2.266', '1.939']
1400 ['2.272', '1.714']
1500 ['2.261', '2.190']
1600 ['2.269', '1.580']
1700 ['2.259', '2.236']
1800 ['2.259', '1.424']
1900 ['2.273', '1.876']
2000 ['2.268', '1.359']
2100 ['2.269', '1.589']
2200 ['2.272', '1.509']
2300 ['2.271', '1.418']
2400 ['2.240', '1.908']
2500 ['2.260', '1.447']
2600 ['2.264', '2.144']
2700 ['2.254', '1.913']
2800 ['2.254', '1.506']
2900 ['2.280', '1.539']
3000 ['2.272', '2.053']
3100 ['2.274', '1.682']
3200 ['2.266', '1.629']
3300 ['2.249', '1.982']
3400 ['2.258', '1.414']
3500 ['2.243', '1.516']
3600 ['2.263', '1.662']
3700 ['2.261', '1.286']
Train: [4][3750/3750]	loss 0.092 (0.084)	Acc@1 31.250 (42.880)
0 ['2.267', '1.230']
100 ['2.255', '1.781']
200 ['2.255', '1.691']
300 ['2.264', '1.821']
400 ['2.264', '1.566']
500 ['2.273', '1.520']
600 ['2.264', '1.990']
700 ['2.280', '1.470']
800 ['2.260', '1.162']
900 ['2.267', '1.155']
1000 ['2.264', '1.664']
1100 ['2.257', '1.711']
1200 ['2.269', '1.592']
1300 ['2.249', '2.013']
1400 ['2.262', '1.403']
1500 ['2.253', '1.826']
1600 ['2.262', '1.904']
1700 ['2.280', '1.729']
1800 ['2.257', '1.867']
1900 ['2.258', '1.132']
2000 ['2.256', '2.021']
2100 ['2.263', '1.666']
2200 ['2.271', '1.868']
2300 ['2.274', '1.611']
2400 ['2.267', '1.395']
2500 ['2.254', '1.746']
2600 ['2.259', '1.693']
2700 ['2.267', '1.043']
2800 ['2.264', '1.463']
2900 ['2.267', '1.661']
3000 ['2.282', '1.903']
3100 ['2.279', '1.629']
3200 ['2.257', '1.781']
3300 ['2.258', '1.944']
3400 ['2.259', '1.447']
3500 ['2.255', '1.639']
3600 ['2.265', '1.974']
3700 ['2.268', '2.433']
Train: [5][3750/3750]	loss 0.078 (0.084)	Acc@1 56.250 (42.860)
Test model 1 on task 1
Test: [3/3]	loss 0.337 (0.328)	Acc@1 89.049 (89.320)
Test model 1 on task 2
Test: [3/3]	loss 0.253 (0.251)	Acc@1 92.035 (91.580)
Test model 1 on task 3
Test: [3/3]	loss 0.226 (0.229)	Acc@1 92.312 (92.630)
Test model 1 on task 4
Test: [3/3]	loss 0.224 (0.246)	Acc@1 92.588 (91.970)
Test model 1 on task 5
Test: [3/3]	loss 0.211 (0.233)	Acc@1 93.695 (93.030)
Test model 1 on task 6
Test: [3/3]	loss 0.243 (0.237)	Acc@1 92.699 (92.640)
Test model 1 on task 7
Test: [3/3]	loss 0.245 (0.243)	Acc@1 92.201 (92.640)
Test model 1 on task 8
Test: [3/3]	loss 0.265 (0.245)	Acc@1 91.704 (92.110)
Test model 1 on task 9
Test: [3/3]	loss 0.254 (0.255)	Acc@1 92.367 (92.510)
Test model 1 on task 10
Test: [3/3]	loss 0.250 (0.259)	Acc@1 91.759 (91.930)
Test model 1 on task 11
Test: [3/3]	loss 0.279 (0.265)	Acc@1 91.704 (92.040)
Test model 1 on task 12
Test: [3/3]	loss 0.255 (0.271)	Acc@1 92.810 (91.900)
Test model 1 on task 13
Test: [3/3]	loss 0.274 (0.279)	Acc@1 92.091 (91.520)
Test model 1 on task 14
Test: [3/3]	loss 0.306 (0.307)	Acc@1 90.929 (90.370)
Test model 1 on task 15
Test: [3/3]	loss 0.300 (0.308)	Acc@1 91.095 (90.570)
Test model 1 on task 16
Test: [3/3]	loss 0.325 (0.339)	Acc@1 90.265 (89.770)
Test model 1 on task 17
Test: [3/3]	loss 0.314 (0.320)	Acc@1 90.487 (90.260)
Test model 1 on task 18
Test: [3/3]	loss 0.368 (0.342)	Acc@1 89.436 (89.950)
Test model 1 on task 19
Test: [3/3]	loss 0.399 (0.385)	Acc@1 87.611 (87.910)
Test model 1 on task 20
Test: [3/3]	loss 0.430 (0.397)	Acc@1 87.832 (88.180)
Test model 1 on task 21
Test: [3/3]	loss 0.425 (0.410)	Acc@1 87.389 (87.770)
Test model 1 on task 22
Test: [3/3]	loss 0.460 (0.476)	Acc@1 85.177 (85.730)
Test model 1 on task 23
Test: [3/3]	loss 0.480 (0.470)	Acc@1 85.454 (85.980)
Test model 1 on task 24
Test: [3/3]	loss 0.487 (0.510)	Acc@1 83.684 (83.900)
Test model 1 on task 25
Test: [3/3]	loss 0.573 (0.520)	Acc@1 82.633 (84.580)
Test model 1 on task 26
Test: [3/3]	loss 0.548 (0.551)	Acc@1 83.518 (83.060)
Test model 1 on task 27
Test: [3/3]	loss 0.508 (0.552)	Acc@1 83.684 (82.780)
Test model 1 on task 28
Test: [3/3]	loss 0.649 (0.633)	Acc@1 79.204 (80.060)
Test model 1 on task 29
Test: [3/3]	loss 0.670 (0.618)	Acc@1 80.088 (80.740)
Test model 1 on task 30
Test: [3/3]	loss 0.701 (0.697)	Acc@1 77.268 (77.700)
Test model 1 on task 31
Test: [3/3]	loss 0.696 (0.728)	Acc@1 79.038 (77.060)
Test model 1 on task 32
Test: [3/3]	loss 0.770 (0.761)	Acc@1 74.447 (75.740)
Test model 1 on task 33
Test: [3/3]	loss 0.788 (0.814)	Acc@1 74.115 (73.590)
Test model 1 on task 34
Test: [3/3]	loss 0.877 (0.871)	Acc@1 72.124 (71.920)
Test model 1 on task 35
Test: [3/3]	loss 0.927 (0.943)	Acc@1 69.524 (68.990)
Test model 1 on task 36
Test: [3/3]	loss 0.951 (0.952)	Acc@1 69.248 (69.380)
Test model 1 on task 37
Test: [3/3]	loss 0.979 (0.983)	Acc@1 66.980 (67.090)
Test model 1 on task 38
Test: [3/3]	loss 0.952 (0.977)	Acc@1 69.137 (67.950)
Test model 1 on task 39
Test: [3/3]	loss 1.116 (1.046)	Acc@1 61.836 (65.000)
Test model 1 on task 40
Test: [3/3]	loss 1.244 (1.223)	Acc@1 56.637 (57.400)
Test model 1 on task 41
Test: [3/3]	loss 1.245 (1.259)	Acc@1 58.850 (58.070)
Test model 1 on task 42
Test: [3/3]	loss 1.234 (1.205)	Acc@1 59.569 (60.380)
Test model 1 on task 43
Test: [3/3]	loss 1.361 (1.363)	Acc@1 53.982 (54.300)
Test model 1 on task 44
Test: [3/3]	loss 1.384 (1.400)	Acc@1 52.876 (52.600)
Test model 1 on task 45
Test: [3/3]	loss 1.513 (1.527)	Acc@1 47.511 (47.820)
Test model 1 on task 46
Test: [3/3]	loss 1.619 (1.624)	Acc@1 45.022 (44.560)
Test model 1 on task 47
Test: [3/3]	loss 1.694 (1.685)	Acc@1 42.644 (43.280)
############################################################ Avg acc: 78.94
Task 48 Model 1:
0 ['1.704', '3.829']
100 ['2.006', '1.815']
200 ['2.062', '1.641']
300 ['2.128', '1.787']
400 ['2.166', '1.625']
500 ['2.181', '1.663']
600 ['2.217', '1.867']
700 ['2.221', '1.920']
800 ['2.239', '1.180']
900 ['2.244', '1.874']
1000 ['2.262', '1.793']
1100 ['2.261', '1.779']
1200 ['2.256', '1.673']
1300 ['2.258', '1.529']
1400 ['2.263', '1.688']
1500 ['2.277', '1.505']
1600 ['2.273', '1.339']
1700 ['2.280', '1.474']
1800 ['2.275', '1.980']
1900 ['2.288', '1.966']
2000 ['2.275', '2.452']
2100 ['2.269', '1.699']
2200 ['2.272', '1.559']
2300 ['2.271', '1.440']
2400 ['2.277', '1.616']
2500 ['2.277', '1.700']
2600 ['2.277', '1.504']
2700 ['2.276', '2.067']
2800 ['2.299', '1.919']
2900 ['2.289', '1.721']
3000 ['2.301', '1.513']
3100 ['2.293', '1.610']
3200 ['2.288', '1.623']
3300 ['2.288', '1.459']
3400 ['2.299', '1.453']
3500 ['2.297', '1.806']
3600 ['2.277', '1.988']
3700 ['2.277', '1.571']
Train: [1][3750/3750]	loss 0.086 (0.084)	Acc@1 43.750 (40.385)
0 ['2.279', '1.403']
100 ['2.282', '1.717']
200 ['2.294', '2.161']
300 ['2.288', '1.542']
400 ['2.281', '1.388']
500 ['2.287', '1.494']
600 ['2.293', '1.733']
700 ['2.293', '1.596']
800 ['2.286', '1.892']
900 ['2.278', '1.557']
1000 ['2.298', '1.405']
1100 ['2.299', '1.938']
1200 ['2.277', '1.293']
1300 ['2.289', '1.592']
1400 ['2.294', '1.612']
1500 ['2.291', '1.648']
1600 ['2.287', '1.582']
1700 ['2.294', '1.417']
1800 ['2.284', '1.278']
1900 ['2.283', '1.541']
2000 ['2.303', '1.467']
2100 ['2.280', '2.208']
2200 ['2.294', '1.489']
2300 ['2.280', '1.353']
2400 ['2.308', '1.659']
2500 ['2.293', '2.028']
2600 ['2.302', '1.663']
2700 ['2.309', '1.265']
2800 ['2.286', '1.809']
2900 ['2.291', '1.472']
3000 ['2.284', '1.932']
3100 ['2.279', '1.417']
3200 ['2.287', '1.528']
3300 ['2.282', '1.435']
3400 ['2.292', '1.321']
3500 ['2.278', '1.555']
3600 ['2.290', '1.661']
3700 ['2.296', '1.807']
Train: [2][3750/3750]	loss 0.092 (0.083)	Acc@1 18.750 (42.720)
0 ['2.296', '1.594']
100 ['2.295', '1.220']
200 ['2.283', '1.836']
300 ['2.297', '1.541']
400 ['2.290', '1.500']
500 ['2.288', '1.666']
600 ['2.315', '1.768']
700 ['2.311', '1.454']
800 ['2.306', '1.364']
900 ['2.285', '2.097']
1000 ['2.290', '2.053']
1100 ['2.316', '1.363']
1200 ['2.292', '1.296']
1300 ['2.286', '1.641']
1400 ['2.296', '1.941']
1500 ['2.299', '1.739']
1600 ['2.282', '2.002']
1700 ['2.289', '1.453']
1800 ['2.294', '1.753']
1900 ['2.293', '2.454']
2000 ['2.298', '1.474']
2100 ['2.292', '1.573']
2200 ['2.290', '1.450']
2300 ['2.289', '1.571']
2400 ['2.297', '1.844']
2500 ['2.283', '1.503']
2600 ['2.293', '1.973']
2700 ['2.291', '2.135']
2800 ['2.293', '1.848']
2900 ['2.295', '1.980']
3000 ['2.290', '1.255']
3100 ['2.285', '1.669']
3200 ['2.297', '1.803']
3300 ['2.281', '1.906']
3400 ['2.288', '1.906']
3500 ['2.298', '2.083']
3600 ['2.296', '1.513']
3700 ['2.295', '1.559']
Train: [3][3750/3750]	loss 0.087 (0.083)	Acc@1 37.500 (43.090)
0 ['2.284', '1.708']
100 ['2.287', '1.506']
200 ['2.308', '2.224']
300 ['2.308', '1.576']
400 ['2.298', '1.799']
500 ['2.301', '1.473']
600 ['2.287', '1.797']
700 ['2.291', '1.640']
800 ['2.279', '1.943']
900 ['2.290', '1.145']
1000 ['2.286', '1.824']
1100 ['2.282', '1.798']
1200 ['2.294', '1.988']
1300 ['2.310', '1.429']
1400 ['2.290', '1.976']
1500 ['2.309', '1.760']
1600 ['2.309', '1.460']
1700 ['2.283', '1.807']
1800 ['2.295', '1.443']
1900 ['2.298', '1.623']
2000 ['2.305', '1.689']
2100 ['2.298', '1.760']
2200 ['2.298', '1.847']
2300 ['2.292', '1.515']
2400 ['2.299', '1.523']
2500 ['2.296', '1.767']
2600 ['2.295', '1.362']
2700 ['2.278', '1.706']
2800 ['2.288', '1.571']
2900 ['2.295', '1.890']
3000 ['2.289', '1.870']
3100 ['2.284', '1.519']
3200 ['2.287', '1.908']
3300 ['2.294', '1.519']
3400 ['2.301', '1.061']
3500 ['2.302', '1.959']
3600 ['2.306', '2.029']
3700 ['2.292', '1.609']
Train: [4][3750/3750]	loss 0.082 (0.083)	Acc@1 50.000 (43.158)
0 ['2.297', '1.877']
100 ['2.307', '1.689']
200 ['2.295', '1.574']
300 ['2.310', '1.877']
400 ['2.278', '1.654']
500 ['2.308', '1.642']
600 ['2.295', '2.029']
700 ['2.293', '1.935']
800 ['2.284', '2.042']
900 ['2.310', '1.258']
1000 ['2.303', '1.276']
1100 ['2.288', '1.636']
1200 ['2.287', '2.138']
1300 ['2.270', '1.624']
1400 ['2.293', '1.635']
1500 ['2.296', '1.581']
1600 ['2.303', '1.484']
1700 ['2.292', '1.762']
1800 ['2.287', '1.894']
1900 ['2.284', '1.197']
2000 ['2.290', '2.273']
2100 ['2.286', '1.300']
2200 ['2.277', '1.920']
2300 ['2.297', '1.630']
2400 ['2.283', '1.396']
2500 ['2.287', '1.588']
2600 ['2.296', '1.798']
2700 ['2.292', '1.340']
2800 ['2.293', '1.948']
2900 ['2.300', '1.415']
3000 ['2.304', '1.910']
3100 ['2.302', '1.940']
3200 ['2.310', '1.981']
3300 ['2.300', '1.979']
3400 ['2.283', '1.222']
3500 ['2.304', '2.194']
3600 ['2.291', '1.687']
3700 ['2.310', '1.657']
Train: [5][3750/3750]	loss 0.075 (0.083)	Acc@1 68.750 (43.052)
Test model 1 on task 1
Test: [3/3]	loss 0.349 (0.329)	Acc@1 88.440 (89.310)
Test model 1 on task 2
Test: [3/3]	loss 0.241 (0.251)	Acc@1 91.593 (91.610)
Test model 1 on task 3
Test: [3/3]	loss 0.237 (0.230)	Acc@1 92.588 (92.680)
Test model 1 on task 4
Test: [3/3]	loss 0.251 (0.247)	Acc@1 92.312 (91.970)
Test model 1 on task 5
Test: [3/3]	loss 0.231 (0.234)	Acc@1 92.920 (93.050)
Test model 1 on task 6
Test: [3/3]	loss 0.227 (0.237)	Acc@1 92.699 (92.540)
Test model 1 on task 7
Test: [3/3]	loss 0.253 (0.243)	Acc@1 91.925 (92.520)
Test model 1 on task 8
Test: [3/3]	loss 0.239 (0.245)	Acc@1 91.538 (92.140)
Test model 1 on task 9
Test: [3/3]	loss 0.247 (0.254)	Acc@1 93.142 (92.550)
Test model 1 on task 10
Test: [3/3]	loss 0.272 (0.261)	Acc@1 91.759 (91.860)
Test model 1 on task 11
Test: [3/3]	loss 0.254 (0.265)	Acc@1 92.146 (92.020)
Test model 1 on task 12
Test: [3/3]	loss 0.253 (0.271)	Acc@1 92.257 (91.860)
Test model 1 on task 13
Test: [3/3]	loss 0.311 (0.280)	Acc@1 90.321 (91.480)
Test model 1 on task 14
Test: [3/3]	loss 0.297 (0.308)	Acc@1 90.929 (90.360)
Test model 1 on task 15
Test: [3/3]	loss 0.291 (0.308)	Acc@1 91.704 (90.580)
Test model 1 on task 16
Test: [3/3]	loss 0.334 (0.339)	Acc@1 90.155 (89.810)
Test model 1 on task 17
Test: [3/3]	loss 0.319 (0.321)	Acc@1 89.934 (90.170)
Test model 1 on task 18
Test: [3/3]	loss 0.329 (0.342)	Acc@1 90.487 (89.910)
Test model 1 on task 19
Test: [3/3]	loss 0.371 (0.385)	Acc@1 88.330 (87.900)
Test model 1 on task 20
Test: [3/3]	loss 0.382 (0.399)	Acc@1 89.159 (88.250)
Test model 1 on task 21
Test: [3/3]	loss 0.412 (0.411)	Acc@1 87.334 (87.790)
Test model 1 on task 22
Test: [3/3]	loss 0.488 (0.476)	Acc@1 85.564 (85.700)
Test model 1 on task 23
Test: [3/3]	loss 0.472 (0.472)	Acc@1 86.228 (85.900)
Test model 1 on task 24
Test: [3/3]	loss 0.502 (0.511)	Acc@1 84.347 (83.970)
Test model 1 on task 25
Test: [3/3]	loss 0.523 (0.522)	Acc@1 84.790 (84.390)
Test model 1 on task 26
Test: [3/3]	loss 0.554 (0.552)	Acc@1 82.854 (83.050)
Test model 1 on task 27
Test: [3/3]	loss 0.561 (0.553)	Acc@1 82.080 (82.900)
Test model 1 on task 28
Test: [3/3]	loss 0.663 (0.635)	Acc@1 78.982 (80.060)
Test model 1 on task 29
Test: [3/3]	loss 0.643 (0.618)	Acc@1 79.480 (80.650)
Test model 1 on task 30
Test: [3/3]	loss 0.704 (0.699)	Acc@1 76.604 (77.640)
Test model 1 on task 31
Test: [3/3]	loss 0.730 (0.728)	Acc@1 76.659 (77.070)
Test model 1 on task 32
Test: [3/3]	loss 0.758 (0.761)	Acc@1 75.885 (75.630)
Test model 1 on task 33
Test: [3/3]	loss 0.819 (0.813)	Acc@1 73.949 (73.720)
Test model 1 on task 34
Test: [3/3]	loss 0.870 (0.870)	Acc@1 70.631 (71.920)
Test model 1 on task 35
Test: [3/3]	loss 0.985 (0.944)	Acc@1 69.027 (68.880)
Test model 1 on task 36
Test: [3/3]	loss 0.960 (0.955)	Acc@1 69.027 (69.080)
Test model 1 on task 37
Test: [3/3]	loss 0.985 (0.984)	Acc@1 66.814 (67.090)
Test model 1 on task 38
Test: [3/3]	loss 0.955 (0.979)	Acc@1 68.529 (67.850)
Test model 1 on task 39
Test: [3/3]	loss 1.046 (1.049)	Acc@1 63.883 (64.890)
Test model 1 on task 40
Test: [3/3]	loss 1.226 (1.223)	Acc@1 56.803 (57.400)
Test model 1 on task 41
Test: [3/3]	loss 1.235 (1.259)	Acc@1 58.573 (58.050)
Test model 1 on task 42
Test: [3/3]	loss 1.193 (1.207)	Acc@1 61.892 (60.310)
Test model 1 on task 43
Test: [3/3]	loss 1.381 (1.363)	Acc@1 53.816 (54.540)
Test model 1 on task 44
Test: [3/3]	loss 1.407 (1.400)	Acc@1 53.429 (52.560)
Test model 1 on task 45
Test: [3/3]	loss 1.550 (1.522)	Acc@1 47.069 (48.080)
Test model 1 on task 46
Test: [3/3]	loss 1.632 (1.626)	Acc@1 42.699 (44.450)
Test model 1 on task 47
Test: [3/3]	loss 1.692 (1.682)	Acc@1 42.423 (43.400)
Test model 1 on task 48
Test: [3/3]	loss 1.658 (1.638)	Acc@1 42.588 (44.170)
############################################################ Avg acc: 78.20
Task 49 Model 1:
0 ['1.670', '2.955']
100 ['2.030', '2.398']
200 ['2.074', '1.843']
300 ['2.147', '1.992']
400 ['2.183', '1.517']
500 ['2.189', '1.207']
600 ['2.204', '2.211']
700 ['2.230', '2.114']
800 ['2.246', '1.529']
900 ['2.237', '1.590']
1000 ['2.254', '1.741']
1100 ['2.255', '1.870']
1200 ['2.257', '1.865']
1300 ['2.248', '1.530']
1400 ['2.257', '1.795']
1500 ['2.259', '2.184']
1600 ['2.263', '1.995']
1700 ['2.273', '2.026']
1800 ['2.278', '1.407']
1900 ['2.266', '1.107']
2000 ['2.288', '2.304']
2100 ['2.296', '1.760']
2200 ['2.276', '1.531']
2300 ['2.289', '1.215']
2400 ['2.298', '1.569']
2500 ['2.267', '2.698']
2600 ['2.279', '1.553']
2700 ['2.277', '1.298']
2800 ['2.282', '1.368']
2900 ['2.281', '1.565']
3000 ['2.301', '1.807']
3100 ['2.275', '1.426']
3200 ['2.295', '2.105']
3300 ['2.256', '0.961']
3400 ['2.281', '1.932']
3500 ['2.303', '1.634']
3600 ['2.287', '1.512']
3700 ['2.282', '1.933']
Train: [1][3750/3750]	loss 0.095 (0.082)	Acc@1 18.750 (41.008)
0 ['2.277', '1.593']
100 ['2.291', '2.053']
200 ['2.296', '1.858']
300 ['2.276', '1.283']
400 ['2.278', '1.791']
500 ['2.282', '1.806']
600 ['2.292', '1.479']
700 ['2.279', '1.470']
800 ['2.284', '1.289']
900 ['2.291', '1.328']
1000 ['2.301', '1.893']
1100 ['2.282', '1.900']
1200 ['2.288', '2.545']
1300 ['2.292', '1.707']
1400 ['2.272', '1.582']
1500 ['2.287', '2.036']
1600 ['2.287', '1.646']
1700 ['2.283', '1.559']
1800 ['2.300', '1.978']
1900 ['2.271', '2.015']
2000 ['2.287', '2.108']
2100 ['2.283', '2.061']
2200 ['2.271', '1.523']
2300 ['2.268', '1.591']
2400 ['2.270', '1.839']
2500 ['2.278', '1.309']
2600 ['2.279', '1.814']
2700 ['2.272', '1.766']
2800 ['2.301', '1.719']
2900 ['2.296', '1.885']
3000 ['2.289', '1.418']
3100 ['2.294', '1.253']
3200 ['2.302', '1.863']
3300 ['2.292', '1.623']
3400 ['2.300', '1.416']
3500 ['2.284', '2.116']
3600 ['2.278', '1.791']
3700 ['2.289', '1.558']
Train: [2][3750/3750]	loss 0.082 (0.082)	Acc@1 50.000 (42.628)
0 ['2.292', '2.017']
100 ['2.288', '1.403']
200 ['2.293', '1.567']
300 ['2.285', '2.216']
400 ['2.266', '1.703']
500 ['2.277', '1.489']
600 ['2.264', '1.815']
700 ['2.291', '1.420']
800 ['2.269', '1.721']
900 ['2.267', '2.295']
1000 ['2.260', '1.574']
1100 ['2.267', '1.668']
1200 ['2.288', '1.371']
1300 ['2.292', '1.610']
1400 ['2.277', '1.383']
1500 ['2.287', '1.579']
1600 ['2.316', '1.675']
1700 ['2.292', '1.868']
1800 ['2.284', '1.443']
1900 ['2.277', '1.826']
2000 ['2.278', '1.726']
2100 ['2.276', '1.660']
2200 ['2.289', '1.456']
2300 ['2.281', '1.647']
2400 ['2.288', '1.821']
2500 ['2.282', '1.810']
2600 ['2.274', '1.646']
2700 ['2.274', '1.852']
2800 ['2.281', '2.294']
2900 ['2.299', '1.464']
3000 ['2.302', '2.375']
3100 ['2.307', '1.493']
3200 ['2.298', '1.751']
3300 ['2.313', '1.601']
3400 ['2.276', '1.601']
3500 ['2.300', '1.455']
3600 ['2.294', '1.642']
3700 ['2.290', '1.790']
Train: [3][3750/3750]	loss 0.078 (0.081)	Acc@1 62.500 (42.642)
0 ['2.299', '1.379']
100 ['2.302', '1.422']
200 ['2.307', '1.320']
300 ['2.285', '1.298']
400 ['2.301', '1.635']
500 ['2.280', '1.221']
600 ['2.280', '2.218']
700 ['2.279', '1.189']
800 ['2.277', '2.073']
900 ['2.269', '1.745']
1000 ['2.289', '1.141']
1100 ['2.265', '1.552']
1200 ['2.262', '1.777']
1300 ['2.288', '1.864']
1400 ['2.280', '1.629']
1500 ['2.292', '1.811']
1600 ['2.281', '2.112']
1700 ['2.290', '2.076']
1800 ['2.282', '1.417']
1900 ['2.293', '1.945']
2000 ['2.298', '2.010']
2100 ['2.297', '1.697']
2200 ['2.276', '2.173']
2300 ['2.294', '1.723']
2400 ['2.292', '1.863']
2500 ['2.321', '1.509']
2600 ['2.285', '1.547']
2700 ['2.282', '1.840']
2800 ['2.277', '2.389']
2900 ['2.283', '1.762']
3000 ['2.277', '1.745']
3100 ['2.267', '1.903']
3200 ['2.272', '1.436']
3300 ['2.273', '1.458']
3400 ['2.282', '1.431']
3500 ['2.293', '1.785']
3600 ['2.282', '2.413']
3700 ['2.283', '1.691']
Train: [4][3750/3750]	loss 0.085 (0.082)	Acc@1 37.500 (42.715)
0 ['2.310', '2.074']
100 ['2.270', '1.609']
200 ['2.288', '1.397']
300 ['2.284', '1.960']
400 ['2.288', '1.858']
500 ['2.285', '1.384']
600 ['2.271', '1.459']
700 ['2.283', '2.141']
800 ['2.271', '2.111']
900 ['2.274', '1.417']
1000 ['2.285', '2.771']
1100 ['2.286', '1.467']
1200 ['2.273', '1.775']
1300 ['2.273', '1.750']
1400 ['2.273', '1.660']
1500 ['2.264', '1.063']
1600 ['2.293', '1.810']
1700 ['2.300', '1.831']
1800 ['2.302', '1.619']
1900 ['2.279', '1.952']
2000 ['2.281', '1.700']
2100 ['2.287', '2.159']
2200 ['2.273', '0.970']
2300 ['2.268', '1.900']
2400 ['2.294', '1.637']
2500 ['2.301', '1.167']
2600 ['2.292', '1.302']
2700 ['2.290', '1.797']
2800 ['2.306', '2.028']
2900 ['2.287', '1.718']
3000 ['2.260', '1.502']
3100 ['2.293', '1.631']
3200 ['2.302', '1.671']
3300 ['2.307', '1.598']
3400 ['2.288', '1.991']
3500 ['2.270', '2.386']
3600 ['2.285', '1.497']
3700 ['2.292', '1.377']
Train: [5][3750/3750]	loss 0.083 (0.082)	Acc@1 31.250 (42.680)
Test model 1 on task 1
Test: [3/3]	loss 0.361 (0.330)	Acc@1 88.551 (89.190)
Test model 1 on task 2
Test: [3/3]	loss 0.248 (0.251)	Acc@1 92.035 (91.650)
Test model 1 on task 3
Test: [3/3]	loss 0.247 (0.230)	Acc@1 92.478 (92.610)
Test model 1 on task 4
Test: [3/3]	loss 0.253 (0.248)	Acc@1 91.261 (91.850)
Test model 1 on task 5
Test: [3/3]	loss 0.228 (0.234)	Acc@1 93.031 (92.950)
Test model 1 on task 6
Test: [3/3]	loss 0.214 (0.237)	Acc@1 93.197 (92.580)
Test model 1 on task 7
Test: [3/3]	loss 0.239 (0.244)	Acc@1 92.644 (92.440)
Test model 1 on task 8
Test: [3/3]	loss 0.249 (0.246)	Acc@1 92.478 (92.060)
Test model 1 on task 9
Test: [3/3]	loss 0.239 (0.255)	Acc@1 92.312 (92.490)
Test model 1 on task 10
Test: [3/3]	loss 0.246 (0.262)	Acc@1 91.482 (91.790)
Test model 1 on task 11
Test: [3/3]	loss 0.281 (0.266)	Acc@1 91.427 (91.970)
Test model 1 on task 12
Test: [3/3]	loss 0.263 (0.272)	Acc@1 92.257 (91.840)
Test model 1 on task 13
Test: [3/3]	loss 0.274 (0.280)	Acc@1 91.316 (91.460)
Test model 1 on task 14
Test: [3/3]	loss 0.286 (0.309)	Acc@1 90.819 (90.340)
Test model 1 on task 15
Test: [3/3]	loss 0.307 (0.310)	Acc@1 90.763 (90.540)
Test model 1 on task 16
Test: [3/3]	loss 0.342 (0.341)	Acc@1 89.436 (89.850)
Test model 1 on task 17
Test: [3/3]	loss 0.316 (0.322)	Acc@1 90.819 (90.130)
Test model 1 on task 18
Test: [3/3]	loss 0.325 (0.342)	Acc@1 90.376 (89.990)
Test model 1 on task 19
Test: [3/3]	loss 0.381 (0.388)	Acc@1 88.606 (87.770)
Test model 1 on task 20
Test: [3/3]	loss 0.426 (0.400)	Acc@1 87.279 (88.230)
Test model 1 on task 21
Test: [3/3]	loss 0.401 (0.411)	Acc@1 88.108 (87.730)
Test model 1 on task 22
Test: [3/3]	loss 0.430 (0.476)	Acc@1 87.777 (85.700)
Test model 1 on task 23
Test: [3/3]	loss 0.487 (0.473)	Acc@1 85.785 (85.940)
Test model 1 on task 24
Test: [3/3]	loss 0.518 (0.511)	Acc@1 84.181 (83.950)
Test model 1 on task 25
Test: [3/3]	loss 0.505 (0.523)	Acc@1 85.177 (84.300)
Test model 1 on task 26
Test: [3/3]	loss 0.552 (0.552)	Acc@1 82.743 (82.950)
Test model 1 on task 27
Test: [3/3]	loss 0.598 (0.553)	Acc@1 82.135 (82.920)
Test model 1 on task 28
Test: [3/3]	loss 0.635 (0.636)	Acc@1 80.199 (79.930)
Test model 1 on task 29
Test: [3/3]	loss 0.623 (0.619)	Acc@1 80.144 (80.700)
Test model 1 on task 30
Test: [3/3]	loss 0.696 (0.698)	Acc@1 77.102 (77.510)
Test model 1 on task 31
Test: [3/3]	loss 0.733 (0.729)	Acc@1 77.544 (77.070)
Test model 1 on task 32
Test: [3/3]	loss 0.754 (0.763)	Acc@1 76.327 (75.550)
Test model 1 on task 33
Test: [3/3]	loss 0.807 (0.814)	Acc@1 73.728 (73.680)
Test model 1 on task 34
Test: [3/3]	loss 0.817 (0.869)	Acc@1 73.562 (71.980)
Test model 1 on task 35
Test: [3/3]	loss 0.962 (0.945)	Acc@1 67.976 (68.860)
Test model 1 on task 36
Test: [3/3]	loss 1.008 (0.955)	Acc@1 67.533 (69.130)
Test model 1 on task 37
Test: [3/3]	loss 0.988 (0.985)	Acc@1 66.538 (67.230)
Test model 1 on task 38
Test: [3/3]	loss 0.997 (0.980)	Acc@1 67.201 (67.600)
Test model 1 on task 39
Test: [3/3]	loss 1.040 (1.050)	Acc@1 65.985 (64.940)
Test model 1 on task 40
Test: [3/3]	loss 1.255 (1.221)	Acc@1 54.757 (57.410)
Test model 1 on task 41
Test: [3/3]	loss 1.256 (1.255)	Acc@1 58.020 (58.080)
Test model 1 on task 42
Test: [3/3]	loss 1.233 (1.206)	Acc@1 59.237 (60.070)
Test model 1 on task 43
Test: [3/3]	loss 1.356 (1.361)	Acc@1 54.148 (54.630)
Test model 1 on task 44
Test: [3/3]	loss 1.350 (1.398)	Acc@1 55.476 (52.830)
Test model 1 on task 45
Test: [3/3]	loss 1.547 (1.520)	Acc@1 46.626 (48.300)
Test model 1 on task 46
Test: [3/3]	loss 1.647 (1.626)	Acc@1 43.584 (44.470)
Test model 1 on task 47
Test: [3/3]	loss 1.700 (1.685)	Acc@1 42.976 (43.300)
Test model 1 on task 48
Test: [3/3]	loss 1.650 (1.640)	Acc@1 43.916 (44.060)
Test model 1 on task 49
Test: [3/3]	loss 1.628 (1.679)	Acc@1 45.409 (43.890)
############################################################ Avg acc: 77.48
Task 50 Model 1:
0 ['1.703', '3.358']
100 ['1.969', '2.304']
200 ['2.058', '2.376']
300 ['2.104', '2.520']
400 ['2.138', '1.683']
500 ['2.158', '1.937']
600 ['2.171', '2.259']
700 ['2.201', '2.319']
800 ['2.230', '2.312']
900 ['2.235', '2.077']
1000 ['2.253', '2.497']
1100 ['2.252', '1.421']
1200 ['2.251', '1.745']
1300 ['2.264', '1.895']
1400 ['2.267', '1.799']
1500 ['2.268', '1.700']
1600 ['2.247', '2.240']
1700 ['2.282', '1.872']
1800 ['2.264', '2.400']
1900 ['2.270', '2.442']
2000 ['2.270', '2.279']
2100 ['2.280', '1.894']
2200 ['2.284', '1.898']
2300 ['2.291', '1.148']
2400 ['2.288', '1.865']
2500 ['2.287', '1.747']
2600 ['2.280', '2.579']
2700 ['2.279', '1.735']
2800 ['2.289', '1.903']
2900 ['2.278', '1.872']
3000 ['2.275', '1.776']
3100 ['2.272', '2.231']
3200 ['2.257', '1.946']
3300 ['2.268', '1.930']
3400 ['2.289', '1.957']
3500 ['2.276', '2.187']
3600 ['2.259', '1.758']
3700 ['2.305', '1.942']
Train: [1][3750/3750]	loss 0.082 (0.084)	Acc@1 37.500 (32.108)
0 ['2.296', '1.830']
100 ['2.288', '2.013']
200 ['2.277', '2.108']
300 ['2.258', '1.459']
400 ['2.281', '1.712']
500 ['2.295', '1.310']
600 ['2.290', '1.827']
700 ['2.287', '2.121']
800 ['2.290', '1.437']
900 ['2.295', '1.779']
1000 ['2.297', '2.153']
1100 ['2.292', '2.011']
1200 ['2.299', '2.236']
1300 ['2.281', '1.724']
1400 ['2.277', '2.186']
1500 ['2.284', '1.722']
1600 ['2.286', '1.926']
1700 ['2.293', '2.476']
1800 ['2.298', '1.743']
1900 ['2.296', '2.049']
2000 ['2.278', '1.219']
2100 ['2.299', '1.299']
2200 ['2.280', '2.150']
2300 ['2.272', '1.758']
2400 ['2.271', '1.721']
2500 ['2.294', '1.491']
2600 ['2.301', '1.334']
2700 ['2.303', '1.748']
2800 ['2.297', '1.700']
2900 ['2.303', '1.622']
3000 ['2.296', '2.054']
3100 ['2.299', '2.102']
3200 ['2.295', '2.038']
3300 ['2.283', '1.899']
3400 ['2.302', '1.827']
3500 ['2.286', '1.896']
3600 ['2.293', '2.092']
3700 ['2.290', '1.667']
Train: [2][3750/3750]	loss 0.084 (0.084)	Acc@1 31.250 (34.198)
0 ['2.263', '1.974']
100 ['2.293', '1.636']
200 ['2.275', '2.136']
300 ['2.282', '1.764']
400 ['2.316', '1.406']
500 ['2.294', '1.988']
600 ['2.294', '2.006']
700 ['2.308', '1.800']
800 ['2.338', '1.583']
900 ['2.319', '1.672']
1000 ['2.286', '2.001']
1100 ['2.296', '2.093']
1200 ['2.296', '1.683']
1300 ['2.294', '1.704']
1400 ['2.305', '1.639']
1500 ['2.287', '1.702']
1600 ['2.286', '1.811']
1700 ['2.275', '2.283']
1800 ['2.284', '1.932']
1900 ['2.280', '2.219']
2000 ['2.284', '1.522']
2100 ['2.305', '1.843']
2200 ['2.295', '2.054']
2300 ['2.277', '2.094']
2400 ['2.309', '1.757']
2500 ['2.295', '1.688']
2600 ['2.282', '1.744']
2700 ['2.293', '1.795']
2800 ['2.285', '2.103']
2900 ['2.323', '1.761']
3000 ['2.295', '1.920']
3100 ['2.304', '1.459']
3200 ['2.304', '1.665']
3300 ['2.297', '1.458']
3400 ['2.289', '1.896']
3500 ['2.289', '1.739']
3600 ['2.304', '1.823']
3700 ['2.322', '2.066']
Train: [3][3750/3750]	loss 0.094 (0.084)	Acc@1 31.250 (34.337)
0 ['2.329', '1.722']
100 ['2.303', '2.312']
200 ['2.313', '2.099']
300 ['2.295', '1.696']
400 ['2.296', '1.982']
500 ['2.302', '1.874']
600 ['2.316', '1.473']
700 ['2.304', '1.835']
800 ['2.297', '1.951']
900 ['2.322', '1.758']
1000 ['2.314', '1.822']
1100 ['2.314', '1.742']
1200 ['2.311', '1.847']
1300 ['2.297', '1.863']
1400 ['2.312', '1.940']
1500 ['2.319', '1.993']
1600 ['2.299', '1.912']
1700 ['2.322', '2.130']
1800 ['2.319', '2.165']
1900 ['2.304', '1.719']
2000 ['2.325', '2.139']
2100 ['2.287', '1.776']
2200 ['2.307', '2.356']
2300 ['2.294', '1.961']
2400 ['2.294', '1.428']
2500 ['2.288', '1.900']
2600 ['2.319', '1.586']
2700 ['2.309', '1.653']
2800 ['2.300', '2.124']
2900 ['2.318', '1.635']
3000 ['2.301', '1.861']
3100 ['2.297', '1.700']
3200 ['2.289', '2.082']
3300 ['2.283', '1.821']
3400 ['2.296', '1.850']
3500 ['2.295', '1.694']
3600 ['2.316', '2.149']
3700 ['2.301', '1.540']
Train: [4][3750/3750]	loss 0.089 (0.084)	Acc@1 25.000 (34.515)
0 ['2.304', '2.321']
100 ['2.297', '2.217']
200 ['2.295', '1.818']
300 ['2.291', '1.664']
400 ['2.286', '1.744']
500 ['2.302', '1.871']
600 ['2.299', '1.789']
700 ['2.321', '2.221']
800 ['2.317', '1.478']
900 ['2.289', '1.769']
1000 ['2.297', '2.000']
1100 ['2.302', '2.229']
1200 ['2.304', '1.598']
1300 ['2.296', '2.062']
1400 ['2.309', '1.895']
1500 ['2.295', '1.832']
1600 ['2.309', '1.494']
1700 ['2.304', '2.390']
1800 ['2.290', '1.687']
1900 ['2.295', '1.694']
2000 ['2.306', '2.015']
2100 ['2.311', '2.148']
2200 ['2.323', '1.777']
2300 ['2.295', '2.136']
2400 ['2.286', '2.002']
2500 ['2.286', '1.654']
2600 ['2.303', '1.952']
2700 ['2.296', '1.786']
2800 ['2.308', '1.460']
2900 ['2.309', '1.707']
3000 ['2.310', '1.789']
3100 ['2.304', '1.692']
3200 ['2.291', '2.222']
3300 ['2.313', '1.490']
3400 ['2.325', '1.433']
3500 ['2.316', '2.161']
3600 ['2.285', '1.870']
3700 ['2.293', '1.830']
Train: [5][3750/3750]	loss 0.081 (0.084)	Acc@1 31.250 (34.620)
Test model 1 on task 1
Test: [3/3]	loss 0.337 (0.330)	Acc@1 88.551 (89.150)
Test model 1 on task 2
Test: [3/3]	loss 0.245 (0.251)	Acc@1 91.704 (91.630)
Test model 1 on task 3
Test: [3/3]	loss 0.233 (0.231)	Acc@1 92.976 (92.540)
Test model 1 on task 4
Test: [3/3]	loss 0.263 (0.249)	Acc@1 90.708 (91.770)
Test model 1 on task 5
Test: [3/3]	loss 0.230 (0.235)	Acc@1 92.920 (92.880)
Test model 1 on task 6
Test: [3/3]	loss 0.214 (0.237)	Acc@1 92.976 (92.540)
Test model 1 on task 7
Test: [3/3]	loss 0.236 (0.245)	Acc@1 92.423 (92.400)
Test model 1 on task 8
Test: [3/3]	loss 0.230 (0.246)	Acc@1 92.423 (92.130)
Test model 1 on task 9
Test: [3/3]	loss 0.251 (0.256)	Acc@1 92.865 (92.470)
Test model 1 on task 10
Test: [3/3]	loss 0.260 (0.262)	Acc@1 92.367 (91.840)
Test model 1 on task 11
Test: [3/3]	loss 0.292 (0.266)	Acc@1 90.763 (91.890)
Test model 1 on task 12
Test: [3/3]	loss 0.284 (0.273)	Acc@1 91.593 (91.740)
Test model 1 on task 13
Test: [3/3]	loss 0.289 (0.281)	Acc@1 91.814 (91.430)
Test model 1 on task 14
Test: [3/3]	loss 0.287 (0.310)	Acc@1 91.206 (90.210)
Test model 1 on task 15
Test: [3/3]	loss 0.331 (0.311)	Acc@1 90.597 (90.600)
Test model 1 on task 16
Test: [3/3]	loss 0.371 (0.342)	Acc@1 89.381 (89.830)
Test model 1 on task 17
Test: [3/3]	loss 0.299 (0.323)	Acc@1 90.431 (90.120)
Test model 1 on task 18
Test: [3/3]	loss 0.378 (0.343)	Acc@1 88.938 (89.910)
Test model 1 on task 19
Test: [3/3]	loss 0.404 (0.390)	Acc@1 87.334 (87.820)
Test model 1 on task 20
Test: [3/3]	loss 0.424 (0.401)	Acc@1 86.615 (88.110)
Test model 1 on task 21
Test: [3/3]	loss 0.380 (0.411)	Acc@1 88.827 (87.780)
Test model 1 on task 22
Test: [3/3]	loss 0.459 (0.478)	Acc@1 86.394 (85.670)
Test model 1 on task 23
Test: [3/3]	loss 0.455 (0.473)	Acc@1 86.560 (86.010)
Test model 1 on task 24
Test: [3/3]	loss 0.506 (0.513)	Acc@1 83.573 (83.960)
Test model 1 on task 25
Test: [3/3]	loss 0.522 (0.526)	Acc@1 84.679 (84.290)
Test model 1 on task 26
Test: [3/3]	loss 0.568 (0.552)	Acc@1 82.412 (83.000)
Test model 1 on task 27
Test: [3/3]	loss 0.560 (0.554)	Acc@1 82.854 (82.780)
Test model 1 on task 28
Test: [3/3]	loss 0.635 (0.637)	Acc@1 80.476 (79.780)
Test model 1 on task 29
Test: [3/3]	loss 0.610 (0.620)	Acc@1 80.808 (80.560)
Test model 1 on task 30
Test: [3/3]	loss 0.706 (0.700)	Acc@1 77.821 (77.410)
Test model 1 on task 31
Test: [3/3]	loss 0.755 (0.730)	Acc@1 75.774 (77.090)
Test model 1 on task 32
Test: [3/3]	loss 0.737 (0.764)	Acc@1 76.715 (75.520)
Test model 1 on task 33
Test: [3/3]	loss 0.795 (0.813)	Acc@1 74.723 (73.820)
Test model 1 on task 34
Test: [3/3]	loss 0.867 (0.870)	Acc@1 72.622 (71.910)
Test model 1 on task 35
Test: [3/3]	loss 0.938 (0.945)	Acc@1 68.695 (68.970)
Test model 1 on task 36
Test: [3/3]	loss 0.965 (0.954)	Acc@1 67.920 (69.220)
Test model 1 on task 37
Test: [3/3]	loss 1.002 (0.987)	Acc@1 66.372 (67.050)
Test model 1 on task 38
Test: [3/3]	loss 1.010 (0.978)	Acc@1 66.316 (67.780)
Test model 1 on task 39
Test: [3/3]	loss 1.023 (1.049)	Acc@1 65.929 (64.990)
Test model 1 on task 40
Test: [3/3]	loss 1.239 (1.217)	Acc@1 57.190 (57.560)
Test model 1 on task 41
Test: [3/3]	loss 1.262 (1.256)	Acc@1 57.080 (58.060)
Test model 1 on task 42
Test: [3/3]	loss 1.188 (1.206)	Acc@1 61.228 (60.160)
Test model 1 on task 43
Test: [3/3]	loss 1.366 (1.362)	Acc@1 53.982 (54.560)
Test model 1 on task 44
Test: [3/3]	loss 1.385 (1.402)	Acc@1 52.821 (52.470)
Test model 1 on task 45
Test: [3/3]	loss 1.550 (1.511)	Acc@1 46.405 (48.690)
Test model 1 on task 46
Test: [3/3]	loss 1.633 (1.627)	Acc@1 43.529 (44.340)
Test model 1 on task 47
Test: [3/3]	loss 1.691 (1.682)	Acc@1 43.308 (43.460)
Test model 1 on task 48
Test: [3/3]	loss 1.641 (1.638)	Acc@1 43.971 (44.320)
Test model 1 on task 49
Test: [3/3]	loss 1.625 (1.680)	Acc@1 46.571 (44.040)
Test model 1 on task 50
Test: [3/3]	loss 1.805 (1.833)	Acc@1 36.781 (35.360)
############################################################ Avg acc: 76.63
